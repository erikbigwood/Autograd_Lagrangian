{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5df526ab-2c79-41a7-96f0-86c4864472df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "bottleneck_size = 512\n",
    "bottleneck_size_2 = 8*64\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, bottleneck_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size, bottleneck_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size, bottleneck_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size, bottleneck_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size, bottleneck_size_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size_2, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0904374c-ab32-4829-b22d-b37683a346d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0121,  0.0123, -0.0223,  ..., -0.0288, -0.0283,  0.0166],\n",
      "        [-0.0301, -0.0341, -0.0260,  ..., -0.0284, -0.0020,  0.0100]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0280, 0.0231], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0195,  0.0023, -0.0431,  ..., -0.0109, -0.0075,  0.0051],\n",
      "        [ 0.0338,  0.0338,  0.0187,  ...,  0.0360, -0.0326,  0.0301]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0163, 0.0141], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0212,  0.0216, -0.0182,  ...,  0.0270, -0.0204,  0.0192],\n",
      "        [-0.0389, -0.0142, -0.0220,  ..., -0.0418, -0.0199,  0.0180]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0120, -0.0224], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d4423e6-9bc6-4941-ac89-86ef43440bc9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKQCAYAAAABnneSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgnklEQVR4nO3deXRV9bXA8Z15HshAIIQEBJkRxJFBAbGgAvIQWpGHAk/RYq2URytYfaJ2QHGqtQ9xKGBtrfgcqkIf8yBWyiggqMwJ85AwJGQezvujizwDv/0j9xpCkt/3s1bXqvvcfc+5957fPdtr9j4Bnud5AgAAgAYv8FIfAAAAAGoHhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhZ/BmjVrZOjQoZKeni5hYWGSkpIi3bt3l0mTJl3qQxMRkRYtWsigQYMu9WEAdcKcOXMkICCgyv+Sk5OlT58+Mm/evEt9eMAlxzUN30Xhd4758+dLjx49JDc3V6ZPny6LFi2Sl19+WXr27Clz58691IcHQDF79mxZvXq1fPHFF/L6669LUFCQDB48WD799NNLfWjAJcM1DecK4F69VfXu3VsOHjwo3377rQQHB1fZVlFRIYGBl75WbtGihXTq1Omi/ZpRUFAgkZGRF+W5gZo2Z84cGTt2rKxbt06uvvrqynhhYaE0atRI7rjjDnnnnXcu4REClw7XNK5p57r0n3gdk5OTI0lJSectEBGpskDO/jS9YMEC6datm0REREi7du1k1qxZ5+UdOXJEHnjgAUlLS5PQ0FBp2bKlPPXUU1JWVlblcU899ZRcd911kpCQILGxsdKtWzf54x//KNWpzWfMmCHBwcEyderUytiSJUukX79+EhsbK5GRkdKzZ09ZunRplbwnn3xSAgICZOPGjTJ8+HBp1KiRtGrV6oL7A+q68PBwCQ0NlZCQkMpYdddYcXGxTJo0SZo0aSKRkZFy4403yoYNG6RFixYyZsyYWn4lgP+4pnFNO9f5Z4LjunfvLm+++aY8/PDD8u///u/SrVu3KheO79q8ebNMmjRJpkyZIikpKfLmm2/KvffeK61bt5Ybb7xRRP61QK699loJDAyUJ554Qlq1aiWrV6+WX//615KZmSmzZ8+ufL7MzEx54IEHJD09XURE/vnPf8pPf/pTOXjwoDzxxBPGY/A8T37xi1/I73//e3nzzTcrL0p//vOf5Z577pEhQ4bIW2+9JSEhIfLaa6/JgAEDZOHChdKvX78qz3PHHXfIiBEj5Mc//rHk5+d/37cRqHXl5eVSVlYmnufJ0aNH5bnnnpP8/HwZOXJk5WOqu8bGjh0rc+fOlUceeURuuukm+frrr2Xo0KGSm5tb668L+D64pnFNO4+HKrKzs71evXp5IuKJiBcSEuL16NHDmzZtmpeXl1f5uIyMDC88PNzLysqqjBUWFnoJCQneAw88UBl74IEHvOjo6CqP8zzPe/755z0R8bZt22Y8jvLycq+0tNR7+umnvcTERK+ioqLKvgcOHOgVFBR4w4YN8+Li4rwlS5ZUbs/Pz/cSEhK8wYMHn/ecXbp08a699trK2NSpUz0R8Z544gkf3ymgbpg9e3blev3u/8LCwrwZM2aoedoa27Ztmyci3uTJk6s8/q9//asnIt7o0aMv5ssBahTXNJyLwk+xbt0675lnnvGGDx/uJSUleSLitWjRwjt+/Ljnef86Ua+//vrz8q6//nrvlltuqfznZs2aeYMHD/ZKS0ur/O/sxeW7F6alS5d6/fr182JjY8+7iB05cqTycWf3ff3113vNmzf3vvrqqyrHsHjxYk9EvPfff/+8/U6ePNkLCAjwzpw543ne/y+SzZs31+j7B9SWs4Xfn/70J2/dunXeunXrvP/93//17r//fi8gIMB75ZVXKh9bnTU2Y8YMT0S8DRs2VNlPaWmpFxwcTOGHeolrGs7iP/Uqrr766so/FC8tLZXJkyfLSy+9JNOnT5fp06eLiEhiYuJ5eWFhYVJYWFj5z0ePHpVPP/1U/Wk9OztbRETWrl0r/fv3lz59+sgbb7xR+bcTf/vb3+Q3v/lNlecUEdmxY4ecPHlSxo0bJ506daqy7ejRoyIiMnz4cPX1nThxQqKioir/uWnTpupjgfqgffv2VZo7brnlFsnKypJHHnlERo0aJTt27KjWGsvJyRERkZSUlCrPHxwcbFzzQH3ANQ1nUfhVQ0hIiEydOlVeeukl2bp1q0+5SUlJcsUVV8hvfvMb4/bU1FQREXn33XclJCRE5s2bJ+Hh4ZXb//a3vxnzunfvLj/84Q/l3nvvFRGRV199tfIPdZOSkkRE5JVXXpHrr7/emH/uRS0gIKD6LwqoJ6644gpZuHCh7Nixo9pr7OzF7+jRo9KsWbPKeFlZWWVRCNRnXNPcRuF3jsOHDxv/TeGbb74Rkf8/qatr0KBB8ve//11atWoljRo1Uh8XEBAgwcHBEhQUVBkrLCyUt99+W80ZPXq0REVFyciRIyU/P1/eeustCQoKkp49e0p8fLx8/fXX8tBDD/l0vEBDsmnTJhERSU5OrvYaO/tH7HPnzpVu3bpVxt9///3zuhaBuo5rGs5F4XeOAQMGSFpamgwePFjatWsnFRUVsmnTJnnhhRckOjpaJkyY4NPzPf3007J48WLp0aOHPPzww9K2bVspKiqSzMxM+fvf/y4zZ86UtLQ0GThwoLz44osycuRIuf/++yUnJ0eef/55CQsLsz7/8OHDJTIyUoYPHy6FhYXy17/+VaKjo+WVV16R0aNHy4kTJ2T48OHSuHFjOX78uGzevFmOHz8ur7766vd5m4A6Z+vWrZWFWU5Ojnz44YeyePFiGTp0qLRs2bLaa6xjx45y1113yQsvvCBBQUFy0003ybZt2+SFF16QuLi4OjH3DKgurmk4z6X+I8O6Zu7cud7IkSO9yy+/3IuOjvZCQkK89PR07+677/a+/vrrysed7UI6V+/evb3evXtXiR0/ftx7+OGHvZYtW3ohISFeQkKCd9VVV3mPPfZY5R+kep7nzZo1y2vbtq0XFhbmXXbZZd60adO8P/7xj56IeHv37rXue/ny5V50dLR3yy23eAUFBZ7ned7KlSu9gQMHegkJCV5ISIjXrFkzb+DAgd7//M//VOad/UPYs3/gC9Q3pq7euLg4r2vXrt6LL77oFRUVVT62umusqKjI+8///E+vcePGXnh4uHf99dd7q1ev9uLi4ryJEydeglcJ+IdrGs7FnTsAoBq++OIL6dmzp/zlL3+pMhsQAOoTCj8AOMfixYtl9erVctVVV0lERIRs3rxZnnnmGYmLi5MtW7ZU+WN1AKhP+Bs/ADhHbGysLFq0SH73u99JXl6eJCUlya233irTpk2j6ANQr/GLHwAAgCNoTwMAAHAEhR8AAIAjKPwAAAAcQeEHAADgiGp39XLfOzREdbG3yZW1Znud2raKigqfc2r6M/7uLaiqux/bcWtq6/XUlrp43K6sNbjlQmuNX/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOIJbtgG4JGx/gOxPI4CWk5aWpubcfPPNxviSJUvUnAMHDvh2YOJfo0ZdbIYAUP/xix8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEBXjVnBnBPQzREdXFkBmtNJDQ01BgvKSlRc26//XZjfMKECWrOwYMHjfHU1FQ1JysryxgfN26cmqPdqzcwUP93b3/u71uXsdaA2sG9egEAACAiFH4AAADOoPADAABwBIUfAACAIyj8AAAAHBF8qQ8AgJuCgoLUbbbuXc0111xjjA8YMEDNKSsr83k/M2bMMMZ/+MMfqjlz5841xhta5y6Auo9f/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjmCcC4CLKiAgwBgvLy/3+bnee+89ddvGjRuNcX9GttisXLnSGL/jjjvUnEaNGhnjM2fOVHMCA83/Xs4IGADfB7/4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjAjzP86r1QKUzD6jPqnn616qGttaCg83DA2zdtuPHjzfGn3rqKTVn0KBBxvjatWvVnJCQEGO8tLRUzUlJSTHGv/jiCzUnPz/fGO/Xr5+ac/z4cWM8KChIzamtjl9/1g1rDagdF1pr/OIHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHCEec4CgAbBNvpDG7MSGOj7vw/aRrPYRqNoevToYYwfPXpUzdm/f7/P+/FnnId2DBs3blRzmjdvbox36dJFzVmyZIkxXl5ebjm62qGdI7U1TgaA//jFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQVcv0ABo3am2DtC60B2q0TqBv/32WzXn8OHDPu+npKTE5xzNxIkT1W1z5841xsPDw2ts/7WJ7l2g/uIXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI5wd5+LPzdk9z/M5JygoyBjXbnIu4t9N7f0xYsQIY/zdd9+tlf2j5mjnZlhYmJpz0003GePx8fFqTmhoqE9x27FFRESoOdddd50xvmvXLjXn1ltvNcabNWum5mivtXPnzmqONjbm1KlTak5sbKwx/vjjj6s5d955pzHesWNHNScmJsYY37Nnj5qjfT6pqalqjvZeHzx4UM3BpWO73mifvz/XO9t11Z/nS0tLM8bvvvtuNWfatGk+7+dSGz9+vLpt7969xviCBQv83h+/+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI5zt6vWnw0jrjLLdsLy8vNynuM1dd92lbtM6dIuLi9WcW265xRg/cuSImrNixQpj3NbNpW2zvW+/+93vjPEvv/xSzXnrrbeMcVtHW0OnvY8ieldvZGSkmqN1Cds+//DwcJ/iIiIPP/ywMf6zn/1MzdG60W1d8tpxl5WVqTna2k1KSlJzPvnkE2N8586dao7W6WfrHta+11q1aqXmlJSUGONRUVFqjtZV+cwzz6g5uHRs37UabSKFiL4GbNfVRo0aGeN9+vRRc7Quda2rXMS/rt7gYHMpZPseqEnHjh1Tt505c6bG9+fuFREAAMAxFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4Ahnx7loYxxs7ej+tMRrN4EfMmSImjNq1ChjvEmTJmrO1q1bjXHbTdMXL15sjL///vtqjnbjdm0khIh/o3OaN29ujNtGs2jjPGwjbRq6Zs2aqdu089k2LkQbb2Ab56KNgPnqq6/UnA8//NAYv//++9WcAwcOGOO2kQza+WQ7n7VteXl5as7+/fuNcdtaGzRokM/7CQkJMca1cRUi+vujjdKw7Qd1k+17U/se8GfkmG3MykMPPeTT/kX00SybN29Wc9544w1jfNy4cWpOTY5tmThxorqtU6dOxrhtTJlt5JO/+MUPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxR7a5ef7pg/aHtx9Y16E+3rT/HrXW0Pvnkk2rOf/zHfxjjtk6dZcuWGeO2m81r3cMdOnRQc7SbP+/evVvN0boTbTdnnzlzpjFeWFio5hQVFRnjq1atUnOuueYaY/zzzz9XcxqK1q1bG+OdO3dWc7T32MbWHaoJDQ01xm1dozfddJMxnpCQoOZs27bNGLd1oGrnoO290brEW7RooeZo67Bp06Zqzvr1643xpKQkNadx48bGuO31aJ+Pje27CNVnu65p/Ll2+XONHDNmjLpNW5/Hjx9Xc/7+978b4xs2bFBz+vbta4yvWbNGzdG+C1988UU1Z+7cuT7vR9OlSxd1m3Zt1SYfiIi0bNnSGN+yZYtvB/Yd/OIHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHBEnRvnoj1fTe9Hu1nyf/3Xf6k5w4YNM8Y3bdqk5owcOdIYz8zMVHNuuOEGY7xr165qjnbjeFt7vTaaw9ZafujQIWNcu5m2iMhTTz1ljD/33HNqzmuvvWaMN2vWTM2ZMGGCMa6N+WhI2rZta4wHBQWpOdqNyW1jdrSxEFFRUWqOdrP3rKwsNWfPnj3G+KlTp9Qc7Tvi2LFjak6jRo2McX9GnGgjlUREdu3aZYzbxjppY1tsY3C0tauNoBHRR7OkpaWpOf/85z/VbfWJP9e1wMCa+73EnzErNomJicb4jTfeqOZMnjzZGF+9erWas3btWmN8+/btao52zb3tttvUHG192kYaaev99OnTas4999xjjGvXfBF9FJPt2n7ixAljPCIiQs1p3ry5us1f/OIHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI4I8KrZLuvPzaT9ER0dbYxrNzkXEbnllluM8euvv17N6d69uzFu60qaN2+eMd67d281R+uMGjp0qJqjdUjauhO1z8efrjGt21NEPzatc1NEJDw83BjPz8/37cDEfh5qr3XcuHFqzldffeXzMVxs/qy1IUOGGONTpkxRc2JjY41xrUNcRO92DQkJUXO0z8XWaZqTk2OM2zpata8y23mmdcEePXpUzdHWgK2DWvtes73X2rqx7UfbZluf2vvWrVs3Neemm24yxpcvX+7zfi6l2rqu1STbde2xxx4zxr/44gs1R1trtmuhdj22nZtah65tTZ85c0bdpklOTjbGtSkWIiIHDx40xm0TDgoKCoxxba2L6N+52mcgor8/r776qppjm+Yhwi9+AAAAzqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABH6P3N1TRmzBh127/9278Z47YRI9oIAdu4iN27dxvjtlEJ69evN8ZtIwe+/fZbY/zqq69Wc+69915jfMeOHWqONrbFnzEONv6M5tBGcNj2r90E3rYfbQSH7fPR9mNrr28oPv74Y2PcNvph1KhRxrhttIB2g3rbaBZt7IFtzIo2MsU2pkAbQ2Q7Z1JTU41x2zlz+PBhY9w2lkJ7D2xjVhISEoxx2/entg6191PEv5Em2s3mXZaenq5uS0tLM8bj4uLUHO2c0c5ZEZFZs2YZ47Y1kJSUZIy3b9/e5xztO1hEf63aKBXb82nvp4jIgQMHjHFtlIqISGJiojGujaAREcnLyzPGbd9R2uuxrU/te0UbRVUd/OIHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6odldvp06djPHbb79dzdE6AG2dP6tWrTLGbV1JWvduZGSkmqN1GGndPSIiP/rRj4xxW1ec1r1rez22m0n7mmN7r7WOQq07UsS/7mHt+WyvU+tYst20OyIiwhjXupddMH/+fHXbnXfeaYzbPmNtrZ08eVLN0T6XoqIiNWfnzp3GuG19at83tu5h7YbutnVz+vRpY9z2HmjnoHazexG908+2H+17xfZ948+aPnr0qM85dZF2Pl1xxRVqjvZZ2rpGNbbJE9rUg71796o5TZs2NcZt3anh4eHqNo3WWW7rbM/NzTXGtWMW0de07b3W1o32XCL6Z1pYWOjzsWnfKSL6xA7t+05EJD4+3hjXuoqrg1/8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOqPbckFtuucUYt91k2p+bC2tjFGwjRrSWeNuN1rVRErYxDm3atDHGbSMmsrOzjXHbCBjtPbWNJdFG19hGpmjjAmw5Whu/9lwiIocOHTLGbe/Bvn37jHHbZ9q1a1djXGuhd8GePXvUbcXFxca4beyB9jmfOnVKzdFGiWhjCkT0z+zw4cNqjrYGbKMStJEItjEOBQUFxnjr1q3VHG1khm0/2s3ebTd0147NpkmTJsa4ttZFRHJycnzeT13UvHlzY7xv375qTlZWljFuG6+hXaNsI42062SzZs3UHO06aRvZon0P23K0z18b2WJjO89SUlKMcdt1ICkpyef9+DM+TGMbH5WRkWGM20batG3b1hi/8sorfTuw7+AXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRLW7et98801j3NaVpHX62W5irN203Hbz5/T0dGPc1mmqdSzZbmatdevYuka1zklbZ7P2fLb9aN3DWlxE7xq0dRpqN6i3dUNrr9XWmVVeXm6MnzhxQs3RzsVvv/1WzWnorrrqKnWbdqPzo0ePqjla56xt3Wjnk617PDU11Ri3dQ9r613rWhXROwBtHed79+41xm2TB7TXatuP9j1p67rW1o2tg1o7Bq0b27af+mbTpk3GuNZJKSJy9dVXG+O273Tte9P2faaxdadq1xtbJ7j2PaB11Iro61NbTyL6d4S2fxF9woXtvQ4KCjLGbetTmzyhfW4ieg1h+0y170/btXDHjh3G+IYNG9ScC+EXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAIwI8W8/+dx+otPxrNx0W0dvetRtWi+g3Yd+3b5+ao42LsL00rRXbNl5Ba5W33ZxbOwbbfnx9Ln/5cwz+sI2f0GjjB2yjObp3726M7969W81ZtWqVbwdWC2ryc1m0aJG6rV27dsa47XzWRqbYcrQxCrabmWvjGrQ1aGPL8Wc/2mu13dReG+diWxvaKAvbGBxtlIUtR9vWvn17NUd7rbb3raa/v2qCP2tNe4/79eun5vTo0cMYt33+2jgf2+gkbeyZbVyI9vnbRqZoI2Vs40+00WIHDhxQczIzM43x7du3qzna89m+b7RttnNWu0bZxqFp55tt7Jo/LrTW+MUPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABzxvbt6/WG7kfN1111njEdERKg52jbbjcltN2zWaJ1R/tw0vaioSM0pLS01xkNDQ9Ucf25MrX2m2nOJ6B1gWreniN4BZusAPHPmjDFuuzm81k01f/58NSc3N1fddqnU5FqzLe9du3b5/HzaTcZtNybX1octRzuftLUhYl9TGq1z0XY+ax2Ats5J7Vy3fT7aerd9F2przdbVq3XotmnTRs3ROo5t66mhdPX6c276Q/uctc9YxL8JCv4ct7Yf2/ezlqN9p4joHcyxsbFqjvaZ2rrutevNyZMnfd6P7bqmvQe2tXbllVca47ZO4HfeeUfdJsIvfgAAAM6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1yScS5AXdFQRkxo4wBWrFih5mhjSWxjD7TRD7b3URthYLuZeUFBgTFeUlKi5mjHoD2XiP5e28ZSaGNjbCNTtLExthxtbIht1Iw2vikmJkbN0T7v1q1bqzktW7Y0xjMzM9WchrLW/KF9ztp5IaKf67YcbcyJ7XzWxhDZPi/te8A2TkYbmWJbA9p+bJ+bdj7bRptpo5Ns31EZGRnGeK9evdQc2/exRvueto3jutBa4xc/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHCE3k4DoN7QbnSu3ehdRO8atN20Xeums3XMafuxdRpqnX5BQUFqjtZRaOtS1m54r8VF9K5a2/tm68StSf50qWrHffjwYTUnLS3NGLd19bpMWx+2daOxnWda56zN0aNHfc6BSHZ2tjG+YcOGWj4S3/GLHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEYxzARqAoqIiY9w2lkQbc5Kbm+tzjj9jKWw3EtdGvdjGlWiv1bYf7Yb3trEx2nutPZeN7ab22kgb23tgG/Xh635sY3D8ea0A6gZ+8QMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR9DVCzQAWieudiNxEZHo6GhjvEmTJmqO1lFq6+rVOnS1uIh+3CUlJWqOxtaBqnW02oSGhhrjto5a7X2zdej6Q+vEtXUpa5+D1r0sIpKTk+PbgQGoM/jFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCMa5AA2ANhYkKSlJzfE8zxjPz89XcwIDzf+uaBuLUlhY6HNOYmKiMW4bMaKxjY3RjkF7nbbns4200T6fmt6PNrZFG0EjIhIfH2+M/+Mf/1BzNm3apG4DULfxix8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOCLA01r7zn1gDd9MHKgLqnn616qaXGt33XWXum3WrFnGeHFxsZpz5MgRY7y0tFTNqaioMMYjIiLUnPT0dJ/2L6J3Au/atUvN0bpqo6Ki1Bytq1brqLXtx9ZtGxISYozbzo+SkhJj/NixY2qO9p5OmzZNzfn888/VbZqGvtaAuuJCa41f/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjmCcC5zm8oiJW2+91RgfP368mjN48GBj/NChQ2pOYWGhMd6qVSs1JzY21hjPy8tTcxoabQRMeHi4mlNUVGSMayN1apPLaw2oTYxzAQAAgIhQ+AEAADiDwg8AAMARFH4AAACOoPADAABwBF29cBqdhr7Rum3vuusuNadDhw7G+NatW9WcN954w7cDQ43TuopF/OsSZq0BtYOuXgAAAIgIhR8AAIAzKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOKLa41wAAABQv/GLHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwuwi2bNkiY8eOlZYtW0p4eLhER0dLt27dZPr06XLixImLss8vvvhCnnzySTl16tRFeX7gYgkICKjW/1asWHGpDxVoMGpi3S1cuFD69+8vqampEhYWJqmpqdKnTx955plnztvXQw89dMFjmjNnjgQEBEhmZma1XsOMGTNkzpw51Xos/l+A53nepT6IhuSNN96QBx98UNq2bSsPPvigdOjQQUpLS2X9+vXyxhtvSJcuXeSjjz6q8f0+//zz8otf/EL27t0rLVq0qPHnBy6Wf/7zn1X++Ve/+pUsX75cli1bViXeoUMHiY2Nrc1DAxqs77vuZs6cKePHj5dhw4bJyJEjJSEhQfbv3y9ffPGFrFu3TtavX1/52ICAAPnJT34if/jDH6zHdPz4cdm9e7dceeWVEhYWdsHX0KlTJ0lKSuJfCn0UfKkPoCFZvXq1jB8/Xn7wgx/I3/72tyon7g9+8AOZNGmSLFiw4BIeIVD3XH/99VX+OTk5WQIDA8+Ln6ugoEAiIyMv5qFdFPX1uNGw+Lvuzpo2bZrceOON8v7771eJ33333VJRUeHXMSUnJ0tycvIFH8ca+n74T7016Le//a0EBATI66+/bvy3ldDQULn99ttFRKSiokKmT58u7dq1k7CwMGncuLHcc889cuDAgSo5ixcvliFDhkhaWpqEh4dL69at5YEHHpDs7OzKxzz55JPyi1/8QkREWrZsyX8aQ4PTp08f6dSpk3z22WfSo0cPiYyMlP/4j/8QEZF9+/bJqFGjpHHjxhIWFibt27eXF154ocrFZ8WKFcY1kZmZKQEBAVX+c9GePXtkxIgRlf/5KiUlRfr16yebNm2qkjt37lzp3r27REVFSXR0tAwYMEC+/PLLKo8ZM2aMREdHy1dffSX9+/eXmJgY6devX42+N8ClkJOTI02bNjVuCww0lxZvv/22tG/fXiIjI6VLly4yb968KttN/6lXW/stWrSQbdu2ycqVKyuvefzXrurhF78aUl5eLsuWLZOrrrpKmjdvfsHHjx8/Xl5//XV56KGHZNCgQZKZmSn/9V//JStWrJCNGzdKUlKSiIjs3r1bunfvLvfdd5/ExcVJZmamvPjii9KrVy/56quvJCQkRO677z45ceKEvPLKK/Lhhx9WLsYOHTpc1NcM1KbDhw/LqFGj5JFHHpHf/va3EhgYKMePH5cePXpISUmJ/OpXv5IWLVrIvHnz5Oc//7ns3r1bZsyY4fN+brvtNikvL5fp06dLenq6ZGdnyxdffFHl72d/+9vfyuOPPy5jx46Vxx9/XEpKSuS5556TG264QdauXVtl7ZWUlMjtt98uDzzwgEyZMkXKyspq4u0ALqnu3bvLBx98IE8++aQMHTpUOnXqJEFBQerj58+fL+vWrZOnn35aoqOjZfr06TJ06FDZvn27XHbZZdZ9mdb+5MmTZfjw4RIXF1e5zqvzn4chIh5qxJEjRzwR8UaMGHHBx37zzTeeiHgPPvhglfiaNWs8EfF++ctfGvMqKiq80tJSLysryxMR7+OPP67c9txzz3ki4u3du/d7vQ7gUhs9erQXFRVVJda7d29PRLylS5dWiU+ZMsUTEW/NmjVV4uPHj/cCAgK87du3e57necuXL/dExFu+fHmVx+3du9cTEW/27Nme53ledna2JyLe7373O/X49u3b5wUHB3s//elPq8Tz8vK8Jk2aeD/60Y+qvBYR8WbNmlWt1w5cKqZ1Z7Nr1y6vU6dOnoh4IuJFRER4/fr18/7whz94JSUlVR4rIl5KSoqXm5tbGTty5IgXGBjoTZs2rTI2e/bs865j2tr3PM/r2LGj17t37+q/SHie53n8p95LYPny5SLyr/8M9F3XXnuttG/fXpYuXVoZO3bsmPz4xz+W5s2bS3BwsISEhEhGRoaIiHzzzTe1dszApdaoUSO56aabqsSWLVsmHTp0kGuvvbZKfMyYMeJ53nl/qH4hCQkJ0qpVK3nuuefkxRdflC+//PK8v1dauHChlJWVyT333CNlZWWV/wsPD5fevXsb/8Ri2LBhPh0HUBd4nlflHP/ur9WtWrWSzZs3y8qVK+Wpp56Sm2++WdatWycPPfSQdO/eXYqKiqo8V9++fSUmJqbyn1NSUqRx48aSlZV1weMwrX34j8KvhiQlJUlkZKTs3bv3go/NyckRETH+fURqamrl9oqKCunfv798+OGH8sgjj8jSpUtl7dq1ld1YhYWFNfgKgLrNtF60vzNKTU2t3O6LgIAAWbp0qQwYMECmT58u3bp1k+TkZHn44YclLy9PRESOHj0qIiLXXHONhISEVPnf3Llzq/z9rYhIZGQk3ciol956663zzvHvCgwMlBtvvFGeeOIJ+eSTT+TQoUNy5513yoYNG2TWrFlVHpuYmHje84eFhVXrOqb9LSH8w9/41ZCgoCDp16+f/O///q8cOHBA0tLS1MeeXQCHDx8+73GHDh2q/Pu+rVu3yubNm2XOnDkyevToysfs2rXrIrwCoG4LCAg4L5aYmCiHDx8+L37o0CERkcq1FB4eLiIixcXFVR53bpEmIpKRkSF//OMfRURkx44d8t5778mTTz4pJSUlMnPmzMrnfP/99yt/fff1uIH6YPDgwbJu3bpqPz4qKkoeffRRmTt3rmzdurXGjoM1VLP4xa8GPfroo+J5nowbN05KSkrO215aWiqffvpp5U/Wf/7zn6tsX7dunXzzzTeVXX9nT/Zz/2D1tddeO++5zz6GXwHhkn79+snXX38tGzdurBL/05/+JAEBAdK3b18Rkcpuvy1btlR53CeffGJ9/jZt2sjjjz8unTt3rtzHgAEDJDg4WHbv3i1XX3218X9AQ5CYmKie26Z/4RL5/z9BOvur+8VU3V8MURW/+NWg7t27y6uvvioPPvigXHXVVTJ+/Hjp2LGjlJaWypdffimvv/66dOrUST766CO5//775ZVXXpHAwEC59dZbK7t6mzdvLhMnThQRkXbt2kmrVq1kypQp4nmeJCQkyKeffiqLFy8+b9+dO3cWEZGXX35ZRo8eLSEhIdK2bdsqf1MBNDQTJ06UP/3pTzJw4EB5+umnJSMjQ+bPny8zZsyQ8ePHS5s2bUREpEmTJnLzzTfLtGnTpFGjRpKRkSFLly6VDz/8sMrzbdmyRR566CH54Q9/KJdffrmEhobKsmXLZMuWLTJlyhQR+VcR+fTTT8tjjz0me/bskVtuuUUaNWokR48elbVr10pUVJQ89dRTtf5eALWpY8eO0q9fP7n11lulVatWUlRUJGvWrJEXXnhBUlJS5N57773ox9C5c2d59913Ze7cuXLZZZdJeHh45bUQFpe2t6Rh2rRpkzd69GgvPT3dCw0N9aKiorwrr7zSe+KJJ7xjx455nud55eXl3rPPPuu1adPGCwkJ8ZKSkrxRo0Z5+/fvr/JcX3/9tfeDH/zAi4mJ8Ro1auT98Ic/9Pbt2+eJiDd16tQqj3300Ue91NRULzAw0NjBCNQHWldvx44djY/PysryRo4c6SUmJnohISFe27Ztveeee84rLy+v8rjDhw97w4cP9xISEry4uDhv1KhR3vr166t09R49etQbM2aM165dOy8qKsqLjo72rrjiCu+ll17yysrKqjzf3/72N69v375ebGysFxYW5mVkZHjDhw/3lixZYn0tQF3k67n62muveXfccYd32WWXeZGRkV5oaKjXqlUr78c//vF51zER8X7yk5+c9xwZGRne6NGjK/9Z6+rV1n5mZqbXv39/LyYmxhMRLyMjo9rH7zJu2QYAAOAI/sYPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHVPvOHdwrzz933XWXMd69e3c1R3uvN2zYoObMmTPHp+PCv9TFMZaurLUOHTqo29566y1j/PPPP1dzgoKCjPHS0lI159x7955lOy/Ky8vVbZpzb7t41uTJk31+rvqKtVY33Xrrrcb4tddeq+asX7/eGLetDe3zr6ioUHMGDBhgjH/22WdqzoVuw1hTtHOnLpznFzoGfvEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEcEeNVsQaH7Sbdq1Sp1W6dOnYzxvLw8NUfrTmzSpImas2XLFmP8yiuvVHNQNzqwzuXKWps+fbq6bfTo0cb4sWPH1Jzk5GRj/MyZM2pObm6uuk2jdS7aPjdtW69evdScwsJC3w6sjmOt1YzAQP33mh49ehjjd9xxh5ozceJEY9y21g4dOmSMFxUVqTlaZ3tcXJyao2ncuLG67f777zfGFyxYoOacPHnS52PQ2M6p2loDdPUCAABARCj8AAAAnEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARdW6ciz83PtZytLEoIiJlZWW+HZiFNkpFRCQqKsrn/Ws3rY6MjFRz9uzZY4z37dtXzdHYxgVo77U/N66vCxgxcens3LlT3bZ3715jPD8/X81JTEw0xk+cOKHmaGMpbOeFNjZm//79Ph/bG2+8oeb84x//ULfVR6w132hjVu677z41p6SkxBiPiIhQc7QRLLbrTaNGjYxx23VAu67Z5OTk+Lyf2NhYY/zw4cNqzueff26ML1q0SM1ZunSpuu1SY5wLAAAARITCDwAAwBkUfgAAAI6g8AMAAHAEhR8AAIAjgi/1AZxL60bx5wboNdm5KyIyaNAgYzw+Pl7N8efYtPfA1m2rdQ+npqaqOVpHoz/dV7YO6vra8YuaoZ23tnNz8+bNxnhISIiaEx4eboynpaWpOVrX4KlTp9QcrUP3wIEDao62BmzHhobv5z//ubrt3nvvNca1zl0R/XqTl5en5mjr09ZBf+bMGXWbRrtG2DpQ/akHCgsLjfGkpCQ1Z/DgwcZ4+/bt1Ryt6/nTTz9Vc+oKfvEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiizo1z0dq0/Wn5TklJUXO0G11rI1tERDp06GCMl5aWqjlaS7xt/IlGa1MX0VvVDx48qOasWLHCGP/www/VnFdeecUYt41s8edG6HXxhu7wz7XXXutzjjbuyLbWsrOzjfHLL79czdHW4YkTJ9Qc7dxMSEhQc7SxMXFxcWoOGo7mzZsb48OGDVNztHO9uLhYzQkONl/S/Rm3ZRs5pu3HRtuP7fqgjZqx5Wj7KSoqUnO090e75ouI/OIXvzDGFy1apObYPrvaxC9+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIOtfV6083580332yMP/3002qOdoNlrYtIRGTHjh3GeEFBgZrTpk0bY9zWoat1c9k6GrXj/vLLL9Wcxo0bG+MPPfSQmvOjH/3IGP/JT36i5mzZskXdhobvqquuMsZtXYPa+RwSEqLmaN18to7z1NRUY/z48eNqjtY9HBMT43OOP939qH/GjBljjGvTGET064rtGqWxdcFq56A/56Y/0zdsKioqjHHbe6BtCw0NVXO0a6vtOh0bG2uMDx8+XM35y1/+om6rTfziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJ0b5+KPyZMnG+NRUVFqjnaT6YiICDVnxYoVxrg2EkJEpF27duo2TVhYmDFuuzG2P633Wqt8SUmJmqPdiP75559Xc/r37+/bgaFB0cYt2UZM+ENbN7a10aRJE2P8zJkzao42hsa2H+074tixY2oO6pdu3bqp2zp16mSMa9/BIvroIttYL210UW2NDbKtaW3Mii1HGwFjGwWlXSdt75v2XttGwGjH1q9fPzXn/fffN8aLi4vVnIuBX/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBH1pqv3lltuUbelp6cb47bOH62Lx3Yj6bFjxxrjtm4hrWvPth+tM8v2erSuLVvXmNZJpL03IiJFRUXGePv27dWcvn37GuPLly9Xc9BwLFmyxBi3dc5qXbAnT55Uc7R1Y+vu19ZudHS0mqOtG9uN47W168+N61E3hYeHq9u6du3q8/Np52ZcXJyao62pmr4WamzXG2192rp6tW22CRfafuLj49Uc7flyc3PVHO2a27NnTzXnnnvuMcbfeOMNNedi4Bc/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAj6s04l4EDB6rbtBZy2w2WNQUFBeo2bTSLbZyLts12U+aIiAhjvKSkRM3RWsttOdqYi7y8PDVHa/23tdf37t3bGGecixu0cyYmJkbN0dZNWFiYmqONGrJJSEgwxg8fPqzmxMbGGuP79u1Tc77++mtjvLCw0HJ0qE+++OILddudd95pjL/88stqjjYiy3btOH36tDFu+37W1pptzIo2usg2zkXjzzgX23gabdyNbX1qOa1bt1Zz9u7da4y/9dZbak5tj23R8IsfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADii3nT1tm3bVt2mdbTaunq1G1CfOnVKzdG6YG1dSdoNo23dT1onru2m2VonrtYhbMvx5+bcti6r6667zufnQ8MxbNgwY7xjx45qzrJly4xxrZtQRF9Ttk79lJQUYzw1NVXNOXnypDGelpam5nTo0MEYf/7559UcNBybNm0yxrWJByIib7/9tjH+2muvqTn/+Z//aYx36dJFzTl69KgxrnXj29iuHdp1sra6ehcuXKjm/OEPfzDGbe91v379jHHtml+X8IsfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMAR9WacS+PGjdVtWgu5rU1cu9G17WbW2g2wbaNZtP3YxlL4+ly2Y9BGw9hER0f7vB9tpI6If2MB0HD8/ve/N8YffvhhNSchIcEY37Vrl5pz+eWXG+MrV65Uc/bv32+M//KXv1RztNEctrEx2racnBw1B267++67fc559tlnjXHbaDPtmme7Fmps1zXteuxPju3YtJzOnTurOdu3bzfG+/Tpo+Zo/Bk5Vdv4xQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHFFvunq1Lj8RvWPO1vmjdZqGh4erOVqHrK1TR+t2tXXBal1JthztGGw3zdbeH1snsHYD7NLSUjUnJSVF3YaGb+jQocZ4x44d1ZyNGzca47bzOS0tzRgfMWKEmtOsWTNjfOrUqWqO1iFpW58xMTHG+IkTJ9Qc1C+2KRL+sJ3rGu2729Zxrp23/kyesF0LteezvW/+5Jw6dUrdVhvqSueuDb/4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcUW/GuWhjRET0VnXbiBFtlElRUZHPObYbYGut3bZRM2FhYca47fVobe+FhYVqjjYuwDZGQHs9ttb/4uJidRsavpMnTxrjERERao52zthy8vPzjfGjR4+qObbxTRpt/IVtxISWs3//fp/3j7rJn/ErNU07n8vKytQc7bj9GUviz0gb2/umbbPtR9vmz1q30fZTF86DC+EXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRL3p6vWnY87WOVuTN9S2dbRq28rLy33eT2RkpM/7sXVmaV3C/tw02/Z6bF3PaPg+++wzY3zcuHFqjrZ2GzdurObs2rXLtwMTfSKAbd1ox2ZbN9pas3Uco+GznTM12R1ak9c7kdrrXPWnq1frYI6KiqqRY7rQMdDVCwAAgDqDwg8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHFHnxrk0atTIGLeNC9Hap0NCQmrkmM7SxjiUlJSoOf4cmzb6obCwUM3Rni8sLEzN0drRba9Hy8nNzVVztGNISkpSc7Kzs9VtqF9Wrlzpc462biIiItScDRs2+Lyf48eP+7R/Ef17wPYdZVsfQE3RRpnU1tgY23P5M1JGez7bCDVtFJPteuMafvEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEfUua7eHj16GOOhoaFqTn5+vjEeHR2t5mhdsLb9aGw3dA8KCjLGbV1JGn86mWw5WpeV7T3Q3jd/3oPExEQ1h67ehuPIkSPGeFFRkZqjnU+2bvhvv/3WtwOzyMnJUbdpXb2216N9RwE1yZ9JFtp1wJ8uXH/UdMex9t0RGxvr83M1VPziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJ0b55KWlmaM+9Nart2wWkRvey8uLvY5x592dNv4E+35bK8nLCzMGNdGqdiOwXazeX9umq0dg+2m2du3b1e3oWHwZ92UlpaqOSdOnPjex3TWrl271G3p6enGuO312NYU3FXTo0wSEhKMcdt1rSZHi9mO2Z/X48+oGe07IisrS81p3ry5Mb5//37L0ZnV9Gd6MfCLHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4os519SYnJxvjtm4YrWPJ1tGqdej6c5NrG63Dx9blFxERYYzbjk27CbzW7Suivz/aTehF7N1hmoyMDGO8tm4CjrrJdm5GR0f7/Hy2TnlfrVu3Tt3Wpk0bYzw+Pl7N4VxHbWjSpIkxvnv3bjXHn65e7XpcF7pWtWOwfd906NDBGLd19Wrvm236Rl3BL34AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEfUuXEu2k2mbeNPtG22tmotxzYCpqSkxBi3jWoIDQ01xm2jJ7Tj1p7Lts32HmjbYmNj1RxtpExBQYGao9FG98ANhYWF6raYmBhj3DZ6Iikp6Xsf01mbN29Wt919993GuG0Mkm2UBNzlz5ifFi1aqNsOHjxojNvGrGhrqi6PZrHR3lPbe92uXTtjfOHChWpOTY6Pqm384gcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqhzXb2JiYnGuK07VetK0joDRfTu3aKiIjUnKirKGNe6fW3H5s+NnG052rHZuqK0rsrS0lI1R7sRva3DSXu+lJQUNQcNX1ZWlrotMjLSGLettVtvvdUYf/vtt307MBHJzMxUt2nnuq3j2Pa9Aviiffv26jZt6kJ+fr6aY5tk4aua7MIV8a/jWFuftmtUr169jPGXX37Z5/3UB/ziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJ0b5+LP+BOthb28vFzNyc3NNcZr+sbUWqu8rYVeO27bKAvt+UJDQ9UcrY3e1qYeHh5ujJ85c0bN0d7rZs2aqTlo+DZv3qxu69mzpzF+6tQpNeeyyy77vodUKTk5Wd2mrTXbOBfAxJ/rzRVXXFGj+9GuA/7k2EazaM/nz3vgT47t+tmpUyefn0/jz3tQ2/imAgAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABH1Lmu3qioKGPc1qGr5Rw5ckTN0boD09PT1ZzCwkJjXOsqtuXYOmcjIiKMcVtHo9axlJKSouZERkYa47auJO3YSktL1RztBvW29xoN38aNG9VtN954ozFuWzfx8fHf95AqHT9+XN2mfRfZOvVtUwngLtv5rLnuuuvUbVrXqO36qbFdBzT+dLb70+lqOzZ/JoNkZGT4fAy+7l/Ev8/hYuAXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI+rNOBebuLg4Y3zbtm1qTqNGjYzx0NBQNUcbmWJrRw8LCzPGz5w5o+ZoLd/a6xQROX36tDF+8uRJNScmJsYYt7Wja++BrVVey6nJ8Ruof1atWqVue/jhh41x28gUbTyRP/bs2aNu085123fHwYMHv/cxof7Sxo/4M8rENgZLGw8THKxf6v0Z21Ibz1XTx2AbnXPgwAFjvGnTpmrO4cOHjXF/PtPaxi9+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIOtfVqykuLla3aV2o4eHhao7WUWrbj9YtZOto1XJsnbNFRUXGuNYhLKJ3/Nq6h3Nzc43x2NhYNae0tNQYt3Vbaq/V1gWJhm/9+vXqtv379xvjSUlJas7OnTu/9zGdZTuf/enaW7ly5fc5HKBSYmKiuq2goMAYt11vtPO5tjp0bcemsXXoas+nXbtE9GveZZddpuZoXb2212M77trEL34AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEfUuXEu2hgF2wgFbWSJrRVbG8FiG82itWLb2rdDQkKMcdsN5bVxLlrctq28vFzN0Uba2MbgFBYWGuO28RclJSXGuO3G4XDb2rVrjfE777xTzdHOZ9sImOzsbGPcNtJIO29to6BWr16tbkPDp41G8Wc00L59+9RtycnJxrjt+7kmx7b4M5qltmjXYhGRkydPGuO262d9Vnc/JQAAANQoCj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqhzbZVaV5Ct21brStI6nERE8vLyjPFTp075vB9bx5R2Y2jbDaO1TiJbV1JERIRPzyWiv9e2/Wifgy1H63bUbiiOhkXrgrWt6VdeecUYHzp0qJqjdcq3aNFCzdG6ehs1aqTmaJ2Yhw4dUnMyMzPVbYAvwsLC1G3aBAXbdUCbVuFPt29Ndgj7ux/tumbroNamVWiTAmz86dSubfziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJ0b51KTbdWrVq1St7Vu3doYb9mypZqzY8cOY9w2zkUbZWG7mbU25sI2/sKfm2NrLf5paWlqzoQJE3yKi4ikpqYa41u3brUcHRoKf250npWVZYxv375dzbnuuuuM8a5du6o569evN8YTEhLUHG1szK5du9QcoKZo57mIyP79+41xbcyLiEh6eroxro15EdFHlthGmWjbanoEjHY91t4bEb0e6NKli5qzYMECY7y2Rtp8H/ziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOqHNdvTNnzjTGT5w4oeZo3aHPPvtsjRzThYSGhqrbbN2BGq1719a5q3VMHT9+3Of9+8N2g/oBAwYY4x988MHFOhzUITV50/K3335b3aZ1D69evdrn/fzjH/9Qt82bN88Y17r8bGwdgPXhZu+oHluHrK8uv/xydVvnzp2N8fDwcDUnJibGGLdNqwgLCzPGtSkWIvq5blsD2jbb+5mbm2uMFxcXqznaNffPf/6zmqOpyc/6YuEXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAIwI8ZgYAAAA4gV/8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIXf9zBnzhwJCAio/F94eLg0adJE+vbtK9OmTZNjx45d6kMEGqQ1a9bI0KFDJT09XcLCwiQlJUW6d+8ukyZNqnxMixYtZNCgQRd8rhUrVkhAQICsWLGiWvt+55135He/+52fRw7UHdVZR7UlMzNTAgICZM6cOT7n+rqGXUfhVwNmz54tq1evlsWLF8t///d/S9euXeXZZ5+V9u3by5IlSy714QENyvz586VHjx6Sm5sr06dPl0WLFsnLL78sPXv2lLlz5/r8fN26dZPVq1dLt27dqvV4Cj80BDW9jlB/BF/qA2gIOnXqJFdffXXlPw8bNkwmTpwovXr1kjvuuEN27twpKSkpxtyCggKJjIysrUMF6r3p06dLy5YtZeHChRIc/P9fYSNGjJDp06f7/HyxsbFy/fXXX/BxrFU0JDW9jlB/8IvfRZKeni4vvPCC5OXlyWuvvSYiImPGjJHo6Gj56quvpH///hITEyP9+vUTEZGSkhL59a9/Le3atZOwsDBJTk6WsWPHyvHjx6s877Jly6RPnz6SmJgoERERkp6eLsOGDZOCgoLKx7z66qvSpUsXiY6OlpiYGGnXrp388pe/rL0XD1xEOTk5kpSUVOVidVZg4PlfaQsWLJBu3bpJRESEtGvXTmbNmlVlu+k/E2lrtU+fPjJ//nzJysqq8mceQH1T3XU0d+5c6d+/vzRt2lQiIiKkffv2MmXKFMnPz6+Sc3bN7Nq1S2677TaJjo6W5s2by6RJk6S4uLjKYw8dOiQ/+tGPJCYmRuLi4uTOO++UI0eOnHcc69evlxEjRkiLFi0kIiJCWrRoIXfddZdkZWXV0LvgJn7xu4huu+02CQoKks8++6wyVlJSIrfffrs88MADMmXKFCkrK5OKigoZMmSIrFq1Sh555BHp0aOHZGVlydSpU6VPnz6yfv16iYiIkMzMTBk4cKDccMMNMmvWLImPj5eDBw/KggULpKSkRCIjI+Xdd9+VBx98UH7605/K888/L4GBgbJr1y75+uuvL+E7AdSc7t27y5tvvikPP/yw/Pu//7t069ZNQkJCjI/dvHmzTJo0SaZMmSIpKSny5ptvyr333iutW7eWG2+80bof01pNS0uT+++/X3bv3i0fffTRxXh5QK2o7jrauXOn3HbbbfKzn/1MoqKi5Ntvv5Vnn31W1q5dK8uWLavy2NLSUrn99tvl3nvvlUmTJslnn30mv/rVryQuLk6eeOIJEREpLCyUm2++WQ4dOiTTpk2TNm3ayPz58+XOO+88b9+ZmZnStm1bGTFihCQkJMjhw4fl1VdflWuuuUa+/vprSUpKujhvTkPnwW+zZ8/2RMRbt26d+piUlBSvffv2nud53ujRoz0R8WbNmlXlMX/96189EfE++OCDKvF169Z5IuLNmDHD8zzPe//99z0R8TZt2qTu76GHHvLi4+P9fUlAnZedne316tXLExFPRLyQkBCvR48e3rRp07y8vLzKx2VkZHjh4eFeVlZWZaywsNBLSEjwHnjggcrY8uXLPRHxli9fXhnT1qrned7AgQO9jIyMi/LagNpS3XX0XRUVFV5paam3cuVKT0S8zZs3V247u2bee++9Kjm33Xab17Zt28p/fvXVVz0R8T7++OMqjxs3bpwnIt7s2bPVYy4rK/POnDnjRUVFeS+//HJl3LSGoeM/9V5knuedFxs2bFiVf543b57Ex8fL4MGDpaysrPJ/Xbt2lSZNmlT+J6iuXbtKaGio3H///fLWW2/Jnj17znvua6+9Vk6dOiV33XWXfPzxx5KdnX1RXhdwqSQmJsqqVatk3bp18swzz8iQIUNkx44d8uijj0rnzp2rnPNdu3aV9PT0yn8ODw+XNm3aVPs/FZ27VoGGorrraM+ePTJy5Ehp0qSJBAUFSUhIiPTu3VtERL755psqzxkQECCDBw+uErviiiuqrLfly5dLTEyM3H777VUeN3LkyPOO8cyZMzJ58mRp3bq1BAcHS3BwsERHR0t+fv55+0b1UfhdRPn5+ZKTkyOpqamVscjISImNja3yuKNHj8qpU6ckNDRUQkJCqvzvyJEjlQuwVatWsmTJEmncuLH85Cc/kVatWkmrVq3k5Zdfrnyuu+++W2bNmiVZWVkybNgwady4sVx33XWyePHi2nnRQC25+uqrZfLkyfI///M/cujQIZk4caJkZmZW+cP0xMTE8/LCwsKksLDwgs9vWqtAQ2NbR2fOnJEbbrhB1qxZI7/+9a9lxYoVsm7dOvnwww9FRM5bR5GRkRIeHl4lFhYWJkVFRZX/nJOTY2x2bNKkyXmxkSNHyh/+8Ae57777ZOHChbJ27VpZt26dJCcnV2sNw4y/8buI5s+fL+Xl5dKnT5/KmOkPwZOSkiQxMVEWLFhgfJ6YmJjK/3/DDTfIDTfcIOXl5bJ+/Xp55ZVX5Gc/+5mkpKTIiBEjRERk7NixMnbsWMnPz5fPPvtMpk6dKoMGDZIdO3ZIRkZGzb5IoA4ICQmRqVOnyksvvSRbt26tkeekaQOuOXcdLVu2TA4dOiQrVqyo/JVPROTUqVN+7yMxMVHWrl17Xvzc5o7Tp0/LvHnzZOrUqTJlypTKeHFxsZw4ccLv/YNf/C6affv2yc9//nOJi4uTBx54wPrYQYMGSU5OjpSXl8vVV1993v/atm17Xk5QUJBcd9118t///d8iIrJx48bzHhMVFSW33nqrPPbYY1JSUiLbtm2rmRcHXEKHDx82xs/+p5/v/sJ+MVT3F0OgLqvOOjr7Lz9hYWFVHnN2UoU/+vbtK3l5efLJJ59Uib/zzjtV/jkgIEA8zztv32+++aaUl5f7vX/wi1+N2Lp1a+Xf5R07dkxWrVols2fPlqCgIPnoo48kOTnZmj9ixAj5y1/+IrfddptMmDBBrr32WgkJCZEDBw7I8uXLZciQITJ06FCZOXOmLFu2TAYOHCjp6elSVFRUOZri5ptvFhGRcePGSUREhPTs2VOaNm0qR44ckWnTpklcXJxcc801F/29AC62AQMGSFpamgwePFjatWsnFRUVsmnTJnnhhRckOjpaJkyYcFH337lzZ/nwww/l1VdflauuukoCAwOrzPEE6oPqrKPU1FRp1KiR/PjHP5apU6dKSEiI/OUvf5HNmzf7vd977rlHXnrpJbnnnnvkN7/5jVx++eXy97//XRYuXFjlcbGxsXLjjTfKc889J0lJSdKiRQtZuXKl/PGPf5T4+Pjv+erdRuFXA8aOHSsiIqGhoRIfHy/t27eXyZMny3333XfBok/kX7/effLJJ/Lyyy/L22+/LdOmTZPg4GBJS0uT3r17S+fOnUXkX3+ovmjRIpk6daocOXJEoqOjpVOnTvLJJ59I//79ReRf/yl4zpw58t5778nJkyclKSlJevXqJX/605+qdSxAXff444/Lxx9/LC+99JIcPnxYiouLpWnTpnLzzTfLo48+Ku3bt7+o+58wYYJs27ZNfvnLX8rp06fF8zxjExdQl1V3Hc2fP18mTZoko0aNkqioKBkyZIjMnTu32ne6OVdkZKQsW7ZMJkyYIFOmTJGAgADp37+/vPvuu9KjR48qj33nnXdkwoQJ8sgjj0hZWZn07NlTFi9eLAMHDvzer99lAR7fWAAAAE7gb/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHBEtQc4u3LfynNvD/NdI0eONMa/ewPqc+3cudMYP3jwoJqTk5NjjF922WVqzrhx44zxLVu2qDmff/65Mb579241p6Gpi2Ms6/Ja046ttt7Hdu3aqdu+ey/R7zp27Jias2/fPmM8MTFRzdEGoe/atUvNWbNmjbqtJl3qz8emLhzDueryWgP8daG1xi9+AAAAjqDwAwAAcASFHwAAgCMo/AAAABwR4FXzL24b2h/Bvvnmm8Z4dHS0mhMeHm6MFxYWqjmhoaHGeFZWlprTvHlzY9z2h+1JSUnG+PLly9WcyMhIY7ysrEzNGT58uLqtPuIPzi++xo0bG+NXXHGFmnP55Zcb4y1atFBz0tPTjfHi4mI1R3uvmzZtquZoDVtHjhxRc7T1npmZqeZoTVa2xrC6jLUG1A6aOwAAACAiFH4AAADOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4Ihq36u3odHuq9mlSxc15/jx4z7vJzU11ae4iEhGRoYx3qlTJzVn9uzZxrjtPsIlJSXGuEv36nWZP/d1jYmJMcb/7d/+Tc3RRiQFBQWpOdq2jRs3qjlLly41xuPj49Wc/v37G+NvvfWWmnPo0CFj3DZqpmXLlsZ4VFSUmtOxY0dj/MSJE2rOp59+aowXFBSoOXX5/r4Aah6/+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI5zt6t26dasx3rlzZzVH6zQ8duyYmqN11WqduyIi27dvN8ZXrFih5gQGmmv4yMhINSc0NNQYr6ioUHPgtj59+hjjWueuiMiOHTuMca1DWEQ/N4uLi/WDU5w6dUrdtmHDBmP8wIEDao7W7Zqfn6/m7Nmzxxg/c+aMmpObm2uMd+3aVc0ZMGCAMf7RRx+pOXTvAm7hFz8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCOcHeeiSU1NVbdpN4i33QReGz+xefNmn45LRCQuLk7dVl5eboxrIyFE9BvE5+Xl+XZgqJf8GeOhrY8TJ06oOdqoF9v+c3JyjHHbqKGQkBBjPCIiQs0pLCw0xm3jlg4dOmSMa8csIhIQEGCMa2tQRCQ2NtYY37Vrl5rTuHFjdRsAiPCLHwAAgDMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4wtmuXu3G7f50Op4+fVrdlpCQYIxHRkaqOUVFRT7nlJaWGuNBQUE+52gdiHBDkyZN1G0lJSXGuG3dNGrUyBjXumNF/DsHCwoKjHGt21dEXx9at6/t+QID9X+P1taa9n6KiCQnJxvj2qQAm6SkJHVbdna2z88HoP7iFz8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCOcHeeijWSwjZHQbpqel5en5mjbbDebDwsLM8bPnDmj5pSVlRnjoaGhak55ebkxnp+fr+bAbcHBvn9laOdZRESEmqONObGNTNHGnERHR6s52vPZRqZo6yMmJkbN0d4D26gZbQSMbXSO9nps+wHgFn7xAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHONvVe/DgQWO8qKhIzTl58qQxrt2EXkS/2butczYhIcEYt93QXduPratX6yzOyclRc9DwxcfHq9u09WHraD1x4oQxbus01daares+OTnZGLetG62zWOusF9E76LOzs9WcoKAgYzwyMlLN0bp6bV3KBQUFxrj2nSIicvjwYXUbgIaHX/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI5wdpzLjh07jHHbjeO1sS228SdJSUnGuHbTdhGRnTt3GuMZGRlqjnbj9tzcXDUnJSXFGLeNv0DDp50XIvq50bp1azWnZ8+exvi7776r5mhjiI4dO6bmaGzjabSRRraxTtp70LRpUzXnzJkzxrg2skVE5LbbbjPGjxw5ouZo32uNGzdWc7Zt26ZuA2qKNr7JtgY0trFO2rWwLujbt68xbluD/nznXQi/+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI5zt6tVs375d3RYcbH67bB1GWsev7ebs6enpxnhhYaGaoz2fLUfrptJu9A43xMbGqtu0blet411EpGvXrsb4jBkz1JzmzZsb41pnoI0tR+vib9Gihc/7KSsrU7c1adLEGD948KCac/XVVxvjq1evVnO0tRsdHa3mADXFtta6detmjGsd7yJ6t2ttde7aJml06NDBGLdd2zMzM41x23fHxcAvfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAARzDO5RxBQUHqNm1si3ZDeRF9BIytHT07O9sYT0pKUnPy8vJ82r+ISGCgue7XngtuaNy4sbpNG09k06VLF2O8WbNmao42EsGfsSQlJSXqNm2UhG2cy+HDh43x8PBwNUcb55Kbm6vmaONcPv/8czVHG6dhG7cD1JRWrVqp27TRRba1po2C2rRpkw9HdWGjRo0yxpOTk9WctWvXGuOdO3dWcz744APfDuwi4Rc/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEXb3nsHUtah1Ltq7BuLg4Y9x2U2atc9HWYXTkyBFjvKioSM3RaF3FaFi0LvWIiAg1R+tg155LROT11183xm1rQOtOLSwsVHM0ttdTUVFhjBcXF/u8H5uCggKf9i8iMnv2bGPc1qlfXl7ucw5QU3bv3q1uu+yyy4zxbdu2qTkdO3Y0xlu3bq3m7Nq1yxi3Td+48sorjfGWLVuqOTt37jTGp0+fruZobN+ftgkg/uIXPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI+jxP0d+fr667fTp08b48ePH1Rxtm20/2giYAwcOqDna+ImgoCA1RxsPk5mZqeag4dNGgoiIlJaWGuM333yzmjN48GBjXBvvICISFhZmjNvGuWgjS2xrQBsbo71OEX18U3x8vJqjsY1b+vWvf22ML1iwQM1ZtmyZMW57D7RttvMAl05tj/7whW3dbN++3Rjv1KmTmqONZmnRooWaEx4ebozbxqF99NFHxnhaWpqaM2/ePHWbrxjnAgAAgIuCwg8AAMARFH4AAACOoPADAABwBIUfAACAI+jqPcc333yjblu0aJExfurUKTWnadOmxnibNm3UHK0radOmTWrOnj17jHGta1FEJD093RiPiopSc2zdyKhfbF1umssvv9wY379/v5qzb98+Y9x2o3Wtc1br3LXRnktEXwPNmjVTc9atW2eMV1RUqDllZWXGeEFBgZqjvafaWhfRP5+8vDw1JzY21hg/efKkmoPz2Toz/cnRujltXZ7a813qbl8brdtXROSaa64xxm1rLTIy0hi3dRyvXr3aGPensz0wUP89zbZNo33n2b7XLoRf/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjmCcyznuu+8+dduRI0eM8ejoaDXn6NGjxnjz5s3VHO2m6Z07d1ZztJEyCQkJas7p06eNcdvohyVLlqjbUL80atTIGD9z5oya07VrV2O8SZMmao42dkAbW2RjG4egrQFtXImIvqZtN4EPCwszxouLi9UcbUSSbX1q4ydso2YyMjKM8c8//1zNSUxMNMYZ53Lx2caS+KO2xrb4M7pGOzbbmBVtvNpVV13l8/5t3zfaaCvt+8HG9pnW9OftL37xAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABH0NV7DtsNo0NCQoxx282StU4/243WtY5CW7ft8ePHfdq/iN5p2K1bNzWHrt6GQ+vMs3X1pqamGuPa+WfTtGlTdVtRUZExbuug1zrmtJu2i+idftraENHft9DQUDVH+45IT09XczQ5OTnqNu3zsXUTajeBh2/86ajVrikierdru3bt1Jz4+Hhj/J///KdPx3UxaB35tnOzsLDQGLe915s2bTLGbWu6devWxrjt+qlNRbCtJ+37xvYdpdUD7777rppzIfziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwhLN9/EFBQcZ4hw4d1JwdO3YY49roCRGRiIgIYzw/P1/N0Vr8beNctBvHa69TRKS8vNwYt40LQMORkJBgjNtGs2jjQr788kuf928bf5Kbm+tzjjZ6wTYy4+TJk8b4qVOn1BxtTZeVlfl8bBkZGWqO5uDBg+q2Nm3aGOP79+9Xc+Li4nw+hoZCG82jxUXs40c0I0aMMMZPnDih5qxYscIYf+yxx9Sc5s2bG+NPPfWUmrN8+XJ1m8af0TX+5Gjv9d69e9Wcjz76yBifOHGimrNx40Zj3Dba7KWXXjLGY2Nj1ZzExERj3DYSTht7tXbtWjXnQvjFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAc4WxXr9Ypo3W6iujdgbZOQ63Tz9b5o3XtNWnSRM3Jysoyxm0djRrbsaHh0M4NrUNcRD/Xs7Ozfd6/7cbk2s3MbZ2ztg52TePGjY1x23ugrY+CggI1R+v8t70HGm2ti4h07drVGI+OjlZzSktLfT6GhkLrNPWnA9VG6x5ftGiRmtOnTx9jvLCwUM3Rrl9aB6qIyJAhQ4xx23nmj06dOhnjb7/9tpozY8YMY9x2PicnJxvjl112mZqzcOFCYzw4WC+Rjh07Zozb3jftO9fW1at1mNvqgQvhFz8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCOcHeeSlpZmjNta5bVREraRKdqIh5iYGDVHOwbbiAmNNkZCRCQw0Fz328ZiaK/V5ZEQ9ZU2qsA2lkQ7B0+fPq3mJCQkGOO280wbb6A9l4h+rtvOTe24beNpmjVrZozv2bNHzdHGg9jGR2mjZmzfUdr6tH2m/ox8aii0NWAbG+SP1atX+5wzcOBAY3zMmDFqjrambOtz5syZxvhtt92m5tx///0+PZeIyO7du41x2/dARUWFMf7BBx+oObbRNZr33nvPGP/yyy/VHO362a5dOzXnxIkTxrj2OkX07wFt/9XBL34AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4Ahnu3qTkpKMcdtN07XuQFvXoNa9a+u29adDVusK0m7w7K/w8HBjnK7e+sd2rmu07kCtW01Evzn60aNH1Rytq9J2M3OtO9Cf7mFb5+zOnTuNcduN47X1YXsPUlNTjXHt5vAiImfOnDHGbe+BP9MCGoo///nPxvi1116r5mjv18KFC9UcbVtmZqaao62B3NxcNUc7z06ePKnm/OAHPzDGbZ2mmueff17d9uSTTxrj+fn5Pu/HH7179/Y5R+vgFxGJjY01xm0d4VFRUcZ4XFycmqN17546dUrNuRB+8QMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOMLZcS5aW7VtLIWWYxuZoo1raNq0qZqjtevbRkxoreW2m3MnJiYa49rIFltOXl6emoO6SbtBvfYZi+hjiGwjDBISEnzO0UZJ2EZMaMdmez3x8fHGuO1G6+vWrfP52LQ1ZRvrpI2SsN2cXRuNkZKSoubYvlcauhEjRvico40Ca926tZqjfT/bRumsXLnSGJ8/f76ao51PtuuNNgIoKytLzdmzZ4+6rSaFhoYa47ZrbnFxsTF+8OBBNWfmzJnG+JYtWyxH5zvte8D2XajlbN261e/j4Bc/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHCEs129ERERxnhMTIyac/jwYWPc1jWo3Wg9JydHzdE6DW3dfNrzJScnqzlax3F6erqao22z3WwcdZPWLWbrTtU6QFu1aqXmaN105eXlao52rhcUFKg5Wuei7dzU3oMDBw6oOdp3RFBQkJpTWlrqc472/ti6R7WuXlv3qO3zxvmys7N9isN/JSUlNfZcu3btUreNHz++xvZTH/CLHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEc6Oc7Hd5FmjtZafPn1azdHGxnie5/N+goP1j0t7PdoNuEX0sTG2MRu20TVoGLSbnNu22cYgaSNLtBvKi+jns+3YtHUTEhKi5mhjY06dOqXmaOvGlqOxjafR3oPIyEg1RxsbYzs22/MBaHj4xQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHOFsV2/z5s2Nce0m5yIiaWlpxritO1Hr3tVuKC+idwnbOpFTU1ONcdvN5qOioozxY8eOqTl09TYcFRUVxrjtM9a6Q7dv367maOdmo0aN1Byt29XWca51Dzdp0kTN0V6r1o1vO4bw8HA1xx/aOty2bZuaEx0dbYxr310iIkeOHPHtwADUa/ziBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwhLPjXLRRErabwGujLMrKytQc7Qbotpuma+MigoP1j0sbARMWFqbm5ObmGuO2cR4xMTHqNtQv2rkeHx+v5mjn07p169ScNWvWGOONGzdWc0pLS43xwsJCNUcbwRISEqLmaONPbPs5c+aMus1XtjV98uRJY/yqq65Sc3r16mWMa6N7RPSRUwAaJn7xAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHONvVGxcXZ4xr3YQiendgSUmJmqNts90EPjs72xiv6e7h5ORkY9x2Q3etexj1T1FRkTGudXuL6N2uti5YzbFjx3zOsdFeT20eQ22wdQJrndo5OTk+5wBomPjFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCGfHuVx55ZXGuG38iXYzc9sIGO1G67Yb1GtjVmxjNrQRLImJiWqOdrN57Zht+0H9Ex0dbYw3b95czUlISDDGAwN9/3dIbTySiH100aWmfQ8EBAT4/Fy29628vNwYt7032ueTkZGh5hw4cEDdBqDh4Rc/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEXb3n6N+/v5oTGRlpjGtduCIiUVFRxrjtxujafgoKCtQcrRM3IiJCzcnOzjbGbTeuX7NmjboN9cumTZuM8UOHDqk5Wkfrrl27fN5/RUWFz/upy/w5Ztt7oPnmm2/UbcuWLTPGV61apebYJhkAaHj4xQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4IgArz7OTQAAAIDP+MUPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEf8HYUpyO4SPCiYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c9a0ef6-5c87-4bb8-a658-47bfdf0a516d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca63df81-d215-4763-b605-b384b5e53baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #X = X.to(device)\n",
    "        #y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "59551aaa-6959-452e-9306-13402e58bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307223  [   64/60000]\n",
      "loss: 2.301068  [ 6464/60000]\n",
      "loss: 2.299096  [12864/60000]\n",
      "loss: 2.293298  [19264/60000]\n",
      "loss: 2.281187  [25664/60000]\n",
      "loss: 2.263267  [32064/60000]\n",
      "loss: 2.173970  [38464/60000]\n",
      "loss: 1.836459  [44864/60000]\n",
      "loss: 1.275470  [51264/60000]\n",
      "loss: 1.196997  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.160946 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.217604  [   64/60000]\n",
      "loss: 0.922880  [ 6464/60000]\n",
      "loss: 0.925605  [12864/60000]\n",
      "loss: 1.120956  [19264/60000]\n",
      "loss: 0.714061  [25664/60000]\n",
      "loss: 1.071122  [32064/60000]\n",
      "loss: 0.965061  [38464/60000]\n",
      "loss: 0.953073  [44864/60000]\n",
      "loss: 0.803259  [51264/60000]\n",
      "loss: 0.692759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.871453 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.736064  [   64/60000]\n",
      "loss: 0.942766  [ 6464/60000]\n",
      "loss: 0.736980  [12864/60000]\n",
      "loss: 0.800925  [19264/60000]\n",
      "loss: 0.614935  [25664/60000]\n",
      "loss: 0.589803  [32064/60000]\n",
      "loss: 0.479728  [38464/60000]\n",
      "loss: 0.903531  [44864/60000]\n",
      "loss: 0.433232  [51264/60000]\n",
      "loss: 0.554775  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.728106 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.572241  [   64/60000]\n",
      "loss: 0.788511  [ 6464/60000]\n",
      "loss: 0.595560  [12864/60000]\n",
      "loss: 0.469466  [19264/60000]\n",
      "loss: 0.748255  [25664/60000]\n",
      "loss: 0.501042  [32064/60000]\n",
      "loss: 0.599486  [38464/60000]\n",
      "loss: 0.543714  [44864/60000]\n",
      "loss: 0.499064  [51264/60000]\n",
      "loss: 0.626660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.529796 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.289761  [   64/60000]\n",
      "loss: 0.569676  [ 6464/60000]\n",
      "loss: 0.469692  [12864/60000]\n",
      "loss: 0.484463  [19264/60000]\n",
      "loss: 0.325090  [25664/60000]\n",
      "loss: 0.732374  [32064/60000]\n",
      "loss: 0.294394  [38464/60000]\n",
      "loss: 0.351824  [44864/60000]\n",
      "loss: 0.508212  [51264/60000]\n",
      "loss: 0.317159  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.498832 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.515106  [   64/60000]\n",
      "loss: 0.384881  [ 6464/60000]\n",
      "loss: 0.414583  [12864/60000]\n",
      "loss: 0.694422  [19264/60000]\n",
      "loss: 0.595888  [25664/60000]\n",
      "loss: 0.512138  [32064/60000]\n",
      "loss: 0.602234  [38464/60000]\n",
      "loss: 0.498079  [44864/60000]\n",
      "loss: 0.465553  [51264/60000]\n",
      "loss: 0.462673  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.469706 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.473421  [   64/60000]\n",
      "loss: 0.414458  [ 6464/60000]\n",
      "loss: 0.513537  [12864/60000]\n",
      "loss: 0.569353  [19264/60000]\n",
      "loss: 0.436198  [25664/60000]\n",
      "loss: 0.345305  [32064/60000]\n",
      "loss: 0.456104  [38464/60000]\n",
      "loss: 0.340813  [44864/60000]\n",
      "loss: 0.370963  [51264/60000]\n",
      "loss: 0.377880  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.437745 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.255629  [   64/60000]\n",
      "loss: 0.269395  [ 6464/60000]\n",
      "loss: 0.324726  [12864/60000]\n",
      "loss: 0.278315  [19264/60000]\n",
      "loss: 0.375979  [25664/60000]\n",
      "loss: 0.314320  [32064/60000]\n",
      "loss: 0.301890  [38464/60000]\n",
      "loss: 0.338340  [44864/60000]\n",
      "loss: 0.309336  [51264/60000]\n",
      "loss: 0.298696  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.395406 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.277179  [   64/60000]\n",
      "loss: 0.409049  [ 6464/60000]\n",
      "loss: 0.301282  [12864/60000]\n",
      "loss: 0.290289  [19264/60000]\n",
      "loss: 0.264119  [25664/60000]\n",
      "loss: 0.402002  [32064/60000]\n",
      "loss: 0.297199  [38464/60000]\n",
      "loss: 0.408272  [44864/60000]\n",
      "loss: 0.315217  [51264/60000]\n",
      "loss: 0.301460  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.424295 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.468618  [   64/60000]\n",
      "loss: 0.227884  [ 6464/60000]\n",
      "loss: 0.300735  [12864/60000]\n",
      "loss: 0.297358  [19264/60000]\n",
      "loss: 0.224253  [25664/60000]\n",
      "loss: 0.407257  [32064/60000]\n",
      "loss: 0.409042  [38464/60000]\n",
      "loss: 0.268132  [44864/60000]\n",
      "loss: 0.382305  [51264/60000]\n",
      "loss: 0.331337  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.410313 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.446739  [   64/60000]\n",
      "loss: 0.227414  [ 6464/60000]\n",
      "loss: 0.398505  [12864/60000]\n",
      "loss: 0.423113  [19264/60000]\n",
      "loss: 0.237582  [25664/60000]\n",
      "loss: 0.156348  [32064/60000]\n",
      "loss: 0.233812  [38464/60000]\n",
      "loss: 0.393774  [44864/60000]\n",
      "loss: 0.307856  [51264/60000]\n",
      "loss: 0.381708  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.378752 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.409768  [   64/60000]\n",
      "loss: 0.230403  [ 6464/60000]\n",
      "loss: 0.431251  [12864/60000]\n",
      "loss: 0.308257  [19264/60000]\n",
      "loss: 0.251452  [25664/60000]\n",
      "loss: 0.399298  [32064/60000]\n",
      "loss: 0.374852  [38464/60000]\n",
      "loss: 0.409302  [44864/60000]\n",
      "loss: 0.426457  [51264/60000]\n",
      "loss: 0.320273  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.376042 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.355617  [   64/60000]\n",
      "loss: 0.312487  [ 6464/60000]\n",
      "loss: 0.307202  [12864/60000]\n",
      "loss: 0.270648  [19264/60000]\n",
      "loss: 0.324972  [25664/60000]\n",
      "loss: 0.203203  [32064/60000]\n",
      "loss: 0.231982  [38464/60000]\n",
      "loss: 0.134112  [44864/60000]\n",
      "loss: 0.158877  [51264/60000]\n",
      "loss: 0.482784  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.457387 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.488522  [   64/60000]\n",
      "loss: 0.220944  [ 6464/60000]\n",
      "loss: 0.301220  [12864/60000]\n",
      "loss: 0.493266  [19264/60000]\n",
      "loss: 0.371051  [25664/60000]\n",
      "loss: 0.311952  [32064/60000]\n",
      "loss: 0.270718  [38464/60000]\n",
      "loss: 0.147886  [44864/60000]\n",
      "loss: 0.296729  [51264/60000]\n",
      "loss: 0.180917  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.396332 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.401340  [   64/60000]\n",
      "loss: 0.194025  [ 6464/60000]\n",
      "loss: 0.198567  [12864/60000]\n",
      "loss: 0.285445  [19264/60000]\n",
      "loss: 0.236568  [25664/60000]\n",
      "loss: 0.167713  [32064/60000]\n",
      "loss: 0.381509  [38464/60000]\n",
      "loss: 0.322967  [44864/60000]\n",
      "loss: 0.418616  [51264/60000]\n",
      "loss: 0.262474  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.368134 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.259580  [   64/60000]\n",
      "loss: 0.343999  [ 6464/60000]\n",
      "loss: 0.244392  [12864/60000]\n",
      "loss: 0.239580  [19264/60000]\n",
      "loss: 0.314130  [25664/60000]\n",
      "loss: 0.320714  [32064/60000]\n",
      "loss: 0.139967  [38464/60000]\n",
      "loss: 0.643394  [44864/60000]\n",
      "loss: 0.219007  [51264/60000]\n",
      "loss: 0.307426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.345650 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.252495  [   64/60000]\n",
      "loss: 0.335146  [ 6464/60000]\n",
      "loss: 0.269016  [12864/60000]\n",
      "loss: 0.498041  [19264/60000]\n",
      "loss: 0.260598  [25664/60000]\n",
      "loss: 0.265068  [32064/60000]\n",
      "loss: 0.236165  [38464/60000]\n",
      "loss: 0.304033  [44864/60000]\n",
      "loss: 0.368088  [51264/60000]\n",
      "loss: 0.153513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.410001 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.474480  [   64/60000]\n",
      "loss: 0.425477  [ 6464/60000]\n",
      "loss: 0.204759  [12864/60000]\n",
      "loss: 0.215022  [19264/60000]\n",
      "loss: 0.124597  [25664/60000]\n",
      "loss: 0.378430  [32064/60000]\n",
      "loss: 0.277681  [38464/60000]\n",
      "loss: 0.199340  [44864/60000]\n",
      "loss: 0.317835  [51264/60000]\n",
      "loss: 0.174194  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391920 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.238695  [   64/60000]\n",
      "loss: 0.232306  [ 6464/60000]\n",
      "loss: 0.493173  [12864/60000]\n",
      "loss: 0.373856  [19264/60000]\n",
      "loss: 0.135287  [25664/60000]\n",
      "loss: 0.177144  [32064/60000]\n",
      "loss: 0.451324  [38464/60000]\n",
      "loss: 0.304454  [44864/60000]\n",
      "loss: 0.324024  [51264/60000]\n",
      "loss: 0.304485  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.397416 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.199479  [   64/60000]\n",
      "loss: 0.217428  [ 6464/60000]\n",
      "loss: 0.239468  [12864/60000]\n",
      "loss: 0.227487  [19264/60000]\n",
      "loss: 0.252603  [25664/60000]\n",
      "loss: 0.505692  [32064/60000]\n",
      "loss: 0.151092  [38464/60000]\n",
      "loss: 0.216351  [44864/60000]\n",
      "loss: 0.122926  [51264/60000]\n",
      "loss: 0.217463  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.375150 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.160051  [   64/60000]\n",
      "loss: 0.134831  [ 6464/60000]\n",
      "loss: 0.183972  [12864/60000]\n",
      "loss: 0.278283  [19264/60000]\n",
      "loss: 0.196468  [25664/60000]\n",
      "loss: 0.294714  [32064/60000]\n",
      "loss: 0.221358  [38464/60000]\n",
      "loss: 0.456623  [44864/60000]\n",
      "loss: 0.376365  [51264/60000]\n",
      "loss: 0.248008  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.393766 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.357253  [   64/60000]\n",
      "loss: 0.291289  [ 6464/60000]\n",
      "loss: 0.264415  [12864/60000]\n",
      "loss: 0.157094  [19264/60000]\n",
      "loss: 0.143894  [25664/60000]\n",
      "loss: 0.158249  [32064/60000]\n",
      "loss: 0.247948  [38464/60000]\n",
      "loss: 0.232217  [44864/60000]\n",
      "loss: 0.158438  [51264/60000]\n",
      "loss: 0.314705  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.353227 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.307852  [   64/60000]\n",
      "loss: 0.124496  [ 6464/60000]\n",
      "loss: 0.170087  [12864/60000]\n",
      "loss: 0.100181  [19264/60000]\n",
      "loss: 0.203174  [25664/60000]\n",
      "loss: 0.449603  [32064/60000]\n",
      "loss: 0.168415  [38464/60000]\n",
      "loss: 0.146567  [44864/60000]\n",
      "loss: 0.262503  [51264/60000]\n",
      "loss: 0.286601  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.377293 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.166945  [   64/60000]\n",
      "loss: 0.205259  [ 6464/60000]\n",
      "loss: 0.232237  [12864/60000]\n",
      "loss: 0.138594  [19264/60000]\n",
      "loss: 0.193892  [25664/60000]\n",
      "loss: 0.214699  [32064/60000]\n",
      "loss: 0.133704  [38464/60000]\n",
      "loss: 0.115615  [44864/60000]\n",
      "loss: 0.241325  [51264/60000]\n",
      "loss: 0.207207  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.382368 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.173405  [   64/60000]\n",
      "loss: 0.211295  [ 6464/60000]\n",
      "loss: 0.274501  [12864/60000]\n",
      "loss: 0.265510  [19264/60000]\n",
      "loss: 0.102426  [25664/60000]\n",
      "loss: 0.326338  [32064/60000]\n",
      "loss: 0.367878  [38464/60000]\n",
      "loss: 0.266598  [44864/60000]\n",
      "loss: 0.150609  [51264/60000]\n",
      "loss: 0.138547  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.341973 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.231572  [   64/60000]\n",
      "loss: 0.312400  [ 6464/60000]\n",
      "loss: 0.468323  [12864/60000]\n",
      "loss: 0.218142  [19264/60000]\n",
      "loss: 0.159101  [25664/60000]\n",
      "loss: 0.232837  [32064/60000]\n",
      "loss: 0.333313  [38464/60000]\n",
      "loss: 0.366020  [44864/60000]\n",
      "loss: 0.068353  [51264/60000]\n",
      "loss: 0.206514  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.370964 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.332125  [   64/60000]\n",
      "loss: 0.204550  [ 6464/60000]\n",
      "loss: 0.196736  [12864/60000]\n",
      "loss: 0.245049  [19264/60000]\n",
      "loss: 0.212406  [25664/60000]\n",
      "loss: 0.117864  [32064/60000]\n",
      "loss: 0.281169  [38464/60000]\n",
      "loss: 0.082600  [44864/60000]\n",
      "loss: 0.186594  [51264/60000]\n",
      "loss: 0.176461  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.336910 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.283362  [   64/60000]\n",
      "loss: 0.227541  [ 6464/60000]\n",
      "loss: 0.189489  [12864/60000]\n",
      "loss: 0.282022  [19264/60000]\n",
      "loss: 0.246926  [25664/60000]\n",
      "loss: 0.304397  [32064/60000]\n",
      "loss: 0.116303  [38464/60000]\n",
      "loss: 0.128954  [44864/60000]\n",
      "loss: 0.134294  [51264/60000]\n",
      "loss: 0.192922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.340495 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.196249  [   64/60000]\n",
      "loss: 0.140175  [ 6464/60000]\n",
      "loss: 0.075599  [12864/60000]\n",
      "loss: 0.157266  [19264/60000]\n",
      "loss: 0.215344  [25664/60000]\n",
      "loss: 0.205375  [32064/60000]\n",
      "loss: 0.226832  [38464/60000]\n",
      "loss: 0.200283  [44864/60000]\n",
      "loss: 0.263369  [51264/60000]\n",
      "loss: 0.339885  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.351100 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.145973  [   64/60000]\n",
      "loss: 0.210953  [ 6464/60000]\n",
      "loss: 0.234040  [12864/60000]\n",
      "loss: 0.243155  [19264/60000]\n",
      "loss: 0.096829  [25664/60000]\n",
      "loss: 0.098803  [32064/60000]\n",
      "loss: 0.242775  [38464/60000]\n",
      "loss: 0.116442  [44864/60000]\n",
      "loss: 0.082513  [51264/60000]\n",
      "loss: 0.129067  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.338647 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.246290  [   64/60000]\n",
      "loss: 0.216493  [ 6464/60000]\n",
      "loss: 0.073080  [12864/60000]\n",
      "loss: 0.136572  [19264/60000]\n",
      "loss: 0.121579  [25664/60000]\n",
      "loss: 0.517805  [32064/60000]\n",
      "loss: 0.293153  [38464/60000]\n",
      "loss: 0.062137  [44864/60000]\n",
      "loss: 0.175057  [51264/60000]\n",
      "loss: 0.289431  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.481930 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.428379  [   64/60000]\n",
      "loss: 0.150291  [ 6464/60000]\n",
      "loss: 0.214078  [12864/60000]\n",
      "loss: 0.119429  [19264/60000]\n",
      "loss: 0.247405  [25664/60000]\n",
      "loss: 0.212711  [32064/60000]\n",
      "loss: 0.128396  [38464/60000]\n",
      "loss: 0.213662  [44864/60000]\n",
      "loss: 0.154795  [51264/60000]\n",
      "loss: 0.149980  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.361423 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.111114  [   64/60000]\n",
      "loss: 0.411601  [ 6464/60000]\n",
      "loss: 0.231608  [12864/60000]\n",
      "loss: 0.188920  [19264/60000]\n",
      "loss: 0.201292  [25664/60000]\n",
      "loss: 0.142935  [32064/60000]\n",
      "loss: 0.067472  [38464/60000]\n",
      "loss: 0.151847  [44864/60000]\n",
      "loss: 0.210639  [51264/60000]\n",
      "loss: 0.176004  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.348887 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.110544  [   64/60000]\n",
      "loss: 0.250984  [ 6464/60000]\n",
      "loss: 0.168835  [12864/60000]\n",
      "loss: 0.097856  [19264/60000]\n",
      "loss: 0.217901  [25664/60000]\n",
      "loss: 0.129970  [32064/60000]\n",
      "loss: 0.118760  [38464/60000]\n",
      "loss: 0.313069  [44864/60000]\n",
      "loss: 0.153158  [51264/60000]\n",
      "loss: 0.175071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.363831 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.252544  [   64/60000]\n",
      "loss: 0.133390  [ 6464/60000]\n",
      "loss: 0.187282  [12864/60000]\n",
      "loss: 0.293167  [19264/60000]\n",
      "loss: 0.169862  [25664/60000]\n",
      "loss: 0.255902  [32064/60000]\n",
      "loss: 0.291004  [38464/60000]\n",
      "loss: 0.069998  [44864/60000]\n",
      "loss: 0.095453  [51264/60000]\n",
      "loss: 0.235672  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.358683 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.115380  [   64/60000]\n",
      "loss: 0.100811  [ 6464/60000]\n",
      "loss: 0.097076  [12864/60000]\n",
      "loss: 0.124227  [19264/60000]\n",
      "loss: 0.116159  [25664/60000]\n",
      "loss: 0.174394  [32064/60000]\n",
      "loss: 0.326145  [38464/60000]\n",
      "loss: 0.145971  [44864/60000]\n",
      "loss: 0.129447  [51264/60000]\n",
      "loss: 0.161599  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.327510 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.133176  [   64/60000]\n",
      "loss: 0.126362  [ 6464/60000]\n",
      "loss: 0.117988  [12864/60000]\n",
      "loss: 0.234521  [19264/60000]\n",
      "loss: 0.055146  [25664/60000]\n",
      "loss: 0.146769  [32064/60000]\n",
      "loss: 0.295316  [38464/60000]\n",
      "loss: 0.126721  [44864/60000]\n",
      "loss: 0.180757  [51264/60000]\n",
      "loss: 0.167053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.371500 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.071349  [   64/60000]\n",
      "loss: 0.174126  [ 6464/60000]\n",
      "loss: 0.168873  [12864/60000]\n",
      "loss: 0.176673  [19264/60000]\n",
      "loss: 0.157191  [25664/60000]\n",
      "loss: 0.084771  [32064/60000]\n",
      "loss: 0.103609  [38464/60000]\n",
      "loss: 0.364808  [44864/60000]\n",
      "loss: 0.125256  [51264/60000]\n",
      "loss: 0.115109  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.433598 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.167565  [   64/60000]\n",
      "loss: 0.089966  [ 6464/60000]\n",
      "loss: 0.113931  [12864/60000]\n",
      "loss: 0.214106  [19264/60000]\n",
      "loss: 0.105021  [25664/60000]\n",
      "loss: 0.177086  [32064/60000]\n",
      "loss: 0.221725  [38464/60000]\n",
      "loss: 0.123713  [44864/60000]\n",
      "loss: 0.085606  [51264/60000]\n",
      "loss: 0.174089  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.420608 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.099302  [   64/60000]\n",
      "loss: 0.135067  [ 6464/60000]\n",
      "loss: 0.165512  [12864/60000]\n",
      "loss: 0.104206  [19264/60000]\n",
      "loss: 0.147079  [25664/60000]\n",
      "loss: 0.180680  [32064/60000]\n",
      "loss: 0.153829  [38464/60000]\n",
      "loss: 0.197285  [44864/60000]\n",
      "loss: 0.205406  [51264/60000]\n",
      "loss: 0.136787  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.432337 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.042687  [   64/60000]\n",
      "loss: 0.043963  [ 6464/60000]\n",
      "loss: 0.172293  [12864/60000]\n",
      "loss: 0.092918  [19264/60000]\n",
      "loss: 0.188841  [25664/60000]\n",
      "loss: 0.167215  [32064/60000]\n",
      "loss: 0.145582  [38464/60000]\n",
      "loss: 0.184304  [44864/60000]\n",
      "loss: 0.105114  [51264/60000]\n",
      "loss: 0.185842  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.388947 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.160985  [   64/60000]\n",
      "loss: 0.252695  [ 6464/60000]\n",
      "loss: 0.196391  [12864/60000]\n",
      "loss: 0.273995  [19264/60000]\n",
      "loss: 0.237691  [25664/60000]\n",
      "loss: 0.165349  [32064/60000]\n",
      "loss: 0.029525  [38464/60000]\n",
      "loss: 0.158737  [44864/60000]\n",
      "loss: 0.099699  [51264/60000]\n",
      "loss: 0.225052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.378669 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.162268  [   64/60000]\n",
      "loss: 0.057869  [ 6464/60000]\n",
      "loss: 0.224389  [12864/60000]\n",
      "loss: 0.059494  [19264/60000]\n",
      "loss: 0.100771  [25664/60000]\n",
      "loss: 0.115811  [32064/60000]\n",
      "loss: 0.166998  [38464/60000]\n",
      "loss: 0.117053  [44864/60000]\n",
      "loss: 0.174739  [51264/60000]\n",
      "loss: 0.127858  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.364251 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.110874  [   64/60000]\n",
      "loss: 0.168744  [ 6464/60000]\n",
      "loss: 0.148182  [12864/60000]\n",
      "loss: 0.046303  [19264/60000]\n",
      "loss: 0.159633  [25664/60000]\n",
      "loss: 0.072528  [32064/60000]\n",
      "loss: 0.227813  [38464/60000]\n",
      "loss: 0.135841  [44864/60000]\n",
      "loss: 0.113550  [51264/60000]\n",
      "loss: 0.259791  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.502358 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.175197  [   64/60000]\n",
      "loss: 0.198300  [ 6464/60000]\n",
      "loss: 0.098041  [12864/60000]\n",
      "loss: 0.075515  [19264/60000]\n",
      "loss: 0.122699  [25664/60000]\n",
      "loss: 0.141958  [32064/60000]\n",
      "loss: 0.167642  [38464/60000]\n",
      "loss: 0.238525  [44864/60000]\n",
      "loss: 0.210877  [51264/60000]\n",
      "loss: 0.158280  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.371479 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.072226  [   64/60000]\n",
      "loss: 0.128907  [ 6464/60000]\n",
      "loss: 0.363871  [12864/60000]\n",
      "loss: 0.088774  [19264/60000]\n",
      "loss: 0.213612  [25664/60000]\n",
      "loss: 0.208758  [32064/60000]\n",
      "loss: 0.098938  [38464/60000]\n",
      "loss: 0.148805  [44864/60000]\n",
      "loss: 0.114634  [51264/60000]\n",
      "loss: 0.077624  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.403963 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.176815  [   64/60000]\n",
      "loss: 0.040607  [ 6464/60000]\n",
      "loss: 0.170665  [12864/60000]\n",
      "loss: 0.125466  [19264/60000]\n",
      "loss: 0.065773  [25664/60000]\n",
      "loss: 0.216861  [32064/60000]\n",
      "loss: 0.043339  [38464/60000]\n",
      "loss: 0.058142  [44864/60000]\n",
      "loss: 0.187581  [51264/60000]\n",
      "loss: 0.158602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.395363 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.099809  [   64/60000]\n",
      "loss: 0.053018  [ 6464/60000]\n",
      "loss: 0.121734  [12864/60000]\n",
      "loss: 0.155258  [19264/60000]\n",
      "loss: 0.154033  [25664/60000]\n",
      "loss: 0.021046  [32064/60000]\n",
      "loss: 0.056228  [38464/60000]\n",
      "loss: 0.137771  [44864/60000]\n",
      "loss: 0.100144  [51264/60000]\n",
      "loss: 0.095447  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.386138 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.194806  [   64/60000]\n",
      "loss: 0.113558  [ 6464/60000]\n",
      "loss: 0.091914  [12864/60000]\n",
      "loss: 0.033719  [19264/60000]\n",
      "loss: 0.096370  [25664/60000]\n",
      "loss: 0.042310  [32064/60000]\n",
      "loss: 0.032190  [38464/60000]\n",
      "loss: 0.169455  [44864/60000]\n",
      "loss: 0.103030  [51264/60000]\n",
      "loss: 0.095253  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.533029 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.279364  [   64/60000]\n",
      "loss: 0.176416  [ 6464/60000]\n",
      "loss: 0.090378  [12864/60000]\n",
      "loss: 0.190529  [19264/60000]\n",
      "loss: 0.135892  [25664/60000]\n",
      "loss: 0.083230  [32064/60000]\n",
      "loss: 0.123331  [38464/60000]\n",
      "loss: 0.214343  [44864/60000]\n",
      "loss: 0.207255  [51264/60000]\n",
      "loss: 0.123970  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.393300 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.131084  [   64/60000]\n",
      "loss: 0.088818  [ 6464/60000]\n",
      "loss: 0.095431  [12864/60000]\n",
      "loss: 0.140659  [19264/60000]\n",
      "loss: 0.223426  [25664/60000]\n",
      "loss: 0.122040  [32064/60000]\n",
      "loss: 0.187538  [38464/60000]\n",
      "loss: 0.180894  [44864/60000]\n",
      "loss: 0.087807  [51264/60000]\n",
      "loss: 0.161763  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.412680 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.073783  [   64/60000]\n",
      "loss: 0.165536  [ 6464/60000]\n",
      "loss: 0.057643  [12864/60000]\n",
      "loss: 0.186619  [19264/60000]\n",
      "loss: 0.076664  [25664/60000]\n",
      "loss: 0.108719  [32064/60000]\n",
      "loss: 0.180850  [38464/60000]\n",
      "loss: 0.201163  [44864/60000]\n",
      "loss: 0.208549  [51264/60000]\n",
      "loss: 0.066090  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.419010 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.065781  [   64/60000]\n",
      "loss: 0.090621  [ 6464/60000]\n",
      "loss: 0.035729  [12864/60000]\n",
      "loss: 0.307698  [19264/60000]\n",
      "loss: 0.072255  [25664/60000]\n",
      "loss: 0.118347  [32064/60000]\n",
      "loss: 0.065194  [38464/60000]\n",
      "loss: 0.123227  [44864/60000]\n",
      "loss: 0.108911  [51264/60000]\n",
      "loss: 0.078326  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.440472 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.037869  [   64/60000]\n",
      "loss: 0.022340  [ 6464/60000]\n",
      "loss: 0.068145  [12864/60000]\n",
      "loss: 0.045251  [19264/60000]\n",
      "loss: 0.152814  [25664/60000]\n",
      "loss: 0.226005  [32064/60000]\n",
      "loss: 0.187369  [38464/60000]\n",
      "loss: 0.044445  [44864/60000]\n",
      "loss: 0.109426  [51264/60000]\n",
      "loss: 0.133043  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.438503 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.168284  [   64/60000]\n",
      "loss: 0.063258  [ 6464/60000]\n",
      "loss: 0.083908  [12864/60000]\n",
      "loss: 0.225050  [19264/60000]\n",
      "loss: 0.068037  [25664/60000]\n",
      "loss: 0.073883  [32064/60000]\n",
      "loss: 0.071691  [38464/60000]\n",
      "loss: 0.099444  [44864/60000]\n",
      "loss: 0.031766  [51264/60000]\n",
      "loss: 0.105481  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.400525 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.084086  [   64/60000]\n",
      "loss: 0.217013  [ 6464/60000]\n",
      "loss: 0.101166  [12864/60000]\n",
      "loss: 0.076950  [19264/60000]\n",
      "loss: 0.202171  [25664/60000]\n",
      "loss: 0.101350  [32064/60000]\n",
      "loss: 0.188391  [38464/60000]\n",
      "loss: 0.040697  [44864/60000]\n",
      "loss: 0.096490  [51264/60000]\n",
      "loss: 0.205319  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.404120 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.188942  [   64/60000]\n",
      "loss: 0.057484  [ 6464/60000]\n",
      "loss: 0.104444  [12864/60000]\n",
      "loss: 0.033896  [19264/60000]\n",
      "loss: 0.097452  [25664/60000]\n",
      "loss: 0.053788  [32064/60000]\n",
      "loss: 0.028973  [38464/60000]\n",
      "loss: 0.055403  [44864/60000]\n",
      "loss: 0.064827  [51264/60000]\n",
      "loss: 0.064747  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.406635 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.059105  [   64/60000]\n",
      "loss: 0.077500  [ 6464/60000]\n",
      "loss: 0.106787  [12864/60000]\n",
      "loss: 0.040576  [19264/60000]\n",
      "loss: 0.093459  [25664/60000]\n",
      "loss: 0.029136  [32064/60000]\n",
      "loss: 0.053701  [38464/60000]\n",
      "loss: 0.059000  [44864/60000]\n",
      "loss: 0.093685  [51264/60000]\n",
      "loss: 0.035920  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.429197 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.038994  [   64/60000]\n",
      "loss: 0.073123  [ 6464/60000]\n",
      "loss: 0.076772  [12864/60000]\n",
      "loss: 0.040520  [19264/60000]\n",
      "loss: 0.171633  [25664/60000]\n",
      "loss: 0.118292  [32064/60000]\n",
      "loss: 0.081759  [38464/60000]\n",
      "loss: 0.075593  [44864/60000]\n",
      "loss: 0.140023  [51264/60000]\n",
      "loss: 0.073910  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.461189 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.126685  [   64/60000]\n",
      "loss: 0.279722  [ 6464/60000]\n",
      "loss: 0.009492  [12864/60000]\n",
      "loss: 0.095020  [19264/60000]\n",
      "loss: 0.075096  [25664/60000]\n",
      "loss: 0.115062  [32064/60000]\n",
      "loss: 0.078662  [38464/60000]\n",
      "loss: 0.070644  [44864/60000]\n",
      "loss: 0.118807  [51264/60000]\n",
      "loss: 0.029746  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.520188 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.215695  [   64/60000]\n",
      "loss: 0.086540  [ 6464/60000]\n",
      "loss: 0.061351  [12864/60000]\n",
      "loss: 0.074488  [19264/60000]\n",
      "loss: 0.221127  [25664/60000]\n",
      "loss: 0.155141  [32064/60000]\n",
      "loss: 0.008189  [38464/60000]\n",
      "loss: 0.080020  [44864/60000]\n",
      "loss: 0.051779  [51264/60000]\n",
      "loss: 0.059082  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.450777 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.112631  [   64/60000]\n",
      "loss: 0.073305  [ 6464/60000]\n",
      "loss: 0.108064  [12864/60000]\n",
      "loss: 0.089662  [19264/60000]\n",
      "loss: 0.052203  [25664/60000]\n",
      "loss: 0.066379  [32064/60000]\n",
      "loss: 0.037713  [38464/60000]\n",
      "loss: 0.063313  [44864/60000]\n",
      "loss: 0.232116  [51264/60000]\n",
      "loss: 0.175631  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.449152 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.112617  [   64/60000]\n",
      "loss: 0.023073  [ 6464/60000]\n",
      "loss: 0.082009  [12864/60000]\n",
      "loss: 0.041564  [19264/60000]\n",
      "loss: 0.194435  [25664/60000]\n",
      "loss: 0.127053  [32064/60000]\n",
      "loss: 0.046736  [38464/60000]\n",
      "loss: 0.030285  [44864/60000]\n",
      "loss: 0.026548  [51264/60000]\n",
      "loss: 0.036040  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.505715 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.118549  [   64/60000]\n",
      "loss: 0.127789  [ 6464/60000]\n",
      "loss: 0.086482  [12864/60000]\n",
      "loss: 0.045412  [19264/60000]\n",
      "loss: 0.040426  [25664/60000]\n",
      "loss: 0.039923  [32064/60000]\n",
      "loss: 0.022607  [38464/60000]\n",
      "loss: 0.061389  [44864/60000]\n",
      "loss: 0.056860  [51264/60000]\n",
      "loss: 0.139824  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.449081 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.100140  [   64/60000]\n",
      "loss: 0.077981  [ 6464/60000]\n",
      "loss: 0.108701  [12864/60000]\n",
      "loss: 0.083524  [19264/60000]\n",
      "loss: 0.069258  [25664/60000]\n",
      "loss: 0.059378  [32064/60000]\n",
      "loss: 0.065844  [38464/60000]\n",
      "loss: 0.126294  [44864/60000]\n",
      "loss: 0.132284  [51264/60000]\n",
      "loss: 0.118547  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.460978 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.094019  [   64/60000]\n",
      "loss: 0.029121  [ 6464/60000]\n",
      "loss: 0.217936  [12864/60000]\n",
      "loss: 0.064131  [19264/60000]\n",
      "loss: 0.078818  [25664/60000]\n",
      "loss: 0.121025  [32064/60000]\n",
      "loss: 0.014808  [38464/60000]\n",
      "loss: 0.124945  [44864/60000]\n",
      "loss: 0.062708  [51264/60000]\n",
      "loss: 0.117025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.500769 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.086727  [   64/60000]\n",
      "loss: 0.049601  [ 6464/60000]\n",
      "loss: 0.044713  [12864/60000]\n",
      "loss: 0.173193  [19264/60000]\n",
      "loss: 0.106417  [25664/60000]\n",
      "loss: 0.099689  [32064/60000]\n",
      "loss: 0.052644  [38464/60000]\n",
      "loss: 0.121765  [44864/60000]\n",
      "loss: 0.112387  [51264/60000]\n",
      "loss: 0.134602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.450326 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.034316  [   64/60000]\n",
      "loss: 0.022309  [ 6464/60000]\n",
      "loss: 0.045867  [12864/60000]\n",
      "loss: 0.025440  [19264/60000]\n",
      "loss: 0.024063  [25664/60000]\n",
      "loss: 0.074049  [32064/60000]\n",
      "loss: 0.025331  [38464/60000]\n",
      "loss: 0.019726  [44864/60000]\n",
      "loss: 0.101154  [51264/60000]\n",
      "loss: 0.040857  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.485122 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.119915  [   64/60000]\n",
      "loss: 0.070118  [ 6464/60000]\n",
      "loss: 0.155030  [12864/60000]\n",
      "loss: 0.094556  [19264/60000]\n",
      "loss: 0.029758  [25664/60000]\n",
      "loss: 0.046383  [32064/60000]\n",
      "loss: 0.123099  [38464/60000]\n",
      "loss: 0.070456  [44864/60000]\n",
      "loss: 0.056917  [51264/60000]\n",
      "loss: 0.241615  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.515997 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.133624  [   64/60000]\n",
      "loss: 0.080284  [ 6464/60000]\n",
      "loss: 0.126207  [12864/60000]\n",
      "loss: 0.101365  [19264/60000]\n",
      "loss: 0.071353  [25664/60000]\n",
      "loss: 0.053212  [32064/60000]\n",
      "loss: 0.079202  [38464/60000]\n",
      "loss: 0.035713  [44864/60000]\n",
      "loss: 0.298476  [51264/60000]\n",
      "loss: 0.049406  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.504305 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.111837  [   64/60000]\n",
      "loss: 0.076768  [ 6464/60000]\n",
      "loss: 0.071752  [12864/60000]\n",
      "loss: 0.031895  [19264/60000]\n",
      "loss: 0.020912  [25664/60000]\n",
      "loss: 0.113976  [32064/60000]\n",
      "loss: 0.128691  [38464/60000]\n",
      "loss: 0.112648  [44864/60000]\n",
      "loss: 0.058832  [51264/60000]\n",
      "loss: 0.010245  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.603816 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.168899  [   64/60000]\n",
      "loss: 0.035213  [ 6464/60000]\n",
      "loss: 0.258316  [12864/60000]\n",
      "loss: 0.130585  [19264/60000]\n",
      "loss: 0.057792  [25664/60000]\n",
      "loss: 0.067576  [32064/60000]\n",
      "loss: 0.068009  [38464/60000]\n",
      "loss: 0.031312  [44864/60000]\n",
      "loss: 0.021823  [51264/60000]\n",
      "loss: 0.057889  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.469041 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.145545  [   64/60000]\n",
      "loss: 0.109724  [ 6464/60000]\n",
      "loss: 0.080127  [12864/60000]\n",
      "loss: 0.153680  [19264/60000]\n",
      "loss: 0.103961  [25664/60000]\n",
      "loss: 0.050783  [32064/60000]\n",
      "loss: 0.114470  [38464/60000]\n",
      "loss: 0.203721  [44864/60000]\n",
      "loss: 0.078982  [51264/60000]\n",
      "loss: 0.255144  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.504688 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.031946  [   64/60000]\n",
      "loss: 0.031473  [ 6464/60000]\n",
      "loss: 0.077855  [12864/60000]\n",
      "loss: 0.112943  [19264/60000]\n",
      "loss: 0.016700  [25664/60000]\n",
      "loss: 0.062514  [32064/60000]\n",
      "loss: 0.053611  [38464/60000]\n",
      "loss: 0.057829  [44864/60000]\n",
      "loss: 0.090738  [51264/60000]\n",
      "loss: 0.146163  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.522987 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.092156  [   64/60000]\n",
      "loss: 0.075137  [ 6464/60000]\n",
      "loss: 0.004950  [12864/60000]\n",
      "loss: 0.086356  [19264/60000]\n",
      "loss: 0.033385  [25664/60000]\n",
      "loss: 0.116075  [32064/60000]\n",
      "loss: 0.052925  [38464/60000]\n",
      "loss: 0.059082  [44864/60000]\n",
      "loss: 0.038108  [51264/60000]\n",
      "loss: 0.178016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.524679 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.151703  [   64/60000]\n",
      "loss: 0.033710  [ 6464/60000]\n",
      "loss: 0.092884  [12864/60000]\n",
      "loss: 0.037812  [19264/60000]\n",
      "loss: 0.042087  [25664/60000]\n",
      "loss: 0.016517  [32064/60000]\n",
      "loss: 0.136390  [38464/60000]\n",
      "loss: 0.083073  [44864/60000]\n",
      "loss: 0.108768  [51264/60000]\n",
      "loss: 0.049581  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.488253 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.102732  [   64/60000]\n",
      "loss: 0.100184  [ 6464/60000]\n",
      "loss: 0.010783  [12864/60000]\n",
      "loss: 0.058884  [19264/60000]\n",
      "loss: 0.083887  [25664/60000]\n",
      "loss: 0.159961  [32064/60000]\n",
      "loss: 0.052692  [38464/60000]\n",
      "loss: 0.023301  [44864/60000]\n",
      "loss: 0.062362  [51264/60000]\n",
      "loss: 0.026595  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.488257 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.046763  [   64/60000]\n",
      "loss: 0.073252  [ 6464/60000]\n",
      "loss: 0.140361  [12864/60000]\n",
      "loss: 0.018929  [19264/60000]\n",
      "loss: 0.044791  [25664/60000]\n",
      "loss: 0.044639  [32064/60000]\n",
      "loss: 0.007075  [38464/60000]\n",
      "loss: 0.165993  [44864/60000]\n",
      "loss: 0.071019  [51264/60000]\n",
      "loss: 0.092550  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.581998 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.318577  [   64/60000]\n",
      "loss: 0.029311  [ 6464/60000]\n",
      "loss: 0.057454  [12864/60000]\n",
      "loss: 0.050652  [19264/60000]\n",
      "loss: 0.056057  [25664/60000]\n",
      "loss: 0.071513  [32064/60000]\n",
      "loss: 0.007760  [38464/60000]\n",
      "loss: 0.014902  [44864/60000]\n",
      "loss: 0.122812  [51264/60000]\n",
      "loss: 0.077476  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.477679 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.045478  [   64/60000]\n",
      "loss: 0.048140  [ 6464/60000]\n",
      "loss: 0.084342  [12864/60000]\n",
      "loss: 0.030892  [19264/60000]\n",
      "loss: 0.040247  [25664/60000]\n",
      "loss: 0.105445  [32064/60000]\n",
      "loss: 0.012534  [38464/60000]\n",
      "loss: 0.050799  [44864/60000]\n",
      "loss: 0.123278  [51264/60000]\n",
      "loss: 0.057943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.532486 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.034394  [   64/60000]\n",
      "loss: 0.060994  [ 6464/60000]\n",
      "loss: 0.009877  [12864/60000]\n",
      "loss: 0.051033  [19264/60000]\n",
      "loss: 0.099940  [25664/60000]\n",
      "loss: 0.020307  [32064/60000]\n",
      "loss: 0.039042  [38464/60000]\n",
      "loss: 0.057289  [44864/60000]\n",
      "loss: 0.120785  [51264/60000]\n",
      "loss: 0.041450  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.576184 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.152106  [   64/60000]\n",
      "loss: 0.057904  [ 6464/60000]\n",
      "loss: 0.030924  [12864/60000]\n",
      "loss: 0.026046  [19264/60000]\n",
      "loss: 0.014351  [25664/60000]\n",
      "loss: 0.050249  [32064/60000]\n",
      "loss: 0.025345  [38464/60000]\n",
      "loss: 0.022818  [44864/60000]\n",
      "loss: 0.048849  [51264/60000]\n",
      "loss: 0.048994  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.551780 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.067927  [   64/60000]\n",
      "loss: 0.215657  [ 6464/60000]\n",
      "loss: 0.155763  [12864/60000]\n",
      "loss: 0.058584  [19264/60000]\n",
      "loss: 0.028301  [25664/60000]\n",
      "loss: 0.013574  [32064/60000]\n",
      "loss: 0.039008  [38464/60000]\n",
      "loss: 0.075479  [44864/60000]\n",
      "loss: 0.044769  [51264/60000]\n",
      "loss: 0.051356  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.601954 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.082989  [   64/60000]\n",
      "loss: 0.056617  [ 6464/60000]\n",
      "loss: 0.024699  [12864/60000]\n",
      "loss: 0.076777  [19264/60000]\n",
      "loss: 0.016197  [25664/60000]\n",
      "loss: 0.033163  [32064/60000]\n",
      "loss: 0.072578  [38464/60000]\n",
      "loss: 0.031889  [44864/60000]\n",
      "loss: 0.048136  [51264/60000]\n",
      "loss: 0.057351  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.499224 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.017954  [   64/60000]\n",
      "loss: 0.092172  [ 6464/60000]\n",
      "loss: 0.041282  [12864/60000]\n",
      "loss: 0.030768  [19264/60000]\n",
      "loss: 0.102086  [25664/60000]\n",
      "loss: 0.027706  [32064/60000]\n",
      "loss: 0.050369  [38464/60000]\n",
      "loss: 0.051233  [44864/60000]\n",
      "loss: 0.202033  [51264/60000]\n",
      "loss: 0.050675  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.525851 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.031525  [   64/60000]\n",
      "loss: 0.036908  [ 6464/60000]\n",
      "loss: 0.027431  [12864/60000]\n",
      "loss: 0.095605  [19264/60000]\n",
      "loss: 0.044673  [25664/60000]\n",
      "loss: 0.020305  [32064/60000]\n",
      "loss: 0.020798  [38464/60000]\n",
      "loss: 0.027395  [44864/60000]\n",
      "loss: 0.009872  [51264/60000]\n",
      "loss: 0.047284  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.511404 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.017303  [   64/60000]\n",
      "loss: 0.033857  [ 6464/60000]\n",
      "loss: 0.013467  [12864/60000]\n",
      "loss: 0.031626  [19264/60000]\n",
      "loss: 0.091662  [25664/60000]\n",
      "loss: 0.009557  [32064/60000]\n",
      "loss: 0.244019  [38464/60000]\n",
      "loss: 0.081938  [44864/60000]\n",
      "loss: 0.047226  [51264/60000]\n",
      "loss: 0.023431  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.580955 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.046158  [   64/60000]\n",
      "loss: 0.010241  [ 6464/60000]\n",
      "loss: 0.031712  [12864/60000]\n",
      "loss: 0.043682  [19264/60000]\n",
      "loss: 0.006423  [25664/60000]\n",
      "loss: 0.026694  [32064/60000]\n",
      "loss: 0.013583  [38464/60000]\n",
      "loss: 0.013312  [44864/60000]\n",
      "loss: 0.103911  [51264/60000]\n",
      "loss: 0.114254  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.535568 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.054252  [   64/60000]\n",
      "loss: 0.031494  [ 6464/60000]\n",
      "loss: 0.030309  [12864/60000]\n",
      "loss: 0.012825  [19264/60000]\n",
      "loss: 0.098653  [25664/60000]\n",
      "loss: 0.018444  [32064/60000]\n",
      "loss: 0.005633  [38464/60000]\n",
      "loss: 0.027179  [44864/60000]\n",
      "loss: 0.020430  [51264/60000]\n",
      "loss: 0.099037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.631419 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.128545  [   64/60000]\n",
      "loss: 0.006418  [ 6464/60000]\n",
      "loss: 0.018057  [12864/60000]\n",
      "loss: 0.015022  [19264/60000]\n",
      "loss: 0.013025  [25664/60000]\n",
      "loss: 0.270317  [32064/60000]\n",
      "loss: 0.055601  [38464/60000]\n",
      "loss: 0.083593  [44864/60000]\n",
      "loss: 0.015213  [51264/60000]\n",
      "loss: 0.012438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.564603 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.048999  [   64/60000]\n",
      "loss: 0.026046  [ 6464/60000]\n",
      "loss: 0.067234  [12864/60000]\n",
      "loss: 0.028744  [19264/60000]\n",
      "loss: 0.024532  [25664/60000]\n",
      "loss: 0.010962  [32064/60000]\n",
      "loss: 0.010960  [38464/60000]\n",
      "loss: 0.026604  [44864/60000]\n",
      "loss: 0.024698  [51264/60000]\n",
      "loss: 0.079742  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.559934 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.042212  [   64/60000]\n",
      "loss: 0.017656  [ 6464/60000]\n",
      "loss: 0.088287  [12864/60000]\n",
      "loss: 0.067796  [19264/60000]\n",
      "loss: 0.019372  [25664/60000]\n",
      "loss: 0.047443  [32064/60000]\n",
      "loss: 0.093006  [38464/60000]\n",
      "loss: 0.016866  [44864/60000]\n",
      "loss: 0.007552  [51264/60000]\n",
      "loss: 0.063408  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.585584 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.133842  [   64/60000]\n",
      "loss: 0.013290  [ 6464/60000]\n",
      "loss: 0.022312  [12864/60000]\n",
      "loss: 0.017519  [19264/60000]\n",
      "loss: 0.015392  [25664/60000]\n",
      "loss: 0.001555  [32064/60000]\n",
      "loss: 0.115087  [38464/60000]\n",
      "loss: 0.034076  [44864/60000]\n",
      "loss: 0.006282  [51264/60000]\n",
      "loss: 0.103821  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.614145 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.052605  [   64/60000]\n",
      "loss: 0.069634  [ 6464/60000]\n",
      "loss: 0.006872  [12864/60000]\n",
      "loss: 0.009336  [19264/60000]\n",
      "loss: 0.060551  [25664/60000]\n",
      "loss: 0.015465  [32064/60000]\n",
      "loss: 0.004220  [38464/60000]\n",
      "loss: 0.006090  [44864/60000]\n",
      "loss: 0.068594  [51264/60000]\n",
      "loss: 0.014532  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.631840 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.039313  [   64/60000]\n",
      "loss: 0.005479  [ 6464/60000]\n",
      "loss: 0.025514  [12864/60000]\n",
      "loss: 0.067705  [19264/60000]\n",
      "loss: 0.028703  [25664/60000]\n",
      "loss: 0.144382  [32064/60000]\n",
      "loss: 0.047938  [38464/60000]\n",
      "loss: 0.040711  [44864/60000]\n",
      "loss: 0.019148  [51264/60000]\n",
      "loss: 0.008457  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.550705 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.016470  [   64/60000]\n",
      "loss: 0.013896  [ 6464/60000]\n",
      "loss: 0.039091  [12864/60000]\n",
      "loss: 0.035641  [19264/60000]\n",
      "loss: 0.011247  [25664/60000]\n",
      "loss: 0.028117  [32064/60000]\n",
      "loss: 0.008841  [38464/60000]\n",
      "loss: 0.069814  [44864/60000]\n",
      "loss: 0.019640  [51264/60000]\n",
      "loss: 0.031786  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.571397 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.010018  [   64/60000]\n",
      "loss: 0.026455  [ 6464/60000]\n",
      "loss: 0.053288  [12864/60000]\n",
      "loss: 0.015829  [19264/60000]\n",
      "loss: 0.042280  [25664/60000]\n",
      "loss: 0.156388  [32064/60000]\n",
      "loss: 0.010178  [38464/60000]\n",
      "loss: 0.084438  [44864/60000]\n",
      "loss: 0.027213  [51264/60000]\n",
      "loss: 0.044969  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.595319 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.039588  [   64/60000]\n",
      "loss: 0.053067  [ 6464/60000]\n",
      "loss: 0.013809  [12864/60000]\n",
      "loss: 0.054438  [19264/60000]\n",
      "loss: 0.031224  [25664/60000]\n",
      "loss: 0.053510  [32064/60000]\n",
      "loss: 0.023031  [38464/60000]\n",
      "loss: 0.020648  [44864/60000]\n",
      "loss: 0.006145  [51264/60000]\n",
      "loss: 0.132390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.622803 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.013778  [   64/60000]\n",
      "loss: 0.022960  [ 6464/60000]\n",
      "loss: 0.028670  [12864/60000]\n",
      "loss: 0.141006  [19264/60000]\n",
      "loss: 0.062754  [25664/60000]\n",
      "loss: 0.036093  [32064/60000]\n",
      "loss: 0.043170  [38464/60000]\n",
      "loss: 0.015506  [44864/60000]\n",
      "loss: 0.013889  [51264/60000]\n",
      "loss: 0.019642  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.597144 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.040222  [   64/60000]\n",
      "loss: 0.024962  [ 6464/60000]\n",
      "loss: 0.071970  [12864/60000]\n",
      "loss: 0.056832  [19264/60000]\n",
      "loss: 0.018210  [25664/60000]\n",
      "loss: 0.056864  [32064/60000]\n",
      "loss: 0.032893  [38464/60000]\n",
      "loss: 0.027857  [44864/60000]\n",
      "loss: 0.011568  [51264/60000]\n",
      "loss: 0.032873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.587072 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.020982  [   64/60000]\n",
      "loss: 0.002622  [ 6464/60000]\n",
      "loss: 0.078150  [12864/60000]\n",
      "loss: 0.026546  [19264/60000]\n",
      "loss: 0.130441  [25664/60000]\n",
      "loss: 0.112955  [32064/60000]\n",
      "loss: 0.058369  [38464/60000]\n",
      "loss: 0.020864  [44864/60000]\n",
      "loss: 0.043802  [51264/60000]\n",
      "loss: 0.007096  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.602295 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.044271  [   64/60000]\n",
      "loss: 0.002462  [ 6464/60000]\n",
      "loss: 0.010861  [12864/60000]\n",
      "loss: 0.062066  [19264/60000]\n",
      "loss: 0.054687  [25664/60000]\n",
      "loss: 0.055734  [32064/60000]\n",
      "loss: 0.004539  [38464/60000]\n",
      "loss: 0.050334  [44864/60000]\n",
      "loss: 0.013300  [51264/60000]\n",
      "loss: 0.018960  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.631526 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.017125  [   64/60000]\n",
      "loss: 0.022607  [ 6464/60000]\n",
      "loss: 0.009378  [12864/60000]\n",
      "loss: 0.019962  [19264/60000]\n",
      "loss: 0.015703  [25664/60000]\n",
      "loss: 0.010953  [32064/60000]\n",
      "loss: 0.047823  [38464/60000]\n",
      "loss: 0.084568  [44864/60000]\n",
      "loss: 0.014014  [51264/60000]\n",
      "loss: 0.003038  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.601549 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.031903  [   64/60000]\n",
      "loss: 0.013349  [ 6464/60000]\n",
      "loss: 0.013027  [12864/60000]\n",
      "loss: 0.029658  [19264/60000]\n",
      "loss: 0.010568  [25664/60000]\n",
      "loss: 0.013663  [32064/60000]\n",
      "loss: 0.008467  [38464/60000]\n",
      "loss: 0.021446  [44864/60000]\n",
      "loss: 0.015519  [51264/60000]\n",
      "loss: 0.100713  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.628198 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.044814  [   64/60000]\n",
      "loss: 0.019260  [ 6464/60000]\n",
      "loss: 0.046643  [12864/60000]\n",
      "loss: 0.022425  [19264/60000]\n",
      "loss: 0.077342  [25664/60000]\n",
      "loss: 0.062678  [32064/60000]\n",
      "loss: 0.024706  [38464/60000]\n",
      "loss: 0.084574  [44864/60000]\n",
      "loss: 0.020083  [51264/60000]\n",
      "loss: 0.007785  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.627401 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.042165  [   64/60000]\n",
      "loss: 0.047919  [ 6464/60000]\n",
      "loss: 0.016268  [12864/60000]\n",
      "loss: 0.005781  [19264/60000]\n",
      "loss: 0.010293  [25664/60000]\n",
      "loss: 0.005347  [32064/60000]\n",
      "loss: 0.018358  [38464/60000]\n",
      "loss: 0.059855  [44864/60000]\n",
      "loss: 0.055536  [51264/60000]\n",
      "loss: 0.004355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.630921 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.080251  [   64/60000]\n",
      "loss: 0.070827  [ 6464/60000]\n",
      "loss: 0.032049  [12864/60000]\n",
      "loss: 0.011352  [19264/60000]\n",
      "loss: 0.002066  [25664/60000]\n",
      "loss: 0.084985  [32064/60000]\n",
      "loss: 0.019687  [38464/60000]\n",
      "loss: 0.009624  [44864/60000]\n",
      "loss: 0.014591  [51264/60000]\n",
      "loss: 0.017657  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.617364 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.019498  [   64/60000]\n",
      "loss: 0.008245  [ 6464/60000]\n",
      "loss: 0.015090  [12864/60000]\n",
      "loss: 0.011566  [19264/60000]\n",
      "loss: 0.156316  [25664/60000]\n",
      "loss: 0.040553  [32064/60000]\n",
      "loss: 0.002166  [38464/60000]\n",
      "loss: 0.006422  [44864/60000]\n",
      "loss: 0.001864  [51264/60000]\n",
      "loss: 0.016427  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.607092 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.038072  [   64/60000]\n",
      "loss: 0.029904  [ 6464/60000]\n",
      "loss: 0.006562  [12864/60000]\n",
      "loss: 0.030293  [19264/60000]\n",
      "loss: 0.034182  [25664/60000]\n",
      "loss: 0.026940  [32064/60000]\n",
      "loss: 0.008277  [38464/60000]\n",
      "loss: 0.008887  [44864/60000]\n",
      "loss: 0.026149  [51264/60000]\n",
      "loss: 0.053818  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.663164 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.003801  [   64/60000]\n",
      "loss: 0.042906  [ 6464/60000]\n",
      "loss: 0.003290  [12864/60000]\n",
      "loss: 0.001805  [19264/60000]\n",
      "loss: 0.094371  [25664/60000]\n",
      "loss: 0.011164  [32064/60000]\n",
      "loss: 0.186342  [38464/60000]\n",
      "loss: 0.023520  [44864/60000]\n",
      "loss: 0.026447  [51264/60000]\n",
      "loss: 0.004674  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.870402 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.248980  [   64/60000]\n",
      "loss: 0.040781  [ 6464/60000]\n",
      "loss: 0.007183  [12864/60000]\n",
      "loss: 0.012131  [19264/60000]\n",
      "loss: 0.002597  [25664/60000]\n",
      "loss: 0.008643  [32064/60000]\n",
      "loss: 0.011358  [38464/60000]\n",
      "loss: 0.009101  [44864/60000]\n",
      "loss: 0.005760  [51264/60000]\n",
      "loss: 0.015438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.670297 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.001893  [   64/60000]\n",
      "loss: 0.030801  [ 6464/60000]\n",
      "loss: 0.013134  [12864/60000]\n",
      "loss: 0.027774  [19264/60000]\n",
      "loss: 0.010278  [25664/60000]\n",
      "loss: 0.007164  [32064/60000]\n",
      "loss: 0.049436  [38464/60000]\n",
      "loss: 0.028645  [44864/60000]\n",
      "loss: 0.069927  [51264/60000]\n",
      "loss: 0.029374  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.691109 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.042706  [   64/60000]\n",
      "loss: 0.005083  [ 6464/60000]\n",
      "loss: 0.053657  [12864/60000]\n",
      "loss: 0.014934  [19264/60000]\n",
      "loss: 0.032310  [25664/60000]\n",
      "loss: 0.013867  [32064/60000]\n",
      "loss: 0.014150  [38464/60000]\n",
      "loss: 0.000903  [44864/60000]\n",
      "loss: 0.108420  [51264/60000]\n",
      "loss: 0.018607  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.658069 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.078787  [   64/60000]\n",
      "loss: 0.016787  [ 6464/60000]\n",
      "loss: 0.038169  [12864/60000]\n",
      "loss: 0.028279  [19264/60000]\n",
      "loss: 0.011595  [25664/60000]\n",
      "loss: 0.046780  [32064/60000]\n",
      "loss: 0.001295  [38464/60000]\n",
      "loss: 0.000909  [44864/60000]\n",
      "loss: 0.022033  [51264/60000]\n",
      "loss: 0.044859  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.647640 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.002545  [   64/60000]\n",
      "loss: 0.037053  [ 6464/60000]\n",
      "loss: 0.091803  [12864/60000]\n",
      "loss: 0.023337  [19264/60000]\n",
      "loss: 0.067420  [25664/60000]\n",
      "loss: 0.051336  [32064/60000]\n",
      "loss: 0.093404  [38464/60000]\n",
      "loss: 0.011615  [44864/60000]\n",
      "loss: 0.010667  [51264/60000]\n",
      "loss: 0.044529  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.627580 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.008309  [   64/60000]\n",
      "loss: 0.111427  [ 6464/60000]\n",
      "loss: 0.044058  [12864/60000]\n",
      "loss: 0.079517  [19264/60000]\n",
      "loss: 0.012865  [25664/60000]\n",
      "loss: 0.009600  [32064/60000]\n",
      "loss: 0.023227  [38464/60000]\n",
      "loss: 0.046585  [44864/60000]\n",
      "loss: 0.005633  [51264/60000]\n",
      "loss: 0.011317  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.695298 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.006322  [   64/60000]\n",
      "loss: 0.016175  [ 6464/60000]\n",
      "loss: 0.039978  [12864/60000]\n",
      "loss: 0.010670  [19264/60000]\n",
      "loss: 0.135862  [25664/60000]\n",
      "loss: 0.121319  [32064/60000]\n",
      "loss: 0.009205  [38464/60000]\n",
      "loss: 0.025413  [44864/60000]\n",
      "loss: 0.028412  [51264/60000]\n",
      "loss: 0.005618  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.690184 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.005918  [   64/60000]\n",
      "loss: 0.032326  [ 6464/60000]\n",
      "loss: 0.001496  [12864/60000]\n",
      "loss: 0.006483  [19264/60000]\n",
      "loss: 0.007429  [25664/60000]\n",
      "loss: 0.019555  [32064/60000]\n",
      "loss: 0.002081  [38464/60000]\n",
      "loss: 0.013106  [44864/60000]\n",
      "loss: 0.004950  [51264/60000]\n",
      "loss: 0.027976  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.748638 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.058427  [   64/60000]\n",
      "loss: 0.027184  [ 6464/60000]\n",
      "loss: 0.004302  [12864/60000]\n",
      "loss: 0.002623  [19264/60000]\n",
      "loss: 0.195084  [25664/60000]\n",
      "loss: 0.067965  [32064/60000]\n",
      "loss: 0.097062  [38464/60000]\n",
      "loss: 0.021440  [44864/60000]\n",
      "loss: 0.019894  [51264/60000]\n",
      "loss: 0.141498  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.699088 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.010484  [   64/60000]\n",
      "loss: 0.012420  [ 6464/60000]\n",
      "loss: 0.006163  [12864/60000]\n",
      "loss: 0.022221  [19264/60000]\n",
      "loss: 0.027044  [25664/60000]\n",
      "loss: 0.004381  [32064/60000]\n",
      "loss: 0.007047  [38464/60000]\n",
      "loss: 0.002062  [44864/60000]\n",
      "loss: 0.008657  [51264/60000]\n",
      "loss: 0.011396  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.892652 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.210759  [   64/60000]\n",
      "loss: 0.109471  [ 6464/60000]\n",
      "loss: 0.015972  [12864/60000]\n",
      "loss: 0.011331  [19264/60000]\n",
      "loss: 0.014873  [25664/60000]\n",
      "loss: 0.004803  [32064/60000]\n",
      "loss: 0.014619  [38464/60000]\n",
      "loss: 0.008576  [44864/60000]\n",
      "loss: 0.003965  [51264/60000]\n",
      "loss: 0.001181  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.685452 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.008060  [   64/60000]\n",
      "loss: 0.000219  [ 6464/60000]\n",
      "loss: 0.001091  [12864/60000]\n",
      "loss: 0.003997  [19264/60000]\n",
      "loss: 0.010821  [25664/60000]\n",
      "loss: 0.003959  [32064/60000]\n",
      "loss: 0.111893  [38464/60000]\n",
      "loss: 0.012903  [44864/60000]\n",
      "loss: 0.003396  [51264/60000]\n",
      "loss: 0.047731  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.805823 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.103328  [   64/60000]\n",
      "loss: 0.005643  [ 6464/60000]\n",
      "loss: 0.021923  [12864/60000]\n",
      "loss: 0.005171  [19264/60000]\n",
      "loss: 0.015491  [25664/60000]\n",
      "loss: 0.001832  [32064/60000]\n",
      "loss: 0.035347  [38464/60000]\n",
      "loss: 0.012579  [44864/60000]\n",
      "loss: 0.061723  [51264/60000]\n",
      "loss: 0.012653  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.670377 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.010586  [   64/60000]\n",
      "loss: 0.000886  [ 6464/60000]\n",
      "loss: 0.008114  [12864/60000]\n",
      "loss: 0.011653  [19264/60000]\n",
      "loss: 0.004025  [25664/60000]\n",
      "loss: 0.064932  [32064/60000]\n",
      "loss: 0.002038  [38464/60000]\n",
      "loss: 0.059823  [44864/60000]\n",
      "loss: 0.001347  [51264/60000]\n",
      "loss: 0.023570  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.692752 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.065544  [   64/60000]\n",
      "loss: 0.005153  [ 6464/60000]\n",
      "loss: 0.018227  [12864/60000]\n",
      "loss: 0.001194  [19264/60000]\n",
      "loss: 0.028202  [25664/60000]\n",
      "loss: 0.040327  [32064/60000]\n",
      "loss: 0.037446  [38464/60000]\n",
      "loss: 0.014717  [44864/60000]\n",
      "loss: 0.006108  [51264/60000]\n",
      "loss: 0.026179  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.694425 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.046699  [   64/60000]\n",
      "loss: 0.010335  [ 6464/60000]\n",
      "loss: 0.032869  [12864/60000]\n",
      "loss: 0.001721  [19264/60000]\n",
      "loss: 0.001143  [25664/60000]\n",
      "loss: 0.002001  [32064/60000]\n",
      "loss: 0.001861  [38464/60000]\n",
      "loss: 0.034907  [44864/60000]\n",
      "loss: 0.032316  [51264/60000]\n",
      "loss: 0.381415  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.692660 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.027431  [   64/60000]\n",
      "loss: 0.016602  [ 6464/60000]\n",
      "loss: 0.004308  [12864/60000]\n",
      "loss: 0.030712  [19264/60000]\n",
      "loss: 0.025233  [25664/60000]\n",
      "loss: 0.004787  [32064/60000]\n",
      "loss: 0.007228  [38464/60000]\n",
      "loss: 0.002944  [44864/60000]\n",
      "loss: 0.003614  [51264/60000]\n",
      "loss: 0.001638  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.762881 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.009179  [   64/60000]\n",
      "loss: 0.016303  [ 6464/60000]\n",
      "loss: 0.114584  [12864/60000]\n",
      "loss: 0.023467  [19264/60000]\n",
      "loss: 0.010354  [25664/60000]\n",
      "loss: 0.004380  [32064/60000]\n",
      "loss: 0.006013  [38464/60000]\n",
      "loss: 0.032701  [44864/60000]\n",
      "loss: 0.013721  [51264/60000]\n",
      "loss: 0.007242  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.691807 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.005633  [   64/60000]\n",
      "loss: 0.026704  [ 6464/60000]\n",
      "loss: 0.003826  [12864/60000]\n",
      "loss: 0.080881  [19264/60000]\n",
      "loss: 0.025693  [25664/60000]\n",
      "loss: 0.018777  [32064/60000]\n",
      "loss: 0.002808  [38464/60000]\n",
      "loss: 0.007708  [44864/60000]\n",
      "loss: 0.061517  [51264/60000]\n",
      "loss: 0.001560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.752247 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.003797  [   64/60000]\n",
      "loss: 0.023878  [ 6464/60000]\n",
      "loss: 0.008497  [12864/60000]\n",
      "loss: 0.010118  [19264/60000]\n",
      "loss: 0.065508  [25664/60000]\n",
      "loss: 0.008378  [32064/60000]\n",
      "loss: 0.013568  [38464/60000]\n",
      "loss: 0.004814  [44864/60000]\n",
      "loss: 0.009982  [51264/60000]\n",
      "loss: 0.000704  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.690832 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.001969  [   64/60000]\n",
      "loss: 0.005725  [ 6464/60000]\n",
      "loss: 0.001948  [12864/60000]\n",
      "loss: 0.002399  [19264/60000]\n",
      "loss: 0.001880  [25664/60000]\n",
      "loss: 0.034055  [32064/60000]\n",
      "loss: 0.017231  [38464/60000]\n",
      "loss: 0.002146  [44864/60000]\n",
      "loss: 0.002645  [51264/60000]\n",
      "loss: 0.007167  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.700794 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.004060  [   64/60000]\n",
      "loss: 0.002006  [ 6464/60000]\n",
      "loss: 0.000914  [12864/60000]\n",
      "loss: 0.002064  [19264/60000]\n",
      "loss: 0.002177  [25664/60000]\n",
      "loss: 0.010104  [32064/60000]\n",
      "loss: 0.080828  [38464/60000]\n",
      "loss: 0.002408  [44864/60000]\n",
      "loss: 0.028120  [51264/60000]\n",
      "loss: 0.129133  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.717425 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.005749  [   64/60000]\n",
      "loss: 0.012657  [ 6464/60000]\n",
      "loss: 0.001871  [12864/60000]\n",
      "loss: 0.010917  [19264/60000]\n",
      "loss: 0.018669  [25664/60000]\n",
      "loss: 0.001823  [32064/60000]\n",
      "loss: 0.008455  [38464/60000]\n",
      "loss: 0.009597  [44864/60000]\n",
      "loss: 0.003507  [51264/60000]\n",
      "loss: 0.044189  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.731525 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.004244  [   64/60000]\n",
      "loss: 0.002002  [ 6464/60000]\n",
      "loss: 0.013527  [12864/60000]\n",
      "loss: 0.000129  [19264/60000]\n",
      "loss: 0.002312  [25664/60000]\n",
      "loss: 0.050317  [32064/60000]\n",
      "loss: 0.004271  [38464/60000]\n",
      "loss: 0.015823  [44864/60000]\n",
      "loss: 0.001831  [51264/60000]\n",
      "loss: 0.007234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.710686 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.003678  [   64/60000]\n",
      "loss: 0.028367  [ 6464/60000]\n",
      "loss: 0.006152  [12864/60000]\n",
      "loss: 0.003319  [19264/60000]\n",
      "loss: 0.007600  [25664/60000]\n",
      "loss: 0.001834  [32064/60000]\n",
      "loss: 0.002447  [38464/60000]\n",
      "loss: 0.004671  [44864/60000]\n",
      "loss: 0.001892  [51264/60000]\n",
      "loss: 0.031898  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.753184 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.004524  [   64/60000]\n",
      "loss: 0.011849  [ 6464/60000]\n",
      "loss: 0.000554  [12864/60000]\n",
      "loss: 0.002202  [19264/60000]\n",
      "loss: 0.021057  [25664/60000]\n",
      "loss: 0.018841  [32064/60000]\n",
      "loss: 0.003046  [38464/60000]\n",
      "loss: 0.057931  [44864/60000]\n",
      "loss: 0.004090  [51264/60000]\n",
      "loss: 0.074075  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.756805 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.019093  [   64/60000]\n",
      "loss: 0.021323  [ 6464/60000]\n",
      "loss: 0.004585  [12864/60000]\n",
      "loss: 0.005425  [19264/60000]\n",
      "loss: 0.002288  [25664/60000]\n",
      "loss: 0.000206  [32064/60000]\n",
      "loss: 0.002461  [38464/60000]\n",
      "loss: 0.000479  [44864/60000]\n",
      "loss: 0.000688  [51264/60000]\n",
      "loss: 0.026956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.768883 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.007329  [   64/60000]\n",
      "loss: 0.000362  [ 6464/60000]\n",
      "loss: 0.004189  [12864/60000]\n",
      "loss: 0.000758  [19264/60000]\n",
      "loss: 0.001350  [25664/60000]\n",
      "loss: 0.000546  [32064/60000]\n",
      "loss: 0.006057  [38464/60000]\n",
      "loss: 0.000372  [44864/60000]\n",
      "loss: 0.002176  [51264/60000]\n",
      "loss: 0.052692  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.924578 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.286112  [   64/60000]\n",
      "loss: 0.000425  [ 6464/60000]\n",
      "loss: 0.010218  [12864/60000]\n",
      "loss: 0.008486  [19264/60000]\n",
      "loss: 1.104743  [25664/60000]\n",
      "loss: 0.008547  [32064/60000]\n",
      "loss: 0.074418  [38464/60000]\n",
      "loss: 0.036557  [44864/60000]\n",
      "loss: 0.025478  [51264/60000]\n",
      "loss: 0.046409  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.821507 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.230861  [   64/60000]\n",
      "loss: 0.004931  [ 6464/60000]\n",
      "loss: 0.068194  [12864/60000]\n",
      "loss: 0.120804  [19264/60000]\n",
      "loss: 0.039888  [25664/60000]\n",
      "loss: 0.002163  [32064/60000]\n",
      "loss: 0.004833  [38464/60000]\n",
      "loss: 0.011839  [44864/60000]\n",
      "loss: 0.011985  [51264/60000]\n",
      "loss: 0.001061  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.723466 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.070162  [   64/60000]\n",
      "loss: 0.010357  [ 6464/60000]\n",
      "loss: 0.003814  [12864/60000]\n",
      "loss: 0.002857  [19264/60000]\n",
      "loss: 0.002375  [25664/60000]\n",
      "loss: 0.083784  [32064/60000]\n",
      "loss: 0.053789  [38464/60000]\n",
      "loss: 0.058528  [44864/60000]\n",
      "loss: 0.001348  [51264/60000]\n",
      "loss: 0.007320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.744925 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.001265  [   64/60000]\n",
      "loss: 0.001243  [ 6464/60000]\n",
      "loss: 0.001700  [12864/60000]\n",
      "loss: 0.028170  [19264/60000]\n",
      "loss: 0.004094  [25664/60000]\n",
      "loss: 0.001558  [32064/60000]\n",
      "loss: 0.001778  [38464/60000]\n",
      "loss: 0.000203  [44864/60000]\n",
      "loss: 0.000618  [51264/60000]\n",
      "loss: 0.000156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.749800 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.012199  [   64/60000]\n",
      "loss: 0.000548  [ 6464/60000]\n",
      "loss: 0.019520  [12864/60000]\n",
      "loss: 0.000296  [19264/60000]\n",
      "loss: 0.000158  [25664/60000]\n",
      "loss: 0.000350  [32064/60000]\n",
      "loss: 0.001020  [38464/60000]\n",
      "loss: 0.003896  [44864/60000]\n",
      "loss: 0.003406  [51264/60000]\n",
      "loss: 0.013487  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.744668 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.001863  [   64/60000]\n",
      "loss: 0.003198  [ 6464/60000]\n",
      "loss: 0.002654  [12864/60000]\n",
      "loss: 0.000416  [19264/60000]\n",
      "loss: 0.008298  [25664/60000]\n",
      "loss: 0.001577  [32064/60000]\n",
      "loss: 0.002430  [38464/60000]\n",
      "loss: 0.000127  [44864/60000]\n",
      "loss: 0.007353  [51264/60000]\n",
      "loss: 0.000980  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.783114 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.000936  [   64/60000]\n",
      "loss: 0.014207  [ 6464/60000]\n",
      "loss: 0.001822  [12864/60000]\n",
      "loss: 0.001800  [19264/60000]\n",
      "loss: 0.000548  [25664/60000]\n",
      "loss: 0.006533  [32064/60000]\n",
      "loss: 0.003729  [38464/60000]\n",
      "loss: 0.002218  [44864/60000]\n",
      "loss: 0.023754  [51264/60000]\n",
      "loss: 0.000495  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.811750 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.000429  [   64/60000]\n",
      "loss: 0.000485  [ 6464/60000]\n",
      "loss: 0.001045  [12864/60000]\n",
      "loss: 0.007360  [19264/60000]\n",
      "loss: 0.002182  [25664/60000]\n",
      "loss: 0.001184  [32064/60000]\n",
      "loss: 0.003416  [38464/60000]\n",
      "loss: 0.001589  [44864/60000]\n",
      "loss: 0.000757  [51264/60000]\n",
      "loss: 0.000757  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.805521 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.001369  [   64/60000]\n",
      "loss: 0.000168  [ 6464/60000]\n",
      "loss: 0.000241  [12864/60000]\n",
      "loss: 0.000255  [19264/60000]\n",
      "loss: 0.000133  [25664/60000]\n",
      "loss: 0.001302  [32064/60000]\n",
      "loss: 0.000662  [38464/60000]\n",
      "loss: 0.000911  [44864/60000]\n",
      "loss: 0.000492  [51264/60000]\n",
      "loss: 0.000506  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.869539 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000766  [   64/60000]\n",
      "loss: 0.009838  [ 6464/60000]\n",
      "loss: 0.006343  [12864/60000]\n",
      "loss: 0.029170  [19264/60000]\n",
      "loss: 0.051404  [25664/60000]\n",
      "loss: 0.038010  [32064/60000]\n",
      "loss: 0.022127  [38464/60000]\n",
      "loss: 0.009490  [44864/60000]\n",
      "loss: 0.048183  [51264/60000]\n",
      "loss: 0.003857  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.754799 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.008574  [   64/60000]\n",
      "loss: 0.005130  [ 6464/60000]\n",
      "loss: 0.000163  [12864/60000]\n",
      "loss: 0.000281  [19264/60000]\n",
      "loss: 0.001178  [25664/60000]\n",
      "loss: 0.006161  [32064/60000]\n",
      "loss: 0.000998  [38464/60000]\n",
      "loss: 0.001042  [44864/60000]\n",
      "loss: 0.013460  [51264/60000]\n",
      "loss: 0.023414  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.793040 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.000593  [   64/60000]\n",
      "loss: 0.001622  [ 6464/60000]\n",
      "loss: 0.003431  [12864/60000]\n",
      "loss: 0.016593  [19264/60000]\n",
      "loss: 0.040927  [25664/60000]\n",
      "loss: 0.001289  [32064/60000]\n",
      "loss: 0.097327  [38464/60000]\n",
      "loss: 0.058030  [44864/60000]\n",
      "loss: 0.006853  [51264/60000]\n",
      "loss: 0.011625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.969663 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.040402  [   64/60000]\n",
      "loss: 0.007520  [ 6464/60000]\n",
      "loss: 0.001435  [12864/60000]\n",
      "loss: 0.002105  [19264/60000]\n",
      "loss: 0.035825  [25664/60000]\n",
      "loss: 0.014024  [32064/60000]\n",
      "loss: 0.053255  [38464/60000]\n",
      "loss: 0.029141  [44864/60000]\n",
      "loss: 0.028261  [51264/60000]\n",
      "loss: 0.069288  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.723543 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.023256  [   64/60000]\n",
      "loss: 0.003496  [ 6464/60000]\n",
      "loss: 0.000125  [12864/60000]\n",
      "loss: 0.005696  [19264/60000]\n",
      "loss: 0.002488  [25664/60000]\n",
      "loss: 0.001170  [32064/60000]\n",
      "loss: 0.016898  [38464/60000]\n",
      "loss: 0.000166  [44864/60000]\n",
      "loss: 0.000616  [51264/60000]\n",
      "loss: 0.000297  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.786815 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.000507  [   64/60000]\n",
      "loss: 0.000223  [ 6464/60000]\n",
      "loss: 0.001096  [12864/60000]\n",
      "loss: 0.002200  [19264/60000]\n",
      "loss: 0.000024  [25664/60000]\n",
      "loss: 0.050160  [32064/60000]\n",
      "loss: 0.000831  [38464/60000]\n",
      "loss: 0.000248  [44864/60000]\n",
      "loss: 0.000231  [51264/60000]\n",
      "loss: 0.007161  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.784868 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.000180  [   64/60000]\n",
      "loss: 0.000186  [ 6464/60000]\n",
      "loss: 0.000896  [12864/60000]\n",
      "loss: 0.004212  [19264/60000]\n",
      "loss: 0.000600  [25664/60000]\n",
      "loss: 0.000224  [32064/60000]\n",
      "loss: 0.000313  [38464/60000]\n",
      "loss: 0.006865  [44864/60000]\n",
      "loss: 0.000171  [51264/60000]\n",
      "loss: 0.000390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.819838 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.001324  [   64/60000]\n",
      "loss: 0.000102  [ 6464/60000]\n",
      "loss: 0.000206  [12864/60000]\n",
      "loss: 0.000342  [19264/60000]\n",
      "loss: 0.000279  [25664/60000]\n",
      "loss: 0.000223  [32064/60000]\n",
      "loss: 0.001608  [38464/60000]\n",
      "loss: 0.000398  [44864/60000]\n",
      "loss: 0.000053  [51264/60000]\n",
      "loss: 0.000846  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.836413 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.000407  [   64/60000]\n",
      "loss: 0.003925  [ 6464/60000]\n",
      "loss: 0.000121  [12864/60000]\n",
      "loss: 0.000076  [19264/60000]\n",
      "loss: 0.000328  [25664/60000]\n",
      "loss: 0.000101  [32064/60000]\n",
      "loss: 0.000231  [38464/60000]\n",
      "loss: 0.000140  [44864/60000]\n",
      "loss: 0.000105  [51264/60000]\n",
      "loss: 0.000337  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.845878 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.001328  [   64/60000]\n",
      "loss: 0.000312  [ 6464/60000]\n",
      "loss: 0.001018  [12864/60000]\n",
      "loss: 0.044276  [19264/60000]\n",
      "loss: 0.002685  [25664/60000]\n",
      "loss: 0.000317  [32064/60000]\n",
      "loss: 0.000320  [38464/60000]\n",
      "loss: 0.000872  [44864/60000]\n",
      "loss: 0.000825  [51264/60000]\n",
      "loss: 0.000066  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.843914 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.000100  [   64/60000]\n",
      "loss: 0.000069  [ 6464/60000]\n",
      "loss: 0.003342  [12864/60000]\n",
      "loss: 0.001871  [19264/60000]\n",
      "loss: 0.000618  [25664/60000]\n",
      "loss: 0.000351  [32064/60000]\n",
      "loss: 0.002583  [38464/60000]\n",
      "loss: 0.000089  [44864/60000]\n",
      "loss: 0.000260  [51264/60000]\n",
      "loss: 0.000353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.857560 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.000518  [   64/60000]\n",
      "loss: 0.000169  [ 6464/60000]\n",
      "loss: 0.000133  [12864/60000]\n",
      "loss: 0.000194  [19264/60000]\n",
      "loss: 0.000305  [25664/60000]\n",
      "loss: 0.000645  [32064/60000]\n",
      "loss: 0.000169  [38464/60000]\n",
      "loss: 0.000030  [44864/60000]\n",
      "loss: 0.000857  [51264/60000]\n",
      "loss: 0.000355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.878414 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.000422  [   64/60000]\n",
      "loss: 0.000025  [ 6464/60000]\n",
      "loss: 0.000119  [12864/60000]\n",
      "loss: 0.000167  [19264/60000]\n",
      "loss: 0.000069  [25664/60000]\n",
      "loss: 0.000741  [32064/60000]\n",
      "loss: 0.000316  [38464/60000]\n",
      "loss: 0.000179  [44864/60000]\n",
      "loss: 0.000096  [51264/60000]\n",
      "loss: 0.000076  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.885772 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.000057  [   64/60000]\n",
      "loss: 0.000602  [ 6464/60000]\n",
      "loss: 0.000412  [12864/60000]\n",
      "loss: 0.000612  [19264/60000]\n",
      "loss: 0.000163  [25664/60000]\n",
      "loss: 0.000097  [32064/60000]\n",
      "loss: 0.000093  [38464/60000]\n",
      "loss: 0.000118  [44864/60000]\n",
      "loss: 0.000334  [51264/60000]\n",
      "loss: 0.000240  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.881485 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.000542  [   64/60000]\n",
      "loss: 0.000553  [ 6464/60000]\n",
      "loss: 0.000177  [12864/60000]\n",
      "loss: 0.001708  [19264/60000]\n",
      "loss: 0.000059  [25664/60000]\n",
      "loss: 0.000170  [32064/60000]\n",
      "loss: 0.001135  [38464/60000]\n",
      "loss: 0.000081  [44864/60000]\n",
      "loss: 0.000788  [51264/60000]\n",
      "loss: 0.000050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.890122 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.000262  [   64/60000]\n",
      "loss: 0.000091  [ 6464/60000]\n",
      "loss: 0.000041  [12864/60000]\n",
      "loss: 0.000162  [19264/60000]\n",
      "loss: 0.000326  [25664/60000]\n",
      "loss: 0.000026  [32064/60000]\n",
      "loss: 0.000151  [38464/60000]\n",
      "loss: 0.000120  [44864/60000]\n",
      "loss: 0.000043  [51264/60000]\n",
      "loss: 0.000033  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.891731 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000166  [   64/60000]\n",
      "loss: 0.000016  [ 6464/60000]\n",
      "loss: 0.000306  [12864/60000]\n",
      "loss: 0.000025  [19264/60000]\n",
      "loss: 0.000487  [25664/60000]\n",
      "loss: 0.000144  [32064/60000]\n",
      "loss: 0.000139  [38464/60000]\n",
      "loss: 0.000188  [44864/60000]\n",
      "loss: 0.000182  [51264/60000]\n",
      "loss: 0.000087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.895327 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000083  [   64/60000]\n",
      "loss: 0.000035  [ 6464/60000]\n",
      "loss: 0.000396  [12864/60000]\n",
      "loss: 0.000108  [19264/60000]\n",
      "loss: 0.000052  [25664/60000]\n",
      "loss: 0.000301  [32064/60000]\n",
      "loss: 0.000217  [38464/60000]\n",
      "loss: 0.000073  [44864/60000]\n",
      "loss: 0.000170  [51264/60000]\n",
      "loss: 0.000031  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.904108 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.000022  [   64/60000]\n",
      "loss: 0.000095  [ 6464/60000]\n",
      "loss: 0.000108  [12864/60000]\n",
      "loss: 0.000111  [19264/60000]\n",
      "loss: 0.000260  [25664/60000]\n",
      "loss: 0.000110  [32064/60000]\n",
      "loss: 0.000201  [38464/60000]\n",
      "loss: 0.000044  [44864/60000]\n",
      "loss: 0.000362  [51264/60000]\n",
      "loss: 0.000027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.911659 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.000054  [   64/60000]\n",
      "loss: 0.000077  [ 6464/60000]\n",
      "loss: 0.000163  [12864/60000]\n",
      "loss: 0.000024  [19264/60000]\n",
      "loss: 0.000618  [25664/60000]\n",
      "loss: 0.000073  [32064/60000]\n",
      "loss: 0.000266  [38464/60000]\n",
      "loss: 0.000103  [44864/60000]\n",
      "loss: 0.000034  [51264/60000]\n",
      "loss: 0.000068  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.920124 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.000492  [   64/60000]\n",
      "loss: 0.000013  [ 6464/60000]\n",
      "loss: 0.000160  [12864/60000]\n",
      "loss: 0.000215  [19264/60000]\n",
      "loss: 0.000367  [25664/60000]\n",
      "loss: 0.000659  [32064/60000]\n",
      "loss: 0.000409  [38464/60000]\n",
      "loss: 0.000153  [44864/60000]\n",
      "loss: 0.000621  [51264/60000]\n",
      "loss: 0.000460  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.916260 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.000186  [   64/60000]\n",
      "loss: 0.000851  [ 6464/60000]\n",
      "loss: 0.000066  [12864/60000]\n",
      "loss: 0.000197  [19264/60000]\n",
      "loss: 0.000083  [25664/60000]\n",
      "loss: 0.000071  [32064/60000]\n",
      "loss: 0.000016  [38464/60000]\n",
      "loss: 0.000220  [44864/60000]\n",
      "loss: 0.000143  [51264/60000]\n",
      "loss: 0.000031  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.920728 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000083  [   64/60000]\n",
      "loss: 0.000190  [ 6464/60000]\n",
      "loss: 0.000087  [12864/60000]\n",
      "loss: 0.000049  [19264/60000]\n",
      "loss: 0.000232  [25664/60000]\n",
      "loss: 0.000016  [32064/60000]\n",
      "loss: 0.000223  [38464/60000]\n",
      "loss: 0.000204  [44864/60000]\n",
      "loss: 0.000048  [51264/60000]\n",
      "loss: 0.000018  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.928856 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.000098  [   64/60000]\n",
      "loss: 0.000277  [ 6464/60000]\n",
      "loss: 0.000037  [12864/60000]\n",
      "loss: 0.000293  [19264/60000]\n",
      "loss: 0.000109  [25664/60000]\n",
      "loss: 0.000117  [32064/60000]\n",
      "loss: 0.000281  [38464/60000]\n",
      "loss: 0.000016  [44864/60000]\n",
      "loss: 0.000043  [51264/60000]\n",
      "loss: 0.000065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.927319 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.000369  [   64/60000]\n",
      "loss: 0.000161  [ 6464/60000]\n",
      "loss: 0.000047  [12864/60000]\n",
      "loss: 0.000060  [19264/60000]\n",
      "loss: 0.000045  [25664/60000]\n",
      "loss: 0.000020  [32064/60000]\n",
      "loss: 0.000050  [38464/60000]\n",
      "loss: 0.000329  [44864/60000]\n",
      "loss: 0.000073  [51264/60000]\n",
      "loss: 0.000027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.933891 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.000014  [   64/60000]\n",
      "loss: 0.000184  [ 6464/60000]\n",
      "loss: 0.000028  [12864/60000]\n",
      "loss: 0.000174  [19264/60000]\n",
      "loss: 0.000025  [25664/60000]\n",
      "loss: 0.000261  [32064/60000]\n",
      "loss: 0.000117  [38464/60000]\n",
      "loss: 0.000085  [44864/60000]\n",
      "loss: 0.000145  [51264/60000]\n",
      "loss: 0.000047  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.935526 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.000264  [   64/60000]\n",
      "loss: 0.000129  [ 6464/60000]\n",
      "loss: 0.000009  [12864/60000]\n",
      "loss: 0.000061  [19264/60000]\n",
      "loss: 0.000013  [25664/60000]\n",
      "loss: 0.000005  [32064/60000]\n",
      "loss: 0.000022  [38464/60000]\n",
      "loss: 0.000036  [44864/60000]\n",
      "loss: 0.000047  [51264/60000]\n",
      "loss: 0.000369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.944261 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.000030  [   64/60000]\n",
      "loss: 0.000021  [ 6464/60000]\n",
      "loss: 0.000166  [12864/60000]\n",
      "loss: 0.000116  [19264/60000]\n",
      "loss: 0.000081  [25664/60000]\n",
      "loss: 0.000061  [32064/60000]\n",
      "loss: 0.000003  [38464/60000]\n",
      "loss: 0.000036  [44864/60000]\n",
      "loss: 0.000156  [51264/60000]\n",
      "loss: 0.000172  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.940689 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.000108  [   64/60000]\n",
      "loss: 0.000111  [ 6464/60000]\n",
      "loss: 0.000082  [12864/60000]\n",
      "loss: 0.000064  [19264/60000]\n",
      "loss: 0.000018  [25664/60000]\n",
      "loss: 0.000012  [32064/60000]\n",
      "loss: 0.000028  [38464/60000]\n",
      "loss: 0.000132  [44864/60000]\n",
      "loss: 0.000131  [51264/60000]\n",
      "loss: 0.000023  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.943748 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.000074  [   64/60000]\n",
      "loss: 0.000085  [ 6464/60000]\n",
      "loss: 0.000064  [12864/60000]\n",
      "loss: 0.000066  [19264/60000]\n",
      "loss: 0.000028  [25664/60000]\n",
      "loss: 0.000443  [32064/60000]\n",
      "loss: 0.000014  [38464/60000]\n",
      "loss: 0.000022  [44864/60000]\n",
      "loss: 0.000018  [51264/60000]\n",
      "loss: 0.000040  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.945390 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000160  [   64/60000]\n",
      "loss: 0.000085  [ 6464/60000]\n",
      "loss: 0.000056  [12864/60000]\n",
      "loss: 0.000138  [19264/60000]\n",
      "loss: 0.000063  [25664/60000]\n",
      "loss: 0.000049  [32064/60000]\n",
      "loss: 0.000173  [38464/60000]\n",
      "loss: 0.000016  [44864/60000]\n",
      "loss: 0.000093  [51264/60000]\n",
      "loss: 0.000107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.947039 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000029  [   64/60000]\n",
      "loss: 0.000050  [ 6464/60000]\n",
      "loss: 0.000022  [12864/60000]\n",
      "loss: 0.000140  [19264/60000]\n",
      "loss: 0.000069  [25664/60000]\n",
      "loss: 0.000097  [32064/60000]\n",
      "loss: 0.000776  [38464/60000]\n",
      "loss: 0.000008  [44864/60000]\n",
      "loss: 0.000007  [51264/60000]\n",
      "loss: 0.000054  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.949383 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.000092  [   64/60000]\n",
      "loss: 0.000178  [ 6464/60000]\n",
      "loss: 0.000356  [12864/60000]\n",
      "loss: 0.000035  [19264/60000]\n",
      "loss: 0.000087  [25664/60000]\n",
      "loss: 0.000004  [32064/60000]\n",
      "loss: 0.000117  [38464/60000]\n",
      "loss: 0.000023  [44864/60000]\n",
      "loss: 0.000049  [51264/60000]\n",
      "loss: 0.000026  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.955807 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000006  [   64/60000]\n",
      "loss: 0.000104  [ 6464/60000]\n",
      "loss: 0.000028  [12864/60000]\n",
      "loss: 0.000095  [19264/60000]\n",
      "loss: 0.000052  [25664/60000]\n",
      "loss: 0.000099  [32064/60000]\n",
      "loss: 0.000081  [38464/60000]\n",
      "loss: 0.000183  [44864/60000]\n",
      "loss: 0.000003  [51264/60000]\n",
      "loss: 0.000014  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.967921 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000043  [   64/60000]\n",
      "loss: 0.000028  [ 6464/60000]\n",
      "loss: 0.000004  [12864/60000]\n",
      "loss: 0.000106  [19264/60000]\n",
      "loss: 0.000180  [25664/60000]\n",
      "loss: 0.000006  [32064/60000]\n",
      "loss: 0.000059  [38464/60000]\n",
      "loss: 0.000008  [44864/60000]\n",
      "loss: 0.000608  [51264/60000]\n",
      "loss: 0.000015  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.963838 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.000121  [   64/60000]\n",
      "loss: 0.000009  [ 6464/60000]\n",
      "loss: 0.000020  [12864/60000]\n",
      "loss: 0.000061  [19264/60000]\n",
      "loss: 0.000027  [25664/60000]\n",
      "loss: 0.000132  [32064/60000]\n",
      "loss: 0.000037  [38464/60000]\n",
      "loss: 0.000077  [44864/60000]\n",
      "loss: 0.000064  [51264/60000]\n",
      "loss: 0.000121  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.970011 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.000015  [   64/60000]\n",
      "loss: 0.000052  [ 6464/60000]\n",
      "loss: 0.000032  [12864/60000]\n",
      "loss: 0.000083  [19264/60000]\n",
      "loss: 0.000048  [25664/60000]\n",
      "loss: 0.000141  [32064/60000]\n",
      "loss: 0.000097  [38464/60000]\n",
      "loss: 0.000110  [44864/60000]\n",
      "loss: 0.000031  [51264/60000]\n",
      "loss: 0.000094  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.963635 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000019  [   64/60000]\n",
      "loss: 0.000289  [ 6464/60000]\n",
      "loss: 0.000010  [12864/60000]\n",
      "loss: 0.000001  [19264/60000]\n",
      "loss: 0.000082  [25664/60000]\n",
      "loss: 0.000129  [32064/60000]\n",
      "loss: 0.000108  [38464/60000]\n",
      "loss: 0.000025  [44864/60000]\n",
      "loss: 0.000008  [51264/60000]\n",
      "loss: 0.000020  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.971722 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.000277  [   64/60000]\n",
      "loss: 0.000054  [ 6464/60000]\n",
      "loss: 0.000109  [12864/60000]\n",
      "loss: 0.000243  [19264/60000]\n",
      "loss: 0.000070  [25664/60000]\n",
      "loss: 0.000073  [32064/60000]\n",
      "loss: 0.000021  [38464/60000]\n",
      "loss: 0.000106  [44864/60000]\n",
      "loss: 0.000019  [51264/60000]\n",
      "loss: 0.000217  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.968727 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.000018  [   64/60000]\n",
      "loss: 0.000121  [ 6464/60000]\n",
      "loss: 0.000166  [12864/60000]\n",
      "loss: 0.000042  [19264/60000]\n",
      "loss: 0.000013  [25664/60000]\n",
      "loss: 0.000146  [32064/60000]\n",
      "loss: 0.000167  [38464/60000]\n",
      "loss: 0.000041  [44864/60000]\n",
      "loss: 0.000410  [51264/60000]\n",
      "loss: 0.000099  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.974155 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000022  [   64/60000]\n",
      "loss: 0.000008  [ 6464/60000]\n",
      "loss: 0.000067  [12864/60000]\n",
      "loss: 0.000014  [19264/60000]\n",
      "loss: 0.000061  [25664/60000]\n",
      "loss: 0.000083  [32064/60000]\n",
      "loss: 0.000105  [38464/60000]\n",
      "loss: 0.000077  [44864/60000]\n",
      "loss: 0.000018  [51264/60000]\n",
      "loss: 0.000127  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.972561 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000036  [   64/60000]\n",
      "loss: 0.000068  [ 6464/60000]\n",
      "loss: 0.000015  [12864/60000]\n",
      "loss: 0.000186  [19264/60000]\n",
      "loss: 0.000048  [25664/60000]\n",
      "loss: 0.000167  [32064/60000]\n",
      "loss: 0.000048  [38464/60000]\n",
      "loss: 0.000023  [44864/60000]\n",
      "loss: 0.000040  [51264/60000]\n",
      "loss: 0.000019  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.974636 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000087  [   64/60000]\n",
      "loss: 0.000076  [ 6464/60000]\n",
      "loss: 0.000334  [12864/60000]\n",
      "loss: 0.000027  [19264/60000]\n",
      "loss: 0.000119  [25664/60000]\n",
      "loss: 0.000203  [32064/60000]\n",
      "loss: 0.000014  [38464/60000]\n",
      "loss: 0.000022  [44864/60000]\n",
      "loss: 0.000097  [51264/60000]\n",
      "loss: 0.000107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.999336 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000029  [   64/60000]\n",
      "loss: 0.000037  [ 6464/60000]\n",
      "loss: 0.000140  [12864/60000]\n",
      "loss: 0.000019  [19264/60000]\n",
      "loss: 0.000004  [25664/60000]\n",
      "loss: 0.000024  [32064/60000]\n",
      "loss: 0.000103  [38464/60000]\n",
      "loss: 0.000006  [44864/60000]\n",
      "loss: 0.000036  [51264/60000]\n",
      "loss: 0.000011  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.977784 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000044  [   64/60000]\n",
      "loss: 0.000007  [ 6464/60000]\n",
      "loss: 0.000012  [12864/60000]\n",
      "loss: 0.000018  [19264/60000]\n",
      "loss: 0.000087  [25664/60000]\n",
      "loss: 0.000113  [32064/60000]\n",
      "loss: 0.000142  [38464/60000]\n",
      "loss: 0.000017  [44864/60000]\n",
      "loss: 0.000346  [51264/60000]\n",
      "loss: 0.000177  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.989107 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000050  [   64/60000]\n",
      "loss: 0.000055  [ 6464/60000]\n",
      "loss: 0.000158  [12864/60000]\n",
      "loss: 0.000083  [19264/60000]\n",
      "loss: 0.000017  [25664/60000]\n",
      "loss: 0.000003  [32064/60000]\n",
      "loss: 0.000015  [38464/60000]\n",
      "loss: 0.000163  [44864/60000]\n",
      "loss: 0.000090  [51264/60000]\n",
      "loss: 0.000019  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.001799 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000034  [   64/60000]\n",
      "loss: 0.000084  [ 6464/60000]\n",
      "loss: 0.000068  [12864/60000]\n",
      "loss: 0.000084  [19264/60000]\n",
      "loss: 0.000086  [25664/60000]\n",
      "loss: 0.000042  [32064/60000]\n",
      "loss: 0.000029  [38464/60000]\n",
      "loss: 0.000028  [44864/60000]\n",
      "loss: 0.000036  [51264/60000]\n",
      "loss: 0.000035  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.984416 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000078  [   64/60000]\n",
      "loss: 0.000073  [ 6464/60000]\n",
      "loss: 0.000171  [12864/60000]\n",
      "loss: 0.000100  [19264/60000]\n",
      "loss: 0.000062  [25664/60000]\n",
      "loss: 0.000073  [32064/60000]\n",
      "loss: 0.000014  [38464/60000]\n",
      "loss: 0.000062  [44864/60000]\n",
      "loss: 0.000004  [51264/60000]\n",
      "loss: 0.000087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.999803 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.000010  [   64/60000]\n",
      "loss: 0.000020  [ 6464/60000]\n",
      "loss: 0.000028  [12864/60000]\n",
      "loss: 0.000213  [19264/60000]\n",
      "loss: 0.000063  [25664/60000]\n",
      "loss: 0.000135  [32064/60000]\n",
      "loss: 0.000026  [38464/60000]\n",
      "loss: 0.000100  [44864/60000]\n",
      "loss: 0.000133  [51264/60000]\n",
      "loss: 0.000130  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.993348 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000058  [   64/60000]\n",
      "loss: 0.000003  [ 6464/60000]\n",
      "loss: 0.000091  [12864/60000]\n",
      "loss: 0.000083  [19264/60000]\n",
      "loss: 0.000067  [25664/60000]\n",
      "loss: 0.000017  [32064/60000]\n",
      "loss: 0.000105  [38464/60000]\n",
      "loss: 0.000145  [44864/60000]\n",
      "loss: 0.000187  [51264/60000]\n",
      "loss: 0.000102  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.996204 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.000118  [   64/60000]\n",
      "loss: 0.000010  [ 6464/60000]\n",
      "loss: 0.000017  [12864/60000]\n",
      "loss: 0.000249  [19264/60000]\n",
      "loss: 0.000086  [25664/60000]\n",
      "loss: 0.000219  [32064/60000]\n",
      "loss: 0.000056  [38464/60000]\n",
      "loss: 0.000009  [44864/60000]\n",
      "loss: 0.000083  [51264/60000]\n",
      "loss: 0.000025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.997439 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.000110  [   64/60000]\n",
      "loss: 0.000114  [ 6464/60000]\n",
      "loss: 0.000042  [12864/60000]\n",
      "loss: 0.000023  [19264/60000]\n",
      "loss: 0.000037  [25664/60000]\n",
      "loss: 0.000057  [32064/60000]\n",
      "loss: 0.000025  [38464/60000]\n",
      "loss: 0.000005  [44864/60000]\n",
      "loss: 0.000012  [51264/60000]\n",
      "loss: 0.000122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.007924 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000181  [   64/60000]\n",
      "loss: 0.000039  [ 6464/60000]\n",
      "loss: 0.000053  [12864/60000]\n",
      "loss: 0.000052  [19264/60000]\n",
      "loss: 0.000066  [25664/60000]\n",
      "loss: 0.000258  [32064/60000]\n",
      "loss: 0.000026  [38464/60000]\n",
      "loss: 0.000051  [44864/60000]\n",
      "loss: 0.000034  [51264/60000]\n",
      "loss: 0.000076  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.998137 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.000031  [   64/60000]\n",
      "loss: 0.000021  [ 6464/60000]\n",
      "loss: 0.000002  [12864/60000]\n",
      "loss: 0.000157  [19264/60000]\n",
      "loss: 0.000072  [25664/60000]\n",
      "loss: 0.000097  [32064/60000]\n",
      "loss: 0.000114  [38464/60000]\n",
      "loss: 0.000029  [44864/60000]\n",
      "loss: 0.000031  [51264/60000]\n",
      "loss: 0.000050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.000969 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.000020  [   64/60000]\n",
      "loss: 0.000046  [ 6464/60000]\n",
      "loss: 0.000041  [12864/60000]\n",
      "loss: 0.000146  [19264/60000]\n",
      "loss: 0.000039  [25664/60000]\n",
      "loss: 0.000054  [32064/60000]\n",
      "loss: 0.000061  [38464/60000]\n",
      "loss: 0.000050  [44864/60000]\n",
      "loss: 0.000021  [51264/60000]\n",
      "loss: 0.000379  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.007670 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.000286  [   64/60000]\n",
      "loss: 0.000062  [ 6464/60000]\n",
      "loss: 0.000040  [12864/60000]\n",
      "loss: 0.000059  [19264/60000]\n",
      "loss: 0.000010  [25664/60000]\n",
      "loss: 0.000010  [32064/60000]\n",
      "loss: 0.000079  [38464/60000]\n",
      "loss: 0.000082  [44864/60000]\n",
      "loss: 0.000110  [51264/60000]\n",
      "loss: 0.000010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.007591 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.000029  [   64/60000]\n",
      "loss: 0.000075  [ 6464/60000]\n",
      "loss: 0.000055  [12864/60000]\n",
      "loss: 0.000040  [19264/60000]\n",
      "loss: 0.000133  [25664/60000]\n",
      "loss: 0.000012  [32064/60000]\n",
      "loss: 0.000161  [38464/60000]\n",
      "loss: 0.000055  [44864/60000]\n",
      "loss: 0.000014  [51264/60000]\n",
      "loss: 0.000065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.016773 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000125  [   64/60000]\n",
      "loss: 0.000008  [ 6464/60000]\n",
      "loss: 0.000024  [12864/60000]\n",
      "loss: 0.000256  [19264/60000]\n",
      "loss: 0.000023  [25664/60000]\n",
      "loss: 0.000066  [32064/60000]\n",
      "loss: 0.000014  [38464/60000]\n",
      "loss: 0.000025  [44864/60000]\n",
      "loss: 0.000040  [51264/60000]\n",
      "loss: 0.000091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.006412 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.000014  [   64/60000]\n",
      "loss: 0.000028  [ 6464/60000]\n",
      "loss: 0.000020  [12864/60000]\n",
      "loss: 0.000014  [19264/60000]\n",
      "loss: 0.000006  [25664/60000]\n",
      "loss: 0.000083  [32064/60000]\n",
      "loss: 0.000063  [38464/60000]\n",
      "loss: 0.000020  [44864/60000]\n",
      "loss: 0.000056  [51264/60000]\n",
      "loss: 0.000037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.020789 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000053  [   64/60000]\n",
      "loss: 0.000014  [ 6464/60000]\n",
      "loss: 0.000005  [12864/60000]\n",
      "loss: 0.000062  [19264/60000]\n",
      "loss: 0.000012  [25664/60000]\n",
      "loss: 0.000063  [32064/60000]\n",
      "loss: 0.000068  [38464/60000]\n",
      "loss: 0.000014  [44864/60000]\n",
      "loss: 0.000011  [51264/60000]\n",
      "loss: 0.000017  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.014033 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000036  [   64/60000]\n",
      "loss: 0.000076  [ 6464/60000]\n",
      "loss: 0.000042  [12864/60000]\n",
      "loss: 0.000044  [19264/60000]\n",
      "loss: 0.000078  [25664/60000]\n",
      "loss: 0.000025  [32064/60000]\n",
      "loss: 0.000016  [38464/60000]\n",
      "loss: 0.000020  [44864/60000]\n",
      "loss: 0.000095  [51264/60000]\n",
      "loss: 0.000013  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.018216 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000152  [   64/60000]\n",
      "loss: 0.000005  [ 6464/60000]\n",
      "loss: 0.000015  [12864/60000]\n",
      "loss: 0.000059  [19264/60000]\n",
      "loss: 0.000028  [25664/60000]\n",
      "loss: 0.000011  [32064/60000]\n",
      "loss: 0.000022  [38464/60000]\n",
      "loss: 0.000193  [44864/60000]\n",
      "loss: 0.000049  [51264/60000]\n",
      "loss: 0.000025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.011212 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000013  [   64/60000]\n",
      "loss: 0.000121  [ 6464/60000]\n",
      "loss: 0.000047  [12864/60000]\n",
      "loss: 0.000039  [19264/60000]\n",
      "loss: 0.000071  [25664/60000]\n",
      "loss: 0.000026  [32064/60000]\n",
      "loss: 0.000072  [38464/60000]\n",
      "loss: 0.000120  [44864/60000]\n",
      "loss: 0.000041  [51264/60000]\n",
      "loss: 0.000143  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.012474 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.000015  [   64/60000]\n",
      "loss: 0.000080  [ 6464/60000]\n",
      "loss: 0.000036  [12864/60000]\n",
      "loss: 0.000009  [19264/60000]\n",
      "loss: 0.000018  [25664/60000]\n",
      "loss: 0.000057  [32064/60000]\n",
      "loss: 0.000009  [38464/60000]\n",
      "loss: 0.000015  [44864/60000]\n",
      "loss: 0.000059  [51264/60000]\n",
      "loss: 0.000045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.019158 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000073  [   64/60000]\n",
      "loss: 0.000069  [ 6464/60000]\n",
      "loss: 0.000025  [12864/60000]\n",
      "loss: 0.000074  [19264/60000]\n",
      "loss: 0.000042  [25664/60000]\n",
      "loss: 0.000033  [32064/60000]\n",
      "loss: 0.000052  [38464/60000]\n",
      "loss: 0.000018  [44864/60000]\n",
      "loss: 0.000052  [51264/60000]\n",
      "loss: 0.000002  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.017226 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000012  [   64/60000]\n",
      "loss: 0.000048  [ 6464/60000]\n",
      "loss: 0.000005  [12864/60000]\n",
      "loss: 0.000131  [19264/60000]\n",
      "loss: 0.000074  [25664/60000]\n",
      "loss: 0.000035  [32064/60000]\n",
      "loss: 0.000215  [38464/60000]\n",
      "loss: 0.000025  [44864/60000]\n",
      "loss: 0.000025  [51264/60000]\n",
      "loss: 0.000091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.025870 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000015  [   64/60000]\n",
      "loss: 0.000077  [ 6464/60000]\n",
      "loss: 0.000063  [12864/60000]\n",
      "loss: 0.000040  [19264/60000]\n",
      "loss: 0.000018  [25664/60000]\n",
      "loss: 0.000082  [32064/60000]\n",
      "loss: 0.000050  [38464/60000]\n",
      "loss: 0.000027  [44864/60000]\n",
      "loss: 0.000030  [51264/60000]\n",
      "loss: 0.000066  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 1.019817 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.000318  [   64/60000]\n",
      "loss: 0.000014  [ 6464/60000]\n",
      "loss: 0.000059  [12864/60000]\n",
      "loss: 0.000034  [19264/60000]\n",
      "loss: 0.000036  [25664/60000]\n",
      "loss: 0.000061  [32064/60000]\n",
      "loss: 0.000028  [38464/60000]\n",
      "loss: 0.000069  [44864/60000]\n",
      "loss: 0.000038  [51264/60000]\n",
      "loss: 0.000110  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.024259 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.000025  [   64/60000]\n",
      "loss: 0.000067  [ 6464/60000]\n",
      "loss: 0.000026  [12864/60000]\n",
      "loss: 0.000097  [19264/60000]\n",
      "loss: 0.000044  [25664/60000]\n",
      "loss: 0.000038  [32064/60000]\n",
      "loss: 0.000106  [38464/60000]\n",
      "loss: 0.000151  [44864/60000]\n",
      "loss: 0.000077  [51264/60000]\n",
      "loss: 0.000094  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.029123 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.000027  [   64/60000]\n",
      "loss: 0.000060  [ 6464/60000]\n",
      "loss: 0.000030  [12864/60000]\n",
      "loss: 0.000005  [19264/60000]\n",
      "loss: 0.000082  [25664/60000]\n",
      "loss: 0.000046  [32064/60000]\n",
      "loss: 0.000005  [38464/60000]\n",
      "loss: 0.000083  [44864/60000]\n",
      "loss: 0.000016  [51264/60000]\n",
      "loss: 0.000004  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.022673 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000065  [   64/60000]\n",
      "loss: 0.000078  [ 6464/60000]\n",
      "loss: 0.000023  [12864/60000]\n",
      "loss: 0.000070  [19264/60000]\n",
      "loss: 0.000039  [25664/60000]\n",
      "loss: 0.000095  [32064/60000]\n",
      "loss: 0.000061  [38464/60000]\n",
      "loss: 0.000062  [44864/60000]\n",
      "loss: 0.000044  [51264/60000]\n",
      "loss: 0.000033  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.027584 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.000078  [   64/60000]\n",
      "loss: 0.000035  [ 6464/60000]\n",
      "loss: 0.000043  [12864/60000]\n",
      "loss: 0.000063  [19264/60000]\n",
      "loss: 0.000035  [25664/60000]\n",
      "loss: 0.000018  [32064/60000]\n",
      "loss: 0.000073  [38464/60000]\n",
      "loss: 0.000007  [44864/60000]\n",
      "loss: 0.000029  [51264/60000]\n",
      "loss: 0.000040  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.034395 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.000024  [   64/60000]\n",
      "loss: 0.000032  [ 6464/60000]\n",
      "loss: 0.000076  [12864/60000]\n",
      "loss: 0.000020  [19264/60000]\n",
      "loss: 0.000007  [25664/60000]\n",
      "loss: 0.000007  [32064/60000]\n",
      "loss: 0.000001  [38464/60000]\n",
      "loss: 0.000017  [44864/60000]\n",
      "loss: 0.000003  [51264/60000]\n",
      "loss: 0.000037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.025842 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.000012  [   64/60000]\n",
      "loss: 0.000023  [ 6464/60000]\n",
      "loss: 0.000018  [12864/60000]\n",
      "loss: 0.000033  [19264/60000]\n",
      "loss: 0.000045  [25664/60000]\n",
      "loss: 0.000064  [32064/60000]\n",
      "loss: 0.000087  [38464/60000]\n",
      "loss: 0.000033  [44864/60000]\n",
      "loss: 0.000013  [51264/60000]\n",
      "loss: 0.000014  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.039660 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000116  [   64/60000]\n",
      "loss: 0.000033  [ 6464/60000]\n",
      "loss: 0.000090  [12864/60000]\n",
      "loss: 0.000005  [19264/60000]\n",
      "loss: 0.000065  [25664/60000]\n",
      "loss: 0.000136  [32064/60000]\n",
      "loss: 0.000007  [38464/60000]\n",
      "loss: 0.000022  [44864/60000]\n",
      "loss: 0.000014  [51264/60000]\n",
      "loss: 0.000028  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.059917 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000030  [   64/60000]\n",
      "loss: 0.000026  [ 6464/60000]\n",
      "loss: 0.000134  [12864/60000]\n",
      "loss: 0.000062  [19264/60000]\n",
      "loss: 0.000043  [25664/60000]\n",
      "loss: 0.000028  [32064/60000]\n",
      "loss: 0.000176  [38464/60000]\n",
      "loss: 0.000047  [44864/60000]\n",
      "loss: 0.000029  [51264/60000]\n",
      "loss: 0.000013  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.029665 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.000022  [   64/60000]\n",
      "loss: 0.000039  [ 6464/60000]\n",
      "loss: 0.000019  [12864/60000]\n",
      "loss: 0.000047  [19264/60000]\n",
      "loss: 0.000041  [25664/60000]\n",
      "loss: 0.000074  [32064/60000]\n",
      "loss: 0.000079  [38464/60000]\n",
      "loss: 0.000026  [44864/60000]\n",
      "loss: 0.000048  [51264/60000]\n",
      "loss: 0.000025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.033928 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.000022  [   64/60000]\n",
      "loss: 0.000017  [ 6464/60000]\n",
      "loss: 0.000069  [12864/60000]\n",
      "loss: 0.000103  [19264/60000]\n",
      "loss: 0.000006  [25664/60000]\n",
      "loss: 0.000025  [32064/60000]\n",
      "loss: 0.000029  [38464/60000]\n",
      "loss: 0.000010  [44864/60000]\n",
      "loss: 0.000019  [51264/60000]\n",
      "loss: 0.000105  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.032574 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000015  [   64/60000]\n",
      "loss: 0.000007  [ 6464/60000]\n",
      "loss: 0.000019  [12864/60000]\n",
      "loss: 0.000061  [19264/60000]\n",
      "loss: 0.000044  [25664/60000]\n",
      "loss: 0.000043  [32064/60000]\n",
      "loss: 0.000016  [38464/60000]\n",
      "loss: 0.000009  [44864/60000]\n",
      "loss: 0.000018  [51264/60000]\n",
      "loss: 0.000029  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.034526 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.000076  [   64/60000]\n",
      "loss: 0.000132  [ 6464/60000]\n",
      "loss: 0.000092  [12864/60000]\n",
      "loss: 0.000007  [19264/60000]\n",
      "loss: 0.000038  [25664/60000]\n",
      "loss: 0.000025  [32064/60000]\n",
      "loss: 0.000070  [38464/60000]\n",
      "loss: 0.000149  [44864/60000]\n",
      "loss: 0.000159  [51264/60000]\n",
      "loss: 0.000057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.038330 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000020  [   64/60000]\n",
      "loss: 0.000043  [ 6464/60000]\n",
      "loss: 0.000007  [12864/60000]\n",
      "loss: 0.000027  [19264/60000]\n",
      "loss: 0.000078  [25664/60000]\n",
      "loss: 0.000029  [32064/60000]\n",
      "loss: 0.000002  [38464/60000]\n",
      "loss: 0.000007  [44864/60000]\n",
      "loss: 0.000025  [51264/60000]\n",
      "loss: 0.000056  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.040865 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000079  [   64/60000]\n",
      "loss: 0.000102  [ 6464/60000]\n",
      "loss: 0.000011  [12864/60000]\n",
      "loss: 0.000137  [19264/60000]\n",
      "loss: 0.000007  [25664/60000]\n",
      "loss: 0.000043  [32064/60000]\n",
      "loss: 0.000055  [38464/60000]\n",
      "loss: 0.000097  [44864/60000]\n",
      "loss: 0.000022  [51264/60000]\n",
      "loss: 0.000001  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.041580 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.000049  [   64/60000]\n",
      "loss: 0.000028  [ 6464/60000]\n",
      "loss: 0.000013  [12864/60000]\n",
      "loss: 0.000008  [19264/60000]\n",
      "loss: 0.000050  [25664/60000]\n",
      "loss: 0.000008  [32064/60000]\n",
      "loss: 0.000012  [38464/60000]\n",
      "loss: 0.000055  [44864/60000]\n",
      "loss: 0.000108  [51264/60000]\n",
      "loss: 0.000018  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.053554 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000162  [   64/60000]\n",
      "loss: 0.000022  [ 6464/60000]\n",
      "loss: 0.000042  [12864/60000]\n",
      "loss: 0.000029  [19264/60000]\n",
      "loss: 0.000101  [25664/60000]\n",
      "loss: 0.000011  [32064/60000]\n",
      "loss: 0.000009  [38464/60000]\n",
      "loss: 0.000017  [44864/60000]\n",
      "loss: 0.000016  [51264/60000]\n",
      "loss: 0.000050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.050903 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.000005  [   64/60000]\n",
      "loss: 0.000050  [ 6464/60000]\n",
      "loss: 0.000050  [12864/60000]\n",
      "loss: 0.000031  [19264/60000]\n",
      "loss: 0.000079  [25664/60000]\n",
      "loss: 0.000112  [32064/60000]\n",
      "loss: 0.000018  [38464/60000]\n",
      "loss: 0.000029  [44864/60000]\n",
      "loss: 0.000077  [51264/60000]\n",
      "loss: 0.000110  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.040299 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.000021  [   64/60000]\n",
      "loss: 0.000009  [ 6464/60000]\n",
      "loss: 0.000024  [12864/60000]\n",
      "loss: 0.000017  [19264/60000]\n",
      "loss: 0.000037  [25664/60000]\n",
      "loss: 0.000003  [32064/60000]\n",
      "loss: 0.000018  [38464/60000]\n",
      "loss: 0.000008  [44864/60000]\n",
      "loss: 0.000001  [51264/60000]\n",
      "loss: 0.000021  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.045291 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000044  [   64/60000]\n",
      "loss: 0.000103  [ 6464/60000]\n",
      "loss: 0.000033  [12864/60000]\n",
      "loss: 0.000046  [19264/60000]\n",
      "loss: 0.000021  [25664/60000]\n",
      "loss: 0.000012  [32064/60000]\n",
      "loss: 0.000041  [38464/60000]\n",
      "loss: 0.000154  [44864/60000]\n",
      "loss: 0.000054  [51264/60000]\n",
      "loss: 0.000021  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.055007 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000006  [   64/60000]\n",
      "loss: 0.000075  [ 6464/60000]\n",
      "loss: 0.000027  [12864/60000]\n",
      "loss: 0.000048  [19264/60000]\n",
      "loss: 0.000022  [25664/60000]\n",
      "loss: 0.000018  [32064/60000]\n",
      "loss: 0.000019  [38464/60000]\n",
      "loss: 0.000079  [44864/60000]\n",
      "loss: 0.000024  [51264/60000]\n",
      "loss: 0.000053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.048538 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000014  [   64/60000]\n",
      "loss: 0.000010  [ 6464/60000]\n",
      "loss: 0.000007  [12864/60000]\n",
      "loss: 0.000082  [19264/60000]\n",
      "loss: 0.000060  [25664/60000]\n",
      "loss: 0.000062  [32064/60000]\n",
      "loss: 0.000073  [38464/60000]\n",
      "loss: 0.000050  [44864/60000]\n",
      "loss: 0.000012  [51264/60000]\n",
      "loss: 0.000024  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.059212 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.000008  [   64/60000]\n",
      "loss: 0.000025  [ 6464/60000]\n",
      "loss: 0.000017  [12864/60000]\n",
      "loss: 0.000039  [19264/60000]\n",
      "loss: 0.000010  [25664/60000]\n",
      "loss: 0.000095  [32064/60000]\n",
      "loss: 0.000049  [38464/60000]\n",
      "loss: 0.000030  [44864/60000]\n",
      "loss: 0.000031  [51264/60000]\n",
      "loss: 0.000038  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.047767 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.000045  [   64/60000]\n",
      "loss: 0.000006  [ 6464/60000]\n",
      "loss: 0.000051  [12864/60000]\n",
      "loss: 0.000038  [19264/60000]\n",
      "loss: 0.000004  [25664/60000]\n",
      "loss: 0.000041  [32064/60000]\n",
      "loss: 0.000022  [38464/60000]\n",
      "loss: 0.000013  [44864/60000]\n",
      "loss: 0.000007  [51264/60000]\n",
      "loss: 0.000053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.047056 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.000011  [   64/60000]\n",
      "loss: 0.000037  [ 6464/60000]\n",
      "loss: 0.000019  [12864/60000]\n",
      "loss: 0.000027  [19264/60000]\n",
      "loss: 0.000040  [25664/60000]\n",
      "loss: 0.000002  [32064/60000]\n",
      "loss: 0.000041  [38464/60000]\n",
      "loss: 0.000014  [44864/60000]\n",
      "loss: 0.000012  [51264/60000]\n",
      "loss: 0.000020  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.055938 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000055  [   64/60000]\n",
      "loss: 0.000088  [ 6464/60000]\n",
      "loss: 0.000212  [12864/60000]\n",
      "loss: 0.000019  [19264/60000]\n",
      "loss: 0.000033  [25664/60000]\n",
      "loss: 0.000062  [32064/60000]\n",
      "loss: 0.000010  [38464/60000]\n",
      "loss: 0.000143  [44864/60000]\n",
      "loss: 0.000019  [51264/60000]\n",
      "loss: 0.000024  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.051440 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000035  [   64/60000]\n",
      "loss: 0.000088  [ 6464/60000]\n",
      "loss: 0.000009  [12864/60000]\n",
      "loss: 0.000067  [19264/60000]\n",
      "loss: 0.000071  [25664/60000]\n",
      "loss: 0.000004  [32064/60000]\n",
      "loss: 0.000004  [38464/60000]\n",
      "loss: 0.000018  [44864/60000]\n",
      "loss: 0.000048  [51264/60000]\n",
      "loss: 0.000015  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.051116 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.000008  [   64/60000]\n",
      "loss: 0.000030  [ 6464/60000]\n",
      "loss: 0.000018  [12864/60000]\n",
      "loss: 0.000041  [19264/60000]\n",
      "loss: 0.000064  [25664/60000]\n",
      "loss: 0.000120  [32064/60000]\n",
      "loss: 0.000076  [38464/60000]\n",
      "loss: 0.000021  [44864/60000]\n",
      "loss: 0.000016  [51264/60000]\n",
      "loss: 0.000050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.051528 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000057  [   64/60000]\n",
      "loss: 0.000004  [ 6464/60000]\n",
      "loss: 0.000002  [12864/60000]\n",
      "loss: 0.000018  [19264/60000]\n",
      "loss: 0.000062  [25664/60000]\n",
      "loss: 0.000027  [32064/60000]\n",
      "loss: 0.000028  [38464/60000]\n",
      "loss: 0.000002  [44864/60000]\n",
      "loss: 0.000066  [51264/60000]\n",
      "loss: 0.000050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.053283 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.000056  [   64/60000]\n",
      "loss: 0.000130  [ 6464/60000]\n",
      "loss: 0.000014  [12864/60000]\n",
      "loss: 0.000005  [19264/60000]\n",
      "loss: 0.000032  [25664/60000]\n",
      "loss: 0.000032  [32064/60000]\n",
      "loss: 0.000003  [38464/60000]\n",
      "loss: 0.000007  [44864/60000]\n",
      "loss: 0.000022  [51264/60000]\n",
      "loss: 0.000037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.058275 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000042  [   64/60000]\n",
      "loss: 0.000005  [ 6464/60000]\n",
      "loss: 0.000069  [12864/60000]\n",
      "loss: 0.000007  [19264/60000]\n",
      "loss: 0.000010  [25664/60000]\n",
      "loss: 0.000059  [32064/60000]\n",
      "loss: 0.000021  [38464/60000]\n",
      "loss: 0.000019  [44864/60000]\n",
      "loss: 0.000052  [51264/60000]\n",
      "loss: 0.000012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.063980 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000011  [   64/60000]\n",
      "loss: 0.000004  [ 6464/60000]\n",
      "loss: 0.000029  [12864/60000]\n",
      "loss: 0.000009  [19264/60000]\n",
      "loss: 0.000022  [25664/60000]\n",
      "loss: 0.000023  [32064/60000]\n",
      "loss: 0.000020  [38464/60000]\n",
      "loss: 0.000015  [44864/60000]\n",
      "loss: 0.000011  [51264/60000]\n",
      "loss: 0.000018  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.057574 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.000058  [   64/60000]\n",
      "loss: 0.000040  [ 6464/60000]\n",
      "loss: 0.000049  [12864/60000]\n",
      "loss: 0.000030  [19264/60000]\n",
      "loss: 0.000025  [25664/60000]\n",
      "loss: 0.000002  [32064/60000]\n",
      "loss: 0.000011  [38464/60000]\n",
      "loss: 0.000036  [44864/60000]\n",
      "loss: 0.000039  [51264/60000]\n",
      "loss: 0.000005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.068853 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000005  [   64/60000]\n",
      "loss: 0.000045  [ 6464/60000]\n",
      "loss: 0.000008  [12864/60000]\n",
      "loss: 0.000048  [19264/60000]\n",
      "loss: 0.000076  [25664/60000]\n",
      "loss: 0.000004  [32064/60000]\n",
      "loss: 0.000034  [38464/60000]\n",
      "loss: 0.000006  [44864/60000]\n",
      "loss: 0.000085  [51264/60000]\n",
      "loss: 0.000011  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.060650 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000006  [   64/60000]\n",
      "loss: 0.000032  [ 6464/60000]\n",
      "loss: 0.000031  [12864/60000]\n",
      "loss: 0.000017  [19264/60000]\n",
      "loss: 0.000002  [25664/60000]\n",
      "loss: 0.000020  [32064/60000]\n",
      "loss: 0.000021  [38464/60000]\n",
      "loss: 0.000073  [44864/60000]\n",
      "loss: 0.000027  [51264/60000]\n",
      "loss: 0.000056  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.067706 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000021  [   64/60000]\n",
      "loss: 0.000027  [ 6464/60000]\n",
      "loss: 0.000087  [12864/60000]\n",
      "loss: 0.000015  [19264/60000]\n",
      "loss: 0.000010  [25664/60000]\n",
      "loss: 0.000004  [32064/60000]\n",
      "loss: 0.000011  [38464/60000]\n",
      "loss: 0.000106  [44864/60000]\n",
      "loss: 0.000034  [51264/60000]\n",
      "loss: 0.000025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.068296 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000063  [   64/60000]\n",
      "loss: 0.000034  [ 6464/60000]\n",
      "loss: 0.000035  [12864/60000]\n",
      "loss: 0.000035  [19264/60000]\n",
      "loss: 0.000051  [25664/60000]\n",
      "loss: 0.000004  [32064/60000]\n",
      "loss: 0.000010  [38464/60000]\n",
      "loss: 0.000041  [44864/60000]\n",
      "loss: 0.000025  [51264/60000]\n",
      "loss: 0.000010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.066126 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.000009  [   64/60000]\n",
      "loss: 0.000008  [ 6464/60000]\n",
      "loss: 0.000032  [12864/60000]\n",
      "loss: 0.000019  [19264/60000]\n",
      "loss: 0.000078  [25664/60000]\n",
      "loss: 0.000137  [32064/60000]\n",
      "loss: 0.000043  [38464/60000]\n",
      "loss: 0.000015  [44864/60000]\n",
      "loss: 0.000022  [51264/60000]\n",
      "loss: 0.000088  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.083862 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.000003  [   64/60000]\n",
      "loss: 0.000050  [ 6464/60000]\n",
      "loss: 0.000023  [12864/60000]\n",
      "loss: 0.000014  [19264/60000]\n",
      "loss: 0.000030  [25664/60000]\n",
      "loss: 0.000039  [32064/60000]\n",
      "loss: 0.000036  [38464/60000]\n",
      "loss: 0.000027  [44864/60000]\n",
      "loss: 0.000005  [51264/60000]\n",
      "loss: 0.000053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.074105 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000009  [   64/60000]\n",
      "loss: 0.000007  [ 6464/60000]\n",
      "loss: 0.000008  [12864/60000]\n",
      "loss: 0.000052  [19264/60000]\n",
      "loss: 0.000008  [25664/60000]\n",
      "loss: 0.000048  [32064/60000]\n",
      "loss: 0.000002  [38464/60000]\n",
      "loss: 0.000084  [44864/60000]\n",
      "loss: 0.000017  [51264/60000]\n",
      "loss: 0.000005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.080265 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000013  [   64/60000]\n",
      "loss: 0.000005  [ 6464/60000]\n",
      "loss: 0.000021  [12864/60000]\n",
      "loss: 0.000028  [19264/60000]\n",
      "loss: 0.000017  [25664/60000]\n",
      "loss: 0.000045  [32064/60000]\n",
      "loss: 0.000046  [38464/60000]\n",
      "loss: 0.000010  [44864/60000]\n",
      "loss: 0.000017  [51264/60000]\n",
      "loss: 0.000012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.070048 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000041  [   64/60000]\n",
      "loss: 0.000028  [ 6464/60000]\n",
      "loss: 0.000007  [12864/60000]\n",
      "loss: 0.000026  [19264/60000]\n",
      "loss: 0.000079  [25664/60000]\n",
      "loss: 0.000023  [32064/60000]\n",
      "loss: 0.000030  [38464/60000]\n",
      "loss: 0.000104  [44864/60000]\n",
      "loss: 0.000004  [51264/60000]\n",
      "loss: 0.000092  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.077750 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000004  [   64/60000]\n",
      "loss: 0.000014  [ 6464/60000]\n",
      "loss: 0.000042  [12864/60000]\n",
      "loss: 0.000005  [19264/60000]\n",
      "loss: 0.000031  [25664/60000]\n",
      "loss: 0.000009  [32064/60000]\n",
      "loss: 0.000027  [38464/60000]\n",
      "loss: 0.000003  [44864/60000]\n",
      "loss: 0.000001  [51264/60000]\n",
      "loss: 0.000047  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.072854 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000013  [   64/60000]\n",
      "loss: 0.000016  [ 6464/60000]\n",
      "loss: 0.000016  [12864/60000]\n",
      "loss: 0.000008  [19264/60000]\n",
      "loss: 0.000009  [25664/60000]\n",
      "loss: 0.000010  [32064/60000]\n",
      "loss: 0.000005  [38464/60000]\n",
      "loss: 0.000034  [44864/60000]\n",
      "loss: 0.000030  [51264/60000]\n",
      "loss: 0.000045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.068068 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000088  [   64/60000]\n",
      "loss: 0.000011  [ 6464/60000]\n",
      "loss: 0.000009  [12864/60000]\n",
      "loss: 0.000054  [19264/60000]\n",
      "loss: 0.000096  [25664/60000]\n",
      "loss: 0.000049  [32064/60000]\n",
      "loss: 0.000056  [38464/60000]\n",
      "loss: 0.000016  [44864/60000]\n",
      "loss: 0.000082  [51264/60000]\n",
      "loss: 0.000053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.087568 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.000038  [   64/60000]\n",
      "loss: 0.000006  [ 6464/60000]\n",
      "loss: 0.000019  [12864/60000]\n",
      "loss: 0.000071  [19264/60000]\n",
      "loss: 0.000032  [25664/60000]\n",
      "loss: 0.000047  [32064/60000]\n",
      "loss: 0.000049  [38464/60000]\n",
      "loss: 0.000022  [44864/60000]\n",
      "loss: 0.000034  [51264/60000]\n",
      "loss: 0.000027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.076586 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.000017  [   64/60000]\n",
      "loss: 0.000027  [ 6464/60000]\n",
      "loss: 0.000021  [12864/60000]\n",
      "loss: 0.000006  [19264/60000]\n",
      "loss: 0.000027  [25664/60000]\n",
      "loss: 0.000002  [32064/60000]\n",
      "loss: 0.000013  [38464/60000]\n",
      "loss: 0.000031  [44864/60000]\n",
      "loss: 0.000072  [51264/60000]\n",
      "loss: 0.000096  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.069967 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.000010  [   64/60000]\n",
      "loss: 0.000011  [ 6464/60000]\n",
      "loss: 0.000035  [12864/60000]\n",
      "loss: 0.000031  [19264/60000]\n",
      "loss: 0.000041  [25664/60000]\n",
      "loss: 0.000009  [32064/60000]\n",
      "loss: 0.000010  [38464/60000]\n",
      "loss: 0.000027  [44864/60000]\n",
      "loss: 0.000154  [51264/60000]\n",
      "loss: 0.000022  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.072478 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000017  [   64/60000]\n",
      "loss: 0.000012  [ 6464/60000]\n",
      "loss: 0.000029  [12864/60000]\n",
      "loss: 0.000012  [19264/60000]\n",
      "loss: 0.000003  [25664/60000]\n",
      "loss: 0.000003  [32064/60000]\n",
      "loss: 0.000037  [38464/60000]\n",
      "loss: 0.000037  [44864/60000]\n",
      "loss: 0.000064  [51264/60000]\n",
      "loss: 0.000110  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.080857 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000014  [   64/60000]\n",
      "loss: 0.000036  [ 6464/60000]\n",
      "loss: 0.000020  [12864/60000]\n",
      "loss: 0.000041  [19264/60000]\n",
      "loss: 0.000030  [25664/60000]\n",
      "loss: 0.000038  [32064/60000]\n",
      "loss: 0.000021  [38464/60000]\n",
      "loss: 0.000085  [44864/60000]\n",
      "loss: 0.000058  [51264/60000]\n",
      "loss: 0.000042  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.088382 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000044  [   64/60000]\n",
      "loss: 0.000010  [ 6464/60000]\n",
      "loss: 0.000016  [12864/60000]\n",
      "loss: 0.000003  [19264/60000]\n",
      "loss: 0.000052  [25664/60000]\n",
      "loss: 0.000026  [32064/60000]\n",
      "loss: 0.000017  [38464/60000]\n",
      "loss: 0.000026  [44864/60000]\n",
      "loss: 0.000028  [51264/60000]\n",
      "loss: 0.000026  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.072574 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000021  [   64/60000]\n",
      "loss: 0.000031  [ 6464/60000]\n",
      "loss: 0.000012  [12864/60000]\n",
      "loss: 0.000004  [19264/60000]\n",
      "loss: 0.000073  [25664/60000]\n",
      "loss: 0.000013  [32064/60000]\n",
      "loss: 0.000020  [38464/60000]\n",
      "loss: 0.000016  [44864/60000]\n",
      "loss: 0.000020  [51264/60000]\n",
      "loss: 0.000032  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.083121 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000004  [   64/60000]\n",
      "loss: 0.000007  [ 6464/60000]\n",
      "loss: 0.000023  [12864/60000]\n",
      "loss: 0.000046  [19264/60000]\n",
      "loss: 0.000046  [25664/60000]\n",
      "loss: 0.000026  [32064/60000]\n",
      "loss: 0.000018  [38464/60000]\n",
      "loss: 0.000054  [44864/60000]\n",
      "loss: 0.000007  [51264/60000]\n",
      "loss: 0.000029  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.078984 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000006  [   64/60000]\n",
      "loss: 0.000037  [ 6464/60000]\n",
      "loss: 0.000037  [12864/60000]\n",
      "loss: 0.000004  [19264/60000]\n",
      "loss: 0.000003  [25664/60000]\n",
      "loss: 0.000003  [32064/60000]\n",
      "loss: 0.000118  [38464/60000]\n",
      "loss: 0.000056  [44864/60000]\n",
      "loss: 0.000011  [51264/60000]\n",
      "loss: 0.000025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.084813 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000011  [   64/60000]\n",
      "loss: 0.000024  [ 6464/60000]\n",
      "loss: 0.000031  [12864/60000]\n",
      "loss: 0.000008  [19264/60000]\n",
      "loss: 0.000035  [25664/60000]\n",
      "loss: 0.000027  [32064/60000]\n",
      "loss: 0.000056  [38464/60000]\n",
      "loss: 0.000024  [44864/60000]\n",
      "loss: 0.000060  [51264/60000]\n",
      "loss: 0.000011  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.080432 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000023  [   64/60000]\n",
      "loss: 0.000016  [ 6464/60000]\n",
      "loss: 0.000120  [12864/60000]\n",
      "loss: 0.000002  [19264/60000]\n",
      "loss: 0.000056  [25664/60000]\n",
      "loss: 0.000017  [32064/60000]\n",
      "loss: 0.000056  [38464/60000]\n",
      "loss: 0.000010  [44864/60000]\n",
      "loss: 0.000014  [51264/60000]\n",
      "loss: 0.000016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.077798 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000000  [   64/60000]\n",
      "loss: 0.000012  [ 6464/60000]\n",
      "loss: 0.000033  [12864/60000]\n",
      "loss: 0.000041  [19264/60000]\n",
      "loss: 0.000012  [25664/60000]\n",
      "loss: 0.000075  [32064/60000]\n",
      "loss: 0.000008  [38464/60000]\n",
      "loss: 0.000002  [44864/60000]\n",
      "loss: 0.000004  [51264/60000]\n",
      "loss: 0.000063  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.087424 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000034  [   64/60000]\n",
      "loss: 0.000023  [ 6464/60000]\n",
      "loss: 0.000015  [12864/60000]\n",
      "loss: 0.000016  [19264/60000]\n",
      "loss: 0.000032  [25664/60000]\n",
      "loss: 0.000014  [32064/60000]\n",
      "loss: 0.000033  [38464/60000]\n",
      "loss: 0.000028  [44864/60000]\n",
      "loss: 0.000009  [51264/60000]\n",
      "loss: 0.000018  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.097680 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.000010  [   64/60000]\n",
      "loss: 0.000021  [ 6464/60000]\n",
      "loss: 0.000015  [12864/60000]\n",
      "loss: 0.000006  [19264/60000]\n",
      "loss: 0.000039  [25664/60000]\n",
      "loss: 0.000029  [32064/60000]\n",
      "loss: 0.000005  [38464/60000]\n",
      "loss: 0.000104  [44864/60000]\n",
      "loss: 0.000005  [51264/60000]\n",
      "loss: 0.000010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.082976 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000059  [   64/60000]\n",
      "loss: 0.000019  [ 6464/60000]\n",
      "loss: 0.000011  [12864/60000]\n",
      "loss: 0.000092  [19264/60000]\n",
      "loss: 0.000025  [25664/60000]\n",
      "loss: 0.000097  [32064/60000]\n",
      "loss: 0.000062  [38464/60000]\n",
      "loss: 0.000008  [44864/60000]\n",
      "loss: 0.000003  [51264/60000]\n",
      "loss: 0.000006  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.092253 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000050  [   64/60000]\n",
      "loss: 0.000006  [ 6464/60000]\n",
      "loss: 0.000012  [12864/60000]\n",
      "loss: 0.000093  [19264/60000]\n",
      "loss: 0.000004  [25664/60000]\n",
      "loss: 0.000043  [32064/60000]\n",
      "loss: 0.000042  [38464/60000]\n",
      "loss: 0.000025  [44864/60000]\n",
      "loss: 0.000048  [51264/60000]\n",
      "loss: 0.000007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 1.081871 \n",
      "\n",
      "Done!\n",
      "t_elapsed = 662.2 sec\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 19e-3\n",
    "batch = 64\n",
    "epochs = 275\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch, shuffle=True)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for x, y in train_dataloader:\n",
    "    x  = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # Rest of training loop\n",
    "\n",
    "t_start = time.time()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "t_elapsed = time.time() - t_start\n",
    "print(f\"t_elapsed = {t_elapsed:.1f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e18f41-61d1-4e47-b92a-a3ca752d28f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
